{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#Import Libraries\nimport sys \nimport pandas as pd \nimport matplotlib \nimport numpy as np \nimport scipy as sc\nimport IPython\nfrom IPython import display \nimport sklearn\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*25)\n\n#Algorithms\nfrom xgboost import XGBClassifier\n\n\nfrom scipy.stats import skew\n\n\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\n\n\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Data\ndata_train = pd.read_csv('../input/train.csv')\ndata_test  = pd.read_csv('../input/test.csv')\ndata_submit = pd.read_csv('../input/sample_submission.csv')\n\ndata_train.head()\ndata_test.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add dfs\nprint('Shape Of train df:',data_train.shape)\nprint('Shape Of test df:',data_test.shape)\ndata_train_test = pd.concat([data_train, data_test]) #Remeber the index because we have to split data later (200000 in train )\nprint('Shape Of train test  df:',data_train_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove id\nprint('Shape Of old train test df:',data_train_test.shape)\ndata_train_test.drop(['ID_code'], axis=1, inplace = True)\nprint('Shape Of new train test df:',data_train_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check null\nnulls = np.sum(data_train_test.isnull())\nnullcols = nulls.loc[(nulls != 0)]\ndtypes = data_train_test.dtypes\ndtypes2 = dtypes.loc[(nulls != 0)]\ninfo = pd.concat([nullcols, dtypes2], axis=1).sort_values(by=0, ascending=False)\nprint(info)\nprint(\"There are\", len(nullcols), \"columns with missing values\")\nprint('Null in  data:',data_train_test.isnull().sum().sum())\nprint('Shape of df:', data_train_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#PLot\n\nsns.countplot(data_train['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Skewness in dataset\n#As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. \n#If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in data_train_test.columns:\n    if data_train_test[i].dtype in numeric_dtypes: \n        numerics2.append(i)\n\nskew_features = data_train_test[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\nskews = pd.DataFrame({'skew':skew_features})\nskews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to plot Graph of each attribute vs target value\ndef PlotAttributeVsTarget(df,target):\n    for y in df.columns:\n        if y!= target:\n            plt.figure(figsize=(20,5))\n            grid = plt.GridSpec(1,2, wspace=0.4, hspace=0.3)\n            plt.subplot(grid[0,0])\n            sns.distplot(data_train[y])\n            #plt.subplot(grid[0,0])\n            #sns.scatterplot(x=data_train[y],y=data_train[target])\n            plt.subplot(grid[0,1])\n            sns.boxplot(x=data_train[target],y=data_train[y])\n            \n#PlotAttributeVsTarget(data_train.iloc[:,1:],'target') #Commented as this will take long time depending upon data and computing power. Change index to see plots of different variable\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"\n#Function to find CV of each variable\n#CV is a measure of relative variation or dispersion \ndef CoeffiecinetOfVariation(df):\n    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    numerics2 = []\n    for y in df.columns:\n        if df[y].dtype in numeric_dtypes:\n            numerics2.append(y)\n    SD_features = df[numerics2].apply(lambda x: np.std(x))\n    Mean_features = df[numerics2].apply(lambda x: np.mean(x))\n    CV_features = df[numerics2].apply(lambda x: (np.std(x)/np.mean(x)))\n    CV = pd.DataFrame({'SD':SD_features,'Mean':Mean_features,'CV':CV_features})\n    CV = CV.sort_values(by='CV',ascending=False)\n    return CV\n    \n#CoeffiecinetOfVariation(data_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation\n#correlation of each varibale with target\ndef Correlation(df):\n    numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    numerics2 = []\n    crr = {}\n    for y in df.columns:\n        if df[y].dtype in numeric_dtypes:\n            numerics2.append(y)\n            for col in numerics2:\n                if col != 'target':\n                    crr[col] = np.corrcoef(df[col],df['target'])[1,0]\n                    \n    Crr_df = pd.DataFrame([crr])\n    Crr_df = Crr_df.T\n    Crr_df.columns = ['CorrCoef']\n    Crr_df = Crr_df.sort_values(by='CorrCoef',ascending=False)\n    return Crr_df\n    \nCorrelation(data_train)\n#Very weak correlations ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = data_train.iloc[:,data_train.columns != 'target']\ny_train = data_train.iloc[:,data_train.columns == 'target']\nX_train.drop(['ID_code'], axis=1, inplace = True)\nX_test = data_test.iloc[:,data_test.columns != 'target']\nX_test.drop(['ID_code'], axis=1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',silent=True, nthread=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n\"\"\"\nfolds = 3\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n\"\"\"\n# Here we go\n#random_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nprint('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\nprint(random_search.best_score_ * 2 - 1)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)\nresults = pd.DataFrame(random_search.cv_results_)\nresults.to_csv('xgb-random-grid-search-results-01.csv', index=False)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nxgb1 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n       seed=None, silent=True, subsample=0.6)\n       \n    \nxgb1 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.79, gamma=1.3, learning_rate=0.02,\n       max_delta_step=0, max_depth=6, min_child_weight=3, missing=None,\n       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n       seed=None, silent=True, subsample=0.6) \"\"\"\n    \nxgb1 = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.79, gamma=1.3, learning_rate=0.02,\n       max_delta_step=0, max_depth=7, min_child_weight=2, missing=None,\n       n_estimators=1000, n_jobs=1, nthread=1,\n       objective='binary:logistic', random_state=0, reg_alpha=0,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=0.6)\n\nxgb1.fit(X_train,y_train.values.ravel())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = xgb1.predict_proba(X_test)\ndata_submit['target'] = y_pred\ndata_submit.to_csv(\"submit.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}