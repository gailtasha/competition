{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Deep Neural Network con Keras**\n\nEn este ejercicio se procede a realizar una Deep Neural Network con el Framework Keras, utilizando Tensorflow como Backend. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.layers import Input, Dense, BatchNormalization, Add, GaussianNoise, Dropout\nfrom keras.models import Model\nfrom sklearn.metrics import roc_auc_score\nfrom keras.layers import Wrapper\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nimport matplotlib.pyplot as plt\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 0. Funciones auxiliares."},{"metadata":{"trusted":true},"cell_type":"code","source":"precisiones_globales=[]\nepochs = 15\ndef graf_model(train_history):\n    f = plt.figure(figsize=(15,10))\n    ax = f.add_subplot(121)\n    ax2 = f.add_subplot(122)\n    # summarize history for accuracy\n    ax.plot(train_history.history['binary_accuracy'])\n    ax.plot(train_history.history['val_binary_accuracy'])\n    ax.set_title('model accuracy')\n    ax.set_ylabel('accuracy')\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(train_history.history['loss'])\n    ax2.plot(train_history.history['val_loss'])\n    ax2.set_title('model loss')\n    ax2.set_ylabel('loss')\n    ax2.set_xlabel('epoch')\n    ax2.legend(['train', 'test'], loc='upper left')\n    plt.show()\ndef precision(model, registrar=False):\n    y_pred = model.predict(train_dfX)\n    train_auc = roc_auc_score(train_dfY, y_pred)\n    y_pred = model.predict(val_dfX)\n    val_auc = roc_auc_score(val_dfY, y_pred)\n    print('Train AUC: ', train_auc)\n    print('Vali AUC: ', val_auc)\n    if registrar:\n        precisiones_globales.append([train_auc,val_auc])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Importando los datos:\nSe procede a leer tanto el train.csv que es el conjunto de entrenamiento como el test.csv que es el conjunto de validacion. Mas adelante se construira en base a train.csv el conjunto de dev"},{"metadata":{"trusted":true,"_uuid":"26df1c182e6b922b9000d6f0030d725bbbe1c497"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \",train_df.shape)\nprint(\"Test shape : \",test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se crea las variables X y Y con las que se van a entrenar al modelo.\nTambien se elimina el ID_Code ya que no aporta valor al entrenamiento del modelo. "},{"metadata":{"trusted":true,"_uuid":"cf8843fccfa85b33d9c953695ffd31043687ca07"},"cell_type":"code","source":"train_dfX = train_df.drop(['ID_code', 'target'], axis=1)\ntrain_dfY = train_df['target']\nsubmission = test_df[['ID_code']].copy()\ntest_df = test_df.drop(['ID_code'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Normalizando los valores de X\nSe transforma X de manera que quede normalizado todos su valores."},{"metadata":{"trusted":true,"_uuid":"2ff0cc7182904889793ee2561710ef9f883d2aac"},"cell_type":"code","source":"sc = StandardScaler()\ntrain_dfX = sc.fit_transform(train_dfX)\ntest_df = sc.transform(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Separando Entrenamiento de Validacion\nSe divide X para tener un conjunto de entrenamiento y otro de validacion y pruebas. El 90% de las observaciones quedan en el conjunto de entrenamiento."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dfX,val_dfX,train_dfY, val_dfY = train_test_split(train_dfX,train_dfY , test_size=0.1, stratify=train_dfY)\nprint(\"Entrnamiento: \",train_dfX.shape)\nprint(\"Validacion : \",val_dfX.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui podemos ver como nuestra variable de entramiento train_dfX tiene 16200 observaciones y 200 caracteristicas. Es decir, la forma en la que ingresaremos datos a nuestro modelo sera (200, )"},{"metadata":{},"cell_type":"markdown","source":"# 4. Creacion del modelo.\n"},{"metadata":{},"cell_type":"markdown","source":"Vamos a definir una funcion que cree un modelo de red neuronal. Esta red va a tener 2 capaz ocultas con 1028 neuronas cada una. Se va a utilizar el optimizador SGD y la funcion de costo BinaryCrossEntropy. Los valores W del modelo se iniciaran de manera aleatoria y uniforme, los valores de b se iniciaran en cero.\n\nA tener en cuenta:\n\nCual es el learning Rate de este modelo?\n"},{"metadata":{"trusted":true,"_uuid":"df0cd2b796f8a7a884a65f1c9a4f77a11976b829"},"cell_type":"code","source":"def func_model():   \n    inp = Input(shape=(200,))\n    x=Dense(1028, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros')(inp)\n    x=Dense(1028, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros')(x) \n    x=Dense(1, activation=\"sigmoid\", kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['binary_accuracy'])\n    return model\nmodel = func_model()\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Entrenamiento del modelo.\n\nSe entrenara el modelo con un batch_size de 512. Utilizando nuestras variables de validacion para seguir de cerca el accuracy tanto en entrenamiento como en validacion. Esto lo haremos por 20 epochs."},{"metadata":{"trusted":true,"_uuid":"e4d79617a719b196df323e850f3e9395ecee0e9a"},"cell_type":"code","source":"train_history = model.fit(train_dfX, train_dfY, batch_size=512, epochs=epochs, validation_data=(val_dfX, val_dfY))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a ver una grafica de como se comporta nuestro modelo tanto en la perdida como en la precision (binary_accuracy)."},{"metadata":{"trusted":true},"cell_type":"code","source":"graf_model(train_history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Precision del modelo.\n\nEn esta competencia la metrica utilizada para medir la precision de nuestro modelo es el AUC (referencia rapida: https://es.wikipedia.org/wiki/Curva_ROC). Por lo que vamos a estar bastante enfocados en mejorarla. \n\nLa funcion precision() nos va a permitir, dado como parametro uno de nuestros modelos, imprimir el valor de AUC tanto del conjunto de entrenamiento como del de validacion. "},{"metadata":{"trusted":true,"_uuid":"772dc8cd54722cf0c93e2f173ed1f3fb387c82aa"},"cell_type":"code","source":"precision(model, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Tamaño de la Red. (Evaluado)\n\nEn este apartado vamos a estar revisando como el tamaño de la red afecta el desempeño de la misma. Vamos a experimentar utilizando distinta cantidad de capaz ocultas y de neuronas por capa.\n\nLa variable arquitectura es una lista de Python que sirve como parametro de la funcion model(arquitectura) para definir una red neuronal con una cantidad len(arquitectura) de capaz ocultas, donde cada capa oculta l tiene una cantidad de neuronas arquitectura[l-1].\n\nPor ejemplo, de configurar la variable arquitectura  de forma [5,10,20] tendremos una red neuronal con 3 capaz ocultas, con 5, 10 y 20 capaz respectivamente. "},{"metadata":{"trusted":true,"_uuid":"d5dd3f8791b0d433c8a164f9b869f5b77472df41"},"cell_type":"code","source":"def func_model(arquitectura): \n    first =True\n    inp = Input(shape=(200,))\n    for capa in arquitectura:        \n        if first:\n            x=Dense(capa, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros')(inp)            \n            first = False\n        else:\n            x=Dense(capa, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros')(x)  \n    x=Dense(1, activation=\"sigmoid\", kernel_initializer='random_uniform', bias_initializer='zeros')(x)  \n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['binary_accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experimento 1\n\nJuega con distintos tamaños de red para ver como esto afecta el desempeño del modelo (Vas a poder ver el impacto en las graficas de perdida, binary_accuracy y valor de AUC)\n\nVas a poder comparar valores utilizando el Experimento 1 y 2 al mismo tiempo."},{"metadata":{"trusted":true},"cell_type":"code","source":"arquitectura1 = [1200,1800]\nmodel1 = func_model(arquitectura1)\n#Para revisar la estructura del modelo, quitar el comentario de la instruccion siguiente:\n#print(model1.summary())\ntrain_history_tam1 = model1.fit(train_dfX, train_dfY, batch_size=512, epochs=epochs, validation_data=(val_dfX, val_dfY), verbose=0)\ngraf_model(train_history_tam1)\nprecision(model1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experimento 2"},{"metadata":{"trusted":true,"_uuid":"146e6ab223886364920dd8570b0d59b2274b5894"},"cell_type":"code","source":"arquitectura2 = [900,500,800]\nmodel2 = func_model(arquitectura2)\n#print(model2.summary())\ntrain_history_tam2 = model2.fit(train_dfX, train_dfY, batch_size=512, epochs=epochs, validation_data=(val_dfX, val_dfY))\ngraf_model(train_history_tam2)\nprecision(model2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resultado Final\n\nElije una arquitectura de red que te permita tener el valor de AUC mas alto que puedas lograr\n\n **Ejecuta esta celda 1 sola vez con la arquitectura final elegida en los experimentos anteriores**"},{"metadata":{"trusted":true},"cell_type":"code","source":"arquitecturaFinal = [900,500,800]\nmodelF = func_model(arquitecturaFinal)\nprint(modelF.summary())\ntrain_history_tamF = modelF.fit(train_dfX, train_dfY, batch_size=512, epochs=epochs, validation_data=(val_dfX, val_dfY))\ngraf_model(train_history_tamF)\nprecision(modelF, True)\nassert(len(precisiones_globales)==2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Regularizacion de la Red. (Evaluado)\n\nEn el siguiente ejercicio vamos a experimentar con la regularizacion de nuestra red. La idea es que basado en la arquitectura \"optima\" que consiguieron en el apartado anterior empecemos a mejorar nuestro modelo. \n\nVamos a experimentar con distintos valores para el P del DropOut y aplicando o no regularizacion L2 en las distintas capas. Para agregar regularizacion L2 a una capa se debe colocar regularizers.l2(0.01) como parametro en kernel_regularizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"def func_model_reg():   \n    inp = Input(shape=(200,))\n    x=Dropout(0)(inp)\n    x=Dense(900, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01))(x)\n    x=Dropout(0)(x)\n    x=Dense(500, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros', kernel_regularizer=None)(x)\n    x=Dropout(0)(x)\n    x=Dense(800, activation=\"relu\", kernel_initializer='random_uniform', bias_initializer='zeros', kernel_regularizer=None)(x)\n    x=Dropout(0)(x)  \n    x=Dense(1, activation=\"sigmoid\", kernel_initializer='random_uniform', bias_initializer='zeros')(x) \n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['binary_accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experimento\n\nPrueba modificando la funcion de arriba para ver que resultados da sobre la precision."},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = func_model_reg()\n#Para revisar la estructura del modelo, quitar el comentario de la instruccion siguiente:\n#print(model1.summary())\ntrain_history_tam1 = model1.fit(train_dfX, train_dfY, batch_size=512, epochs=epochs, validation_data=(val_dfX, val_dfY), verbose=0)\ngraf_model(train_history_tam1)\nprecision(model1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resultado Final\n\nElije una arquitectura de red que te permita tener el valor de AUC mas alto que puedas lograr\n\n **Ejecuta esta celda 1 sola vez con la arquitectura final elegida en los experimentos anteriores**"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRF = func_model_reg()\nprint(modelRF.summary())\ntrain_history_regF = modelRF.fit(train_dfX, train_dfY, batch_size=512, epochs=epochs, validation_data=(val_dfX, val_dfY))\ngraf_model(train_history_regF)\nprecision(modelRF, True)\nassert(len(precisiones_globales)==3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo Final.\n\nJuega con el modelo y genera el mejor valor de AUC que puedas lograr. "},{"metadata":{},"cell_type":"markdown","source":"# Salida de datos.\n\nCon esta celda se exportaran los datos.\n\n"},{"metadata":{"trusted":true,"_uuid":"5f9794aa253268b327dfa47d39bcbee522802066"},"cell_type":"code","source":"y_test = model.predict(test_df)\nsubmission['target'] = y_test\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}