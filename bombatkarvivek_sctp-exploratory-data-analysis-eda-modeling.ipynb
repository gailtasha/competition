{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SANTANDER CUSTOMER TRANSACTION PREDICTION\n\n**BHAVESHKUMAR THAKER**"},{"metadata":{},"cell_type":"markdown","source":"## INTRODUCTION\n\nIn this challenge, Santander invites Kagglers to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data they have available to solve this problem.\n\nThe data is anonimyzed, each row containing 200 numerical values identified just with a number."},{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#SANTANDER-CUSTOMER-TRANSACTION-PREDICTION\" data-toc-modified-id=\"SANTANDER-CUSTOMER-TRANSACTION-PREDICTION-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>SANTANDER CUSTOMER TRANSACTION PREDICTION</a></span><ul class=\"toc-item\"><li><span><a href=\"#INTRODUCTION\" data-toc-modified-id=\"INTRODUCTION-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>INTRODUCTION</a></span></li></ul></li><li><span><a href=\"#LOAD-PACKAGES\" data-toc-modified-id=\"LOAD-PACKAGES-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LOAD PACKAGES</a></span></li><li><span><a href=\"#DEFINE-GENERIC-COMMON-METHODS\" data-toc-modified-id=\"DEFINE-GENERIC-COMMON-METHODS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DEFINE GENERIC COMMON METHODS</a></span></li><li><span><a href=\"#LOAD-DATA-AND-PERFORM-ANALYSIS\" data-toc-modified-id=\"LOAD-DATA-AND-PERFORM-ANALYSIS-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LOAD DATA AND PERFORM ANALYSIS</a></span><ul class=\"toc-item\"><li><span><a href=\"#ANALYSE-TRAIN-DATA\" data-toc-modified-id=\"ANALYSE-TRAIN-DATA-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>ANALYSE TRAIN DATA</a></span></li><li><span><a href=\"#ANALYSE-TEST-DATA\" data-toc-modified-id=\"ANALYSE-TEST-DATA-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>ANALYSE TEST DATA</a></span></li></ul></li><li><span><a href=\"#PERFORM-EXPLORATORY-DATA-ANALYSIS-(EDA)\" data-toc-modified-id=\"PERFORM-EXPLORATORY-DATA-ANALYSIS-(EDA)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>PERFORM EXPLORATORY DATA ANALYSIS (EDA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#UNDERSTANDING-DISTRIBUTION-OF-FEATURE(S)\" data-toc-modified-id=\"UNDERSTANDING-DISTRIBUTION-OF-FEATURE(S)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>UNDERSTANDING DISTRIBUTION OF FEATURE(S)</a></span></li><li><span><a href=\"#UNDERSTANDING-TARGET-VARIABLE\" data-toc-modified-id=\"UNDERSTANDING-TARGET-VARIABLE-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>UNDERSTANDING TARGET VARIABLE</a></span></li></ul></li><li><span><a href=\"#FEATURE-ENGINEERING\" data-toc-modified-id=\"FEATURE-ENGINEERING-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>FEATURE ENGINEERING</a></span><ul class=\"toc-item\"><li><span><a href=\"#UP-SAMPLE-MINORITY-CLASS-(TARGET)-TO-BALANCE-DATA\" data-toc-modified-id=\"UP-SAMPLE-MINORITY-CLASS-(TARGET)-TO-BALANCE-DATA-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>UP-SAMPLE MINORITY CLASS (TARGET) TO BALANCE DATA</a></span></li><li><span><a href=\"#SEPERATE-DATA-AND-TARGET-FEATURES\" data-toc-modified-id=\"SEPERATE-DATA-AND-TARGET-FEATURES-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>SEPERATE DATA AND TARGET FEATURES</a></span></li><li><span><a href=\"#CORRELATION-MATRIX\" data-toc-modified-id=\"CORRELATION-MATRIX-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>CORRELATION MATRIX</a></span></li></ul></li><li><span><a href=\"#MODELING\" data-toc-modified-id=\"MODELING-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>MODELING</a></span><ul class=\"toc-item\"><li><span><a href=\"#BINOMIAL-CLASSIFICATION:-Using-LGBMClassifier-with-BayesSearchCV\" data-toc-modified-id=\"BINOMIAL-CLASSIFICATION:-Using-LGBMClassifier-with-BayesSearchCV-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>BINOMIAL CLASSIFICATION: Using <strong>LGBMClassifier</strong> with BayesSearchCV</a></span><ul class=\"toc-item\"><li><span><a href=\"#PERFORM-CLASSIFICATION\" data-toc-modified-id=\"PERFORM-CLASSIFICATION-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>PERFORM CLASSIFICATION</a></span></li></ul></li><li><span><a href=\"#BINOMIAL-CLASSIFICATION:-Using-XGBClassifier-with-BayesSearchCV\" data-toc-modified-id=\"BINOMIAL-CLASSIFICATION:-Using-XGBClassifier-with-BayesSearchCV-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>BINOMIAL CLASSIFICATION: Using <strong>XGBClassifier</strong> with BayesSearchCV</a></span><ul class=\"toc-item\"><li><span><a href=\"#PERFORM-CLASSIFICATION\" data-toc-modified-id=\"PERFORM-CLASSIFICATION-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>PERFORM CLASSIFICATION</a></span></li></ul></li></ul></li><li><span><a href=\"#COMPARE-MODELS\" data-toc-modified-id=\"COMPARE-MODELS-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>COMPARE MODELS</a></span></li><li><span><a href=\"#PREDICTIONS-OF-TEST-DATA\" data-toc-modified-id=\"PREDICTIONS-OF-TEST-DATA-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>PREDICTIONS OF TEST DATA</a></span></li></ul></div>"},{"metadata":{},"cell_type":"markdown","source":"# LOAD PACKAGES"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nnotebookstart = time.time()\nnotebookstart","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter(action='ignore', category=DeprecationWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import platform\nimport sys\nimport importlib\nimport multiprocessing\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nrandom.seed(321)\nnp.random.seed(321)\n\npd.options.display.max_columns = 9999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport matplotlib.colors as mcolors\n\n%matplotlib inline\n\nmpl.rc('figure', figsize=(15, 12))\nplt.figure(figsize=(15, 12))\nplt.rcParams['figure.facecolor'] = 'azure'\nmpl.style.use('seaborn')\nplt.style.use('seaborn')\n\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.set(rc={'figure.figsize': (15, 12)})\nsns.set(context='notebook', style='darkgrid', font='sans-serif',\n        font_scale=1.1, rc={'figure.facecolor': 'azure',\n        'axes.facecolor': 'azure', 'grid.color': 'steelblue'})\nsns.color_palette(mcolors.TABLEAU_COLORS);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\n\nfrom sklearn.model_selection import train_test_split, \\\n    cross_val_predict, cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit, \\\n    StratifiedKFold, GridSearchCV\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, \\\n    RobustScaler, MaxAbsScaler, Normalizer\nfrom sklearn.preprocessing import LabelBinarizer, label_binarize\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, \\\n    classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.metrics import average_precision_score, \\\n    precision_recall_fscore_support\n\nfrom sklearn.utils import shuffle, resample\nfrom sklearn.base import BaseEstimator, ClassifierMixin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgbm\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import catboost\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import skopt\nfrom skopt import BayesSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import imblearn\nfrom imblearn.over_sampling import SMOTE, SMOTENC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Operating system version........', platform.platform())\nprint('Python version is............... %s.%s.%s' % sys.version_info[:3])\nprint('scikit-learn version is.........', sklearn.__version__)\nprint('pandas version is...............', pd.__version__)\nprint('numpy version is................', np.__version__)\nprint('matplotlib version is...........', mpl.__version__)\nprint('seaborn version is..............', sns.__version__)\nprint('scikit-plot version is..........', skplt.__version__)\nprint('missingno version is............', msno.__version__)\nprint('xgboost version is..............', xgb.__version__)\nprint('catboost version is.............', catboost.__version__)\nprint('lightgbm version is.............', lgbm.__version__)\nprint('scikit-optimize version is......', skopt.__version__)\nprint('imblearn version is.............', imblearn.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DEFINE GENERIC COMMON METHODS"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getDatasetInformation(csv_filepath, is_corr_required=True):\n    \"\"\"\n    Read CSV (comma-separated) file into DataFrame\n    \n    Returns,\n    - DataFrame\n    - DataFrame's shape\n    - DataFrame's data types\n    - DataFrame's describe\n    - DataFrame's sorted unique value count\n    - DataFrame's missing or NULL value count\n    - DataFrame's correlation between numerical columns\n    \"\"\"\n\n    dataset_tmp = pd.read_csv(csv_filepath)\n\n    dataset_tmp_shape = pd.DataFrame(list(dataset_tmp.shape),\n            index=['No of Rows', 'No of Columns'], columns=['Total'])\n    dataset_tmp_shape = dataset_tmp_shape.reset_index()\n\n    dataset_tmp_dtypes = dataset_tmp.dtypes.reset_index()\n    dataset_tmp_dtypes.columns = ['Column Names', 'Column Data Types']\n\n    dataset_tmp_desc = pd.DataFrame(dataset_tmp.describe())\n    dataset_tmp_desc = dataset_tmp_desc.transpose()\n\n    dataset_tmp_unique = dataset_tmp.nunique().reset_index()\n    dataset_tmp_unique.columns = ['Column Name', 'Unique Value(s) Count'\n                                  ]\n\n    dataset_tmp_missing = dataset_tmp.isnull().sum(axis=0).reset_index()\n    dataset_tmp_missing.columns = ['Column Names',\n                                   'NULL value count per Column']\n    dataset_tmp_missing = \\\n        dataset_tmp_missing.sort_values(by='NULL value count per Column'\n            , ascending=False)\n\n    if is_corr_required:\n        dataset_tmp_corr = dataset_tmp.corr(method='spearman')\n    else:\n        dataset_tmp_corr = pd.DataFrame()\n\n    return [\n        dataset_tmp,\n        dataset_tmp_shape,\n        dataset_tmp_dtypes,\n        dataset_tmp_desc,\n        dataset_tmp_unique,\n        dataset_tmp_missing,\n        dataset_tmp_corr,\n        ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getHighlyCorrelatedColumns(dataset, NoOfCols=6):\n    df_corr = dataset.corr()\n\n    # set the correlations on the diagonal or lower triangle to zero,\n    # so they will not be reported as the highest ones\n\n    df_corr *= np.tri(k=-1, *df_corr.values.shape).T\n    df_corr = df_corr.stack()\n    df_corr = \\\n        df_corr.reindex(df_corr.abs().sort_values(ascending=False).index).reset_index()\n    return df_corr.head(NoOfCols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createFeatureEngineeredColumns(dataset):\n    dataset_tmp = pd.DataFrame()\n\n    dataset_tmp['CountOfZeroValues'] = (dataset == 0).sum(axis=1)\n    dataset_tmp['CountOfNonZeroValues'] = (dataset != 0).sum(axis=1)\n\n    weight = ((dataset != 0).sum() / len(dataset)).values\n    dataset_tmp['WeightedCount'] = (dataset * weight).sum(axis=1)\n\n    dataset_tmp['SumOfValues'] = dataset.sum(axis=1)\n\n    dataset_tmp['VarianceOfValues'] = dataset.var(axis=1)\n    dataset_tmp['MedianOfValues'] = dataset.median(axis=1)\n    dataset_tmp['MeanOfValues'] = dataset.mean(axis=1)\n    dataset_tmp['StandardDeviationOfValues'] = dataset.std(axis=1)\n    #dataset_tmp['ModeOfValues'] = dataset.mode(axis=1)\n    dataset_tmp['SkewOfValues'] = dataset.skew(axis=1)\n    dataset_tmp['KurtosisOfValues'] = dataset.kurtosis(axis=1)\n\n    dataset_tmp['MaxOfValues'] = dataset.max(axis=1)\n    dataset_tmp['MinOfValues'] = dataset.min(axis=1)\n    dataset_tmp['DiffOfMinMaxOfValues'] = \\\n        np.subtract(dataset_tmp['MaxOfValues'],\n                    dataset_tmp['MinOfValues'])\n\n    dataset_tmp['QuantilePointFiveOfValues'] = dataset[dataset\n            > 0].quantile(0.5, axis=1)\n\n    dataset = pd.concat([dataset, dataset_tmp], axis=1)\n\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getZeroStdColumns(dataset):\n    columnsWithZeroStd = dataset.columns[dataset.std() == 0].tolist()\n    return columnsWithZeroStd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getUniqueValueColumns(dataset, valueToCheck=0):\n    columnsWithUniqueValue = dataset.columns[dataset.nunique()\n            == valueToCheck].tolist()\n    return columnsWithUniqueValue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotCategoricalVariableDistributionGraph(target_value, title='', xticksrotation=0):\n    tmp_count = target_value.value_counts()\n    \n    fig=plt.figure()\n    fig.suptitle(title, fontsize=18)\n    \n    ax1=fig.add_subplot(221)\n    sns.pointplot(x=tmp_count.index, y=tmp_count, ax=ax1)\n    ax1.set_title('Distribution Graph')\n    plt.xticks(rotation=xticksrotation)\n    \n    ax2=fig.add_subplot(222)\n    sns.barplot(x=tmp_count.index, y=tmp_count, ax=ax2)\n    ax2.set_title('Distribution Graph - Bar')\n    plt.xticks(rotation=xticksrotation)\n    \n    ax3=fig.add_subplot(212)\n    ax3.pie(tmp_count, labels=tmp_count.index, autopct=\"%1.1f%%\", shadow=True, startangle=195)\n    ax3.axis('equal')\n    ax3.set_title('Distribution Graph - Pie')\n    \n    fig.tight_layout()\n    fig.subplots_adjust(top=0.90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distplot(dataset):\n    colors = mcolors.TABLEAU_COLORS\n\n    dataset_fordist = dataset.select_dtypes([np.int, np.float])\n    number_of_subplots = len(dataset_fordist.columns)\n    number_of_columns = 3\n\n    number_of_rows = number_of_subplots // number_of_columns\n    number_of_rows += number_of_subplots % number_of_columns\n\n    postion = range(1, number_of_subplots + 1)\n\n    fig = plt.figure(1)\n    for k in range(number_of_subplots):\n        ax = fig.add_subplot(number_of_rows, number_of_columns,\n                             postion[k])\n        sns.distplot(dataset_fordist.iloc[:, k],\n                     color=random.choice(list(colors.keys())), ax=ax)\n    fig.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convertIntFloatToInt(dictObj):\n    for (k, v) in dictObj.items():\n        if float('Inf') == v:\n            pass\n        elif int(v) == v and isinstance(v, float):\n            dictObj[k] = int(v)\n    return dictObj","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LOAD DATA AND PERFORM ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"(\n    dataset_sctp_train,\n    df_train_shape,\n    df_train_dtypes,\n    df_train_describe,\n    df_train_unique,\n    df_train_missing,\n    df_train_corr,\n    ) = getDatasetInformation('../input/train.csv', False)\n\n(\n    dataset_sctp_test,\n    df_test_shape,\n    df_test_dtypes,\n    df_test_describe,\n    df_test_unique,\n    df_test_missing,\n    df_test_corr,\n    ) = getDatasetInformation('../input/test.csv', False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ANALYSE TRAIN DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(dataset_sctp_train, color=(33 / 255, 102 / 255, 172 / 255));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ANALYSE TEST DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(dataset_sctp_test, color=(33 / 255, 102 / 255, 172 / 255));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(df_train_shape, df_train_dtypes, df_train_describe, df_train_unique, df_train_missing, df_train_corr)\ndel(df_test_shape, df_test_dtypes, df_test_describe, df_test_unique, df_test_missing, df_test_corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PERFORM EXPLORATORY DATA ANALYSIS (EDA)"},{"metadata":{},"cell_type":"markdown","source":"## UNDERSTANDING DISTRIBUTION OF FEATURE(S)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 2:29])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 29:56])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 56:83])","execution_count":null,"outputs":[]},{"metadata":{"inputHidden":false,"outputHidden":false,"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 83:110])","execution_count":null,"outputs":[]},{"metadata":{"inputHidden":false,"outputHidden":false,"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 110:137])","execution_count":null,"outputs":[]},{"metadata":{"inputHidden":false,"outputHidden":false,"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 137:164])","execution_count":null,"outputs":[]},{"metadata":{"inputHidden":false,"outputHidden":false,"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 164:191])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distplot(dataset_sctp_train.iloc[:, 191:204])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## UNDERSTANDING TARGET VARIABLE"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_train.target.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotCategoricalVariableDistributionGraph(dataset_sctp_train.target, 'Target (feature) - Distribution', xticksrotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FEATURE ENGINEERING"},{"metadata":{},"cell_type":"markdown","source":"## UP-SAMPLE MINORITY CLASS (TARGET) TO BALANCE DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_train_majority = dataset_sctp_train[dataset_sctp_train.target==0]\ndataset_sctp_train_minority = dataset_sctp_train[dataset_sctp_train.target==1]\n\ndataset_sctp_train_minority_upsampled = resample(dataset_sctp_train_minority, replace=True, n_samples=100000,)\n\ndataset_sctp_train_upsampled = pd.concat([dataset_sctp_train_majority, dataset_sctp_train_minority_upsampled])\ndataset_sctp_train_upsampled.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotCategoricalVariableDistributionGraph(dataset_sctp_train_upsampled.target, 'Target (feature) - Distribution', xticksrotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SEPERATE DATA AND TARGET FEATURES"},{"metadata":{"trusted":true},"cell_type":"code","source":"#y=dataset_sctp_train['target']\n#X=dataset_sctp_train.drop(['ID_code', 'target'], axis=1)\n\ny=dataset_sctp_train_upsampled['target']\nX=dataset_sctp_train_upsampled.drop(['ID_code', 'target'], axis=1)\n\ndataset_sctp_test_ID_code = dataset_sctp_test['ID_code']\ndataset_sctp_test.drop(['ID_code'], axis=1, inplace=True)\n\n(X.shape, y.shape, dataset_sctp_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CORRELATION MATRIX"},{"metadata":{},"cell_type":"raw","source":"df_train_corr = X.corr(method='spearman')\ndf_train_corr"},{"metadata":{},"cell_type":"raw","source":"#mask = np.zeros_like(df_train_corr, dtype=np.bool)\n#mask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(\n    df_train_corr,\n    cmap='rainbow',\n    annot=False,\n    fmt='.2f',\n    center=0,\n    square=False,\n    linewidths=.75,\n    #mask=mask,\n    );\nplt.title('Correlation Matrix', fontsize=18)\nplt.show()"},{"metadata":{"trusted":true},"cell_type":"code","source":"getHighlyCorrelatedColumns(X, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"upper = df_train_corr.where(np.triu(np.ones(df_train_corr.shape), k=1).astype(np.bool))\n\nto_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n\nprint(f'Columns to drop from Train and Test datasets are {to_drop}.')\n\nX.drop(columns=to_drop, axis=1, inplace=True)\ndataset_sctp_test.drop(columns=to_drop, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=createFeatureEngineeredColumns(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_test=createFeatureEngineeredColumns(dataset_sctp_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X.shape, dataset_sctp_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columnsWithZeroStdToRemove = getZeroStdColumns(X)\nprint(f'Columns with Zero STD to drop from Train and Test dataset(s) are {columnsWithZeroStdToRemove}.')\n\nX.drop(columnsWithZeroStdToRemove, axis=1, inplace=True)\ndataset_sctp_test.drop(columnsWithZeroStdToRemove, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_columns_one_unique_value = getUniqueValueColumns(X, 1)\nprint(f'Columns with only 1 as value to drop from Train and Test datasets are {X_columns_one_unique_value}.')\n\nX.drop(X_columns_one_unique_value, axis=1, inplace=True)\ndataset_sctp_test.drop(X_columns_one_unique_value, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_columns_zero_unique_value = getUniqueValueColumns(X, 0)\nprint(f'Columns with only 0 as value to drop from Train and Test datasets are {X_columns_zero_unique_value}.')\n\nX.drop(X_columns_zero_unique_value, axis=1, inplace=True)\ndataset_sctp_test.drop(X_columns_zero_unique_value, axis=1, inplace=True)\n\n(X.shape, dataset_sctp_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"del(df_train_corr)"},{"metadata":{},"cell_type":"markdown","source":"# MODELING"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_cpus_avaliable = multiprocessing.cpu_count()\n\nprint(f'We\\'ve got {n_cpus_avaliable} cpus to work with.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_scores = pd.DataFrame(columns=['Classification_Type', 'Model_Name',\n                            'Accuracy_Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n        test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BINOMIAL CLASSIFICATION: Using **LGBMClassifier** with BayesSearchCV"},{"metadata":{},"cell_type":"markdown","source":"### PERFORM CLASSIFICATION"},{"metadata":{"scrolled":false},"cell_type":"raw","source":"def lgbm_status_print_twoclass(optimal_result):\n    all_models = pd.DataFrame(lgbm_bayes_cv_tuner_twoclass.cv_results_)\n    best_params = pd.Series(lgbm_bayes_cv_tuner_twoclass.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(len(all_models),\n            np.round(lgbm_bayes_cv_tuner_twoclass.best_score_, 4),\n            lgbm_bayes_cv_tuner_twoclass.best_params_)\n         )\n\n\nlgbm_bayes_cv_tuner_twoclass = BayesSearchCV(\n    estimator=lgbm.LGBMClassifier(n_jobs=n_cpus_avaliable,\n                                  objective='binary',\n                                  metric='binary_logloss',\n                                  #is_unbalance=True,\n                                  class_weight='balanced',\n                                  silent=True),\n    search_spaces={\n        #'boosting_type': ['gbdt', 'dart', 'rf'],\n        'num_leaves': (1, 50),\n        'max_depth': (1, 40),\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'n_estimators': (100, 300),\n        'min_split_gain': (0.01, 1.0, 'uniform'),\n        'min_child_weight': (0.01, 1.0, 'uniform'),\n        'min_child_samples': (1, 10),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'subsample_freq': (1, 50),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        #'bagging_fraction': (0.01, 1.0, 'uniform'),     # OR subsample\n        #'feature_fraction': (0.01, 1.0, 'uniform'),     # OR colsample_bytree\n        },\n    scoring='roc_auc',\n    cv=StratifiedKFold(n_splits=13, shuffle=True),\n    n_jobs=n_cpus_avaliable,\n    n_iter=9,\n    refit=True,\n    verbose=0,\n    )\n\n\nlgbm_result_twoclass = lgbm_bayes_cv_tuner_twoclass.fit(X, y, \n        callback=lgbm_status_print_twoclass)\n\nlgbm_twoclass_model = lgbm_result_twoclass.best_estimator_\n\nprint(lgbm_twoclass_model)"},{"metadata":{"scrolled":false},"cell_type":"raw","source":"y_pred = lgbm_twoclass_model.predict(X_test)\ny_pred_proba = lgbm_twoclass_model.predict_proba(X_test)\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the LightGBM (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': lgbm_twoclass_model.__class__.__name__ + ' - BayesSearchCV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (LightGBM Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_precision_recall(y_test, y_pred_proba,\n                                    title='Binomial Classification (LightGBM Precision-Recall Curve)',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_roc(y_test, y_pred_proba,\n                       title='Binomial Classification (LightGBM ROC Curves)',\n                      );"},{"metadata":{},"cell_type":"raw","source":"feature_importance = pd.DataFrame({'imp': lgbm_twoclass_model.feature_importances_, 'col': X_train.columns})\nfeature_importance = feature_importance.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\nfeature_importance.plot(kind='barh', x='col', y='imp', color=mcolors.TABLEAU_COLORS);\nplt.title('Binomial Classification (LightGBM - Feature Importance(s))', fontsize=18)\nplt.show()"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_train_lgbm = lgbm.Dataset(data=X, label=y)\ndataset_sctp_test_lgbm = lgbm.Dataset(data=X_test, label=y_test)\nwatchlist = [dataset_sctp_train_lgbm, dataset_sctp_test_lgbm]\n\nevaluation_results = {}\n\nlgbmparams = {\n    'boosting_type': 'gbdt',\n    'class_weight': 'balanced',\n    'colsample_bytree': 0.8220008732467731,\n    'importance_type': 'split',\n    'learning_rate': 0.6161285857013439,\n    'max_depth': 33,\n    'metric': 'binary_logloss',\n    'min_child_samples': 9,\n    'min_child_weight': 0.7823020109077508,\n    'min_split_gain': 0.7211200712627109,\n    'n_estimators': 295,\n    'n_jobs': n_cpus_avaliable,\n    'num_leaves': 41,\n    'objective': 'binary',\n    'reg_alpha': 0.0,\n    'reg_lambda': 0.002053077897015527,\n    'silent': False,\n    'subsample': 0.6820394902275151,\n    'subsample_for_bin': 200000,\n    'subsample_freq': 8,\n    }\n\nlgbm_twoclass_model = lgbm.train(\n    lgbmparams,\n    train_set=dataset_sctp_train_lgbm,\n    num_boost_round=5000,\n    valid_sets=watchlist,\n    early_stopping_rounds=120,\n    evals_result=evaluation_results,\n    verbose_eval=100,\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = lgbm_twoclass_model.predict(X_test)\ny_pred = [round(value) for value in y_pred_proba]\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the LightGBM (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': lgbm_twoclass_model.__class__.__name__ + ' - BayesSearchCV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (LightGBM Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = lgbm.plot_metric(evaluation_results)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = lgbm.plot_importance(lgbm_twoclass_model, max_num_features=30, color=mcolors.TABLEAU_COLORS)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BINOMIAL CLASSIFICATION: Using **XGBClassifier** with BayesSearchCV"},{"metadata":{},"cell_type":"markdown","source":"### PERFORM CLASSIFICATION"},{"metadata":{},"cell_type":"raw","source":"def status_print_twoclass(optimal_result):\n    all_models = pd.DataFrame(bayes_cv_tuner_twoclass.cv_results_)\n    best_params = pd.Series(bayes_cv_tuner_twoclass.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(len(all_models), \n            np.round(bayes_cv_tuner_twoclass.best_score_, 4), \n            bayes_cv_tuner_twoclass.best_params_)\n         )\n\n\nbayes_cv_tuner_twoclass = BayesSearchCV(\n    estimator=xgb.XGBClassifier(\n        n_jobs=n_cpus_avaliable,\n        objective='binary:logistic',\n        eval_metric='auc',\n        silent=1,\n        tree_method='approx',\n        device='cpu',\n        ),\n    search_spaces={\n        #'booster': ['gbtree', 'dart'],\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'max_delta_step': (0, 20),\n        'max_depth': (0, 40),\n        'min_child_weight': (0, 20),\n        'n_estimators': (200, 300),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        'gamma': (1e-9, 0.5, 'log-uniform'),\n        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n        },\n    scoring='roc_auc',\n    cv=StratifiedKFold(n_splits=13, shuffle=True),\n    n_jobs=n_cpus_avaliable,\n    n_iter=9,\n    refit=True,\n    verbose=0,\n    )\n\nresult_twoclass = bayes_cv_tuner_twoclass.fit(X, y,\n        callback=status_print_twoclass)\n\nxgb_twoclass_model = result_twoclass.best_estimator_\n\nprint(xgb_twoclass_model)"},{"metadata":{},"cell_type":"raw","source":"y_pred = xgb_twoclass_model.predict(X_test)\ny_pred_proba = xgb_twoclass_model.predict_proba(X_test)\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the XGBoost (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': xgb_twoclass_model.__class__.__name__ + ' - BayesSearchCV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (XGBoost Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_precision_recall(y_test, y_pred_proba,\n                                    title='Binomial Classification (XGBoost Precision-Recall Curve)',\n                                   );\nprint('\\n')\n\nskplt.metrics.plot_roc(y_test, y_pred_proba,\n                       title='Binomial Classification (XGBoost ROC Curves)',\n                      );"},{"metadata":{},"cell_type":"raw","source":"feature_importance = pd.DataFrame({'imp': xgb_twoclass_model.feature_importances_, 'col': X_train.columns})\nfeature_importance = feature_importance.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\nfeature_importance.plot(kind='barh', x='col', y='imp', color=mcolors.TABLEAU_COLORS);\nplt.title('Binomial Classification (XGBoost - Feature Importance(s))', fontsize=18)\nplt.show()"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(X, label=y)\ndtest = xgb.DMatrix(X_test, label=y_test)\n\nwatchlist = [(dtrain, 'train'), (dtest, 'valid')]\n\nxgbparams = {\n    'base_score': 0.5,\n    'booster': 'gbtree',\n    'colsample_bylevel': 0.48973134715974026,\n    'colsample_bytree': 0.46131821596707184,\n    'device': 'cpu',\n    'eval_metric': 'auc',\n    'gamma': 8.0762512124703e-06,\n    'learning_rate': 0.054722068464825926,\n    'max_delta_step': 3,\n    'max_depth': 29,\n    'min_child_weight': 14,\n    'missing': 'None',\n    'n_estimators': 274,\n    'n_jobs': n_cpus_avaliable,\n    'objective': 'binary:logistic',\n    'reg_alpha': 0,\n    'reg_lambda': 2.1021696940800796,\n    'scale_pos_weight': 43.8858626195784,\n    'silent': True,\n    'subsample': 0.8113392946402368,\n    'tree_method': 'approx',\n    }\nxgb_twoclass_model = xgb.train(\n    xgbparams,\n    dtrain,\n    5000,\n    watchlist,\n    verbose_eval=200,\n    early_stopping_rounds=100,\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = xgb_twoclass_model.predict(dtest)\ny_pred = [round(value) for value in y_pred_proba]\n\nac = accuracy_score(y_test, y_pred)\nprint('The accuracy score of the XGBoost (Two Class) model is: {}%'.format(ac * 100))\nprint('\\n')\n\nmodel_scores = model_scores.append({'Classification_Type': 'Binomial',\n                                   'Model_Name': xgb_twoclass_model.__class__.__name__ + ' - CV',\n                                   'Accuracy_Score': '{:.4f}'.format(ac * 100)}, \n                                   ignore_index=True)\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\nprint('\\n')\n\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, title='Binomial Classification (XGBoost Confusion Matrix)',\n                                    x_tick_rotation=90, \n                                    cmap='Oranges',\n                                   );","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COMPARE MODELS"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_scores.Accuracy_Score = model_scores.Accuracy_Score.astype('float32')\nmodel_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Model_Name', y='Accuracy_Score', data=model_scores);\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREDICTIONS OF TEST DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"sctp_predictions_lgbm = lgbm_twoclass_model.predict(dataset_sctp_test)\nsctp_predictions_lgbm = [round(value) for value in sctp_predictions_lgbm]\nsctp_predictions_lgbm = list(map(int, sctp_predictions_lgbm))\nsctp_predictions_lgbm[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_submission = pd.DataFrame()\ndataset_submission['ID_code'] = dataset_sctp_test_ID_code\ndataset_submission['target'] = sctp_predictions_lgbm\ndataset_submission.to_csv('lgbm_twoclass_model_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_sctp_test_xgb = xgb.DMatrix(dataset_sctp_test)\nsctp_predictions_xgb = xgb_twoclass_model.predict(dataset_sctp_test_xgb)\nsctp_predictions_xgb = [round(value) for value in sctp_predictions_xgb]\nsctp_predictions_xgb = list(map(int, sctp_predictions_xgb))\nsctp_predictions_xgb[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_submission = pd.DataFrame()\ndataset_submission['ID_code'] = dataset_sctp_test_ID_code\ndataset_submission['target'] = sctp_predictions_xgb\ndataset_submission.to_csv('xgb_twoclass_model_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))","execution_count":null,"outputs":[]}],"metadata":{"kernel_info":{"name":"python3"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"0.12.3"},"toc":{"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"232.188px"},"skip_h1_title":false,"number_sections":true,"title_cell":"Table of Contents","toc_window_display":true,"base_numbering":1,"toc_section_display":true,"title_sidebar":"Contents","toc_cell":true,"nav_menu":{},"sideBar":true}},"nbformat":4,"nbformat_minor":1}