{"cells":[{"metadata":{"_uuid":"5721a548bb9a38031c4a1ab9e13539e7d2f27698","trusted":true},"cell_type":"code","source":"def add_columns(df):\n    for col in df.columns:\n        # Normalize the data, so that it can be used in norm.cdf(), as though it is a standard normal variable\n        df[col] = ((df[col] - df[col].mean()) / df[col].std()).astype('float32')\n\n        # Square\n        df[col+'_s'] = df[col] * df[col]\n\n        # Cube\n        df[col+'_c'] = df[col] * df[col] * df[col]\n\n        # 4th power\n        df[col+'_q'] = df[col] * df[col] * df[col] * df[col]\n\n        # Cumulative percentile (not normalized)\n        df[col+'_r'] = rankdata(df[col]).astype('float32')\n\n        # Cumulative normal percentile\n        df[col+'_n'] = norm.cdf(df[col]).astype('float32')\n    for col in df.columns:\n        df[col] = ((df[col] - df[col].mean()) / df[col].std()).astype('float32')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea005def562ae65202ec9322bec60fd25a1961e1"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n## 1. Loading the data"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import rankdata\nimport lightgbm as lgb\nfrom sklearn import metrics\nimport gc\nimport warnings\nfrom scipy.stats import norm, rankdata\nfrom scipy.stats import norm, rankdata\nfrom sklearn.decomposition import PCA\n\npd.set_option('display.max_columns', 200)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5624fd428106888ec023312d3479d324ef0eac9","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\n\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba5573cfaec6625aed13e98c6e034809e2997b5b"},"cell_type":"markdown","source":"We are given anonymized dataset containing 200 numeric feature variables from var_0 to var_199. Let's have a look train dataset:"},{"metadata":{"_uuid":"7365ac9a050f611cb284bbb47519e04ac1ee19f9","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba5573cfaec6625aed13e98c6e034809e2997b5b"},"cell_type":"markdown","source":"Test dataset:"},{"metadata":{"_uuid":"93aa6148650a23671d5f01a834f948c5e6721234","trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26ef9192a9860f54cbcb58c64efad15af642da34","trusted":true},"cell_type":"code","source":"target = train_df.target\nID_code = test_df.ID_code\n\ntrain_df = train_df.drop('target',axis = 1)\ntrain_df = train_df.drop('ID_code',axis=1)\ntest_df = test_df.drop('ID_code',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=1, copy=True,  random_state=4)\npca.fit(pd.concat([train_df,test_df]))\n\nP1 = pca.transform(train_df)\nP2 = pca.transform(test_df)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37982c471330c4a623dfc918a37597fb935d1d12","trusted":true},"cell_type":"code","source":"len_train = len(train_df)\ndf = pd.concat([train_df,test_df])\nadd_columns(df)\n\ntrain_df = df[:len_train]\ntest_df = df[len_train:]\ndel df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['P1'] = P1[:,0]\ntest_df['P1'] = P2[:,0]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba5573cfaec6625aed13e98c6e034809e2997b5b"},"cell_type":"markdown","source":"Distribution of target variable"},{"metadata":{"_uuid":"6f7cd5bdd625e69c75e10f586a826da80c814cdf","trusted":true},"cell_type":"code","source":"predictors = train_df.columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"496907f42901e10bb883858252b2783e30ff2e43"},"cell_type":"markdown","source":"In this kernel I will be using **50% Stratified rows** as holdout rows for the validation-set to get optimal parameters. Later I will use 5 fold cross validation in the final model fit."},{"metadata":{"_uuid":"7ec87a3460c6358b9a134afea5bac561f7a84226","trusted":true},"cell_type":"code","source":"bayesian_tr_index, bayesian_val_index  = list(StratifiedKFold(n_splits=2, shuffle=True, random_state=1).split(train_df, target))[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbcebd0aacaeb637a1e119971303c9fcd60f9ea5"},"cell_type":"markdown","source":"These `bayesian_tr_index` and `bayesian_val_index` indexes will be used for the bayesian optimization as training and validation index of training dataset."},{"metadata":{"_uuid":"c2893bc7de2bf69fd02ef26e90fc354f71b83e10"},"cell_type":"markdown","source":"OK, by default these will be explored lazily (lazy=True), meaning these points will be evaluated only the next time you call maximize. Let's do a maximize call of `LGB_BO` object."},{"metadata":{"_uuid":"b91db8b5c98da4f014f1863ba7de18e241f517c6"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n## 3. Training LightGBM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# bayes_params ={'feature_fraction': 0.058874549652091476,\n#  'lambda_l1': 3.953340038056426,\n#  'lambda_l2': 3.1010968272896537,\n#  'learning_rate': 0.014946929978539511,\n#  'max_depth': 19.47829334300404,\n#  'min_data_in_leaf': 19.88287907569752,\n#  'min_gain_to_split': 0.9527282592922265,\n#  'min_sum_hessian_in_leaf': 0.0027063753098792356,\n#  'num_leaves': 34.454229480072925}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# param_lgb = {\n#         'num_leaves': int(bayes_params['num_leaves']), # remember to int here\n#         'max_bin': 63,\n#         'min_data_in_leaf': int(bayes_params['min_data_in_leaf']), # remember to int here\n#         'learning_rate': bayes_params['learning_rate'],\n#         'min_sum_hessian_in_leaf': bayes_params['min_sum_hessian_in_leaf'],\n#         'bagging_fraction': 1.0, \n#         'bagging_freq': 5, \n#         'feature_fraction': bayes_params['feature_fraction'],\n#         'lambda_l1': bayes_params['lambda_l1'],\n#         'lambda_l2': bayes_params['lambda_l2'],\n#         'min_gain_to_split': bayes_params['min_gain_to_split'],\n#         'max_depth': int(bayes_params['max_depth']), # remember to int here\n#         'save_binary': True,\n#         'seed': 1337,\n#         'feature_fraction_seed': 1337,\n#         'bagging_seed': 1337,\n#         'drop_seed': 1337,\n#         'data_random_seed': 1337,\n#         'objective': 'binary',\n#         'boosting_type': 'gbdt',\n#         'verbose': 1,\n#         'metric': 'auc',\n#         'is_unbalance': True,\n#         'boost_from_average': False,\n#     }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56d006d366fc5c2686249887b5d1f302d4a708f5","trusted":true},"cell_type":"code","source":"# param_lgb = {\n#          'num_leaves': 6, # remember to int here\n#          'max_bin': 63,\n#          'min_data_in_leaf': 20, # remember to int here\n#          'learning_rate': 0.018,\n#          'min_sum_hessian_in_leaf': 0.009,\n#          'bagging_fraction': 1.0, \n#          'bagging_freq': 5, \n#          'feature_fraction': 0.075,\n#          'lambda_l1': 1.569,\n#          'lambda_l2': 3.9436,\n#          'min_gain_to_split': 0.0006,\n#          'max_depth': 20, # remember to int here\n#          'save_binary': True,\n#          'seed': 1337,\n#          'feature_fraction_seed': 1337,\n#          'bagging_seed': 1337,\n#          'drop_seed': 1337,\n#          'data_random_seed': 1337,\n#          'objective': 'binary',\n#          'boosting_type': 'gbdt',\n#          'verbose': 1,\n#          'metric': 'auc',\n#          'is_unbalance': True,\n#          'boost_from_average': False,\n#      }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#v8 bayes optimization https://www.kaggle.com/poppins/lgb-bayesian-parameters-finding-rank-average\nparams={'feature_fraction': 0.05303293150022274,\n 'lambda_l1': 4.742447900648306,\n 'lambda_l2': 3.797046693025151,\n 'learning_rate': 0.012061342816038765,\n 'max_depth': 14.202377588960745,\n 'min_data_in_leaf': 9.784931229481742,\n 'min_gain_to_split': 0.06340137767250764,\n 'min_sum_hessian_in_leaf': 0.00672958286082188,\n 'num_leaves': 14.036858809140814}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_lgb = {\n        'num_leaves': int(params['num_leaves']), # remember to int here\n        'max_bin': 63,\n        'min_data_in_leaf': int(params['min_data_in_leaf']), # remember to int here\n        'learning_rate': params['learning_rate'],\n        'min_sum_hessian_in_leaf': params['min_sum_hessian_in_leaf'],\n        'bagging_fraction': 1.0, \n        'bagging_freq': 5, \n        'feature_fraction': params['feature_fraction'],\n        'lambda_l1': params['lambda_l1'],\n        'lambda_l2': params['lambda_l2'],\n        'min_gain_to_split': params['min_gain_to_split'],\n        'max_depth': int(params['max_depth']), # remember to int here\n        'save_binary': True,\n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'auc',\n        'is_unbalance': True,\n        'boost_from_average': False,\n    }\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ab8ef627687c7602b81a9ac83f90ff3a2094d0c"},"cell_type":"markdown","source":"Number of Kfolds:"},{"metadata":{"_uuid":"9f306e20ae748715da17a2f15702ea1aa4d81497","trusted":true},"cell_type":"code","source":"nfold = 5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2f01a6006dcb34ffb53ca33a055e592ee9e75e1","trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e9f0fd37207aeaa33f3d758ed22a32b462fc93d","scrolled":true,"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"0e9f0fd37207aeaa33f3d758ed22a32b462fc93d","scrolled":true,"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(train_df))\npredictions = np.zeros((len(test_df),nfold))\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, target.values):\n    print(\"\\nfold {}\".format(i))\n    xg_train = lgb.Dataset(train_df.iloc[train_index][predictors].values,\n                           label=target.iloc[train_index].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    xg_valid = lgb.Dataset(train_df.iloc[valid_index][predictors].values,\n                           label=target.iloc[valid_index].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    \n    clf = lgb.train(param_lgb, xg_train, 10000, valid_sets = [xg_valid], verbose_eval=1000)\n    oof[valid_index] = clf.predict(train_df.iloc[valid_index][predictors].values, num_iteration=clf.best_iteration) \n    \n    predictions[:,i-1] += clf.predict(test_df[predictors], num_iteration=clf.best_iteration)\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.6f}\".format(metrics.roc_auc_score(target.values, oof)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6c8fde3d71858028688bd9a62bf1a4430b6bbb1"},"cell_type":"markdown","source":"So we got 0.90 AUC in 5 fold cross validation. And 5 fold prediction look like:"},{"metadata":{"_uuid":"a889d2c1f63dbe989b3f0b0373ce9e1c80e3ee10","trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01339e95305a72802fd23a2c740cb7cc988d1c27"},"cell_type":"markdown","source":"If you are still reading, bare with me. I will not take much of your time. :D We are almost done. Let's do a rank averaging on 5 fold predictions."},{"metadata":{"_uuid":"116f2c0c3c43095d456a88d50425de0a3e7fdd11"},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n## 4. Rank averaging"},{"metadata":{"_uuid":"6ec40259b4636edd2c336583c5eb5c62feaaaa31","trusted":true},"cell_type":"code","source":"print(\"Rank averaging on\", nfold, \"fold predictions\") \nrank_predictions = np.zeros((predictions.shape[0],1))\nfor i in range(nfold):\n    rank_predictions[:, 0] = np.add(rank_predictions[:, 0], rankdata(predictions[:, i].reshape(-1,1))/rank_predictions.shape[0]) \n\nrank_predictions /= nfold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74eea39312bae04f6542a2f557c0454eda19d2f3"},"cell_type":"markdown","source":"Let's submit prediction to Kaggle."},{"metadata":{"_uuid":"08a4c881ae24d784e9ee3c197d1188e26fdb40c7"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n## 5. Submission"},{"metadata":{"_uuid":"1fe8a68970387c8e57d373b4d0944731a32ccd51","trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame({\"ID_code\": ID_code.values})\nsub_df[\"target\"] = rank_predictions\nsub_df[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65cd74398d3f80186d65a2ff3431403a6846e229","trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"Customer_Transaction_rank_predictions.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba5573cfaec6625aed13e98c6e034809e2997b5b"},"cell_type":"markdown","source":"Do not forget to upvote :) Also fork and modify for your own use. ;)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}