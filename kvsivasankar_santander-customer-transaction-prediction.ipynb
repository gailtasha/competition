{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ndf_test=test.drop(['ID_code'], axis=1)\ndf_test = df_test.values\nunique_samples = []\nunique_count = np.zeros_like(df_test)\nfor feature in tqdm(range(df_test.shape[1])):\n    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n    unique_count[index_[count_ == 1], feature] += 1\n\n# Samples which have unique values are real the others are fake\nreal_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\nsynthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n\ndf_test_real = df_test[real_samples_indexes].copy()\ndf_test_real=pd.DataFrame(df_test_real)\ndf_test_real=df_test_real.add_prefix('var_')\ndf_test_real.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_value=train.drop(['ID_code', 'target'], axis=1)\ndf_combined=pd.concat([train_value, df_test_real])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_combined.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(25):\n    var='var_'+str(i)\n    if i%25==0:\n        print (i)\n    dictionary=df_combined[var].value_counts().to_dict()\n    train['count_'+var]=train[var].map(dictionary)\n    train['test_'+var]=train[var]*np.log2(train['count_'+var]+1)\n    train['test1_'+var]=train[var]/np.log2(train['count_'+var]+1)\n    train['test2_'+var]=train[var]*(-np.log2(train['count_'+var]+1))\n    train.drop('count_'+var, inplace=True, axis=1)\n    dictionary1=df_test_real[var].value_counts().to_dict()\n    test['count_'+var]=test[var].map(dictionary)\n    test['test_'+var]=np.log2(test['count_'+var]+1)*test[var]\n    test['test1_'+var]=test[var]/np.log2(test['count_'+var]+1)\n    test['test2_'+var]=test[var]*(-np.log2(test['count_'+var]+1))\n    test.drop('count_'+var, inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ID_code=test['ID_code']\nX_test = test.drop(['ID_code'],axis = 1)\n#X_test=X_test[X_test.columns[:200].append(X_test.columns[400:])]\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train['target']\nX = train.drop(['target', 'ID_code'], axis=1)\n#X=X[X.columns[:200].append(X.columns[400:])]\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in X.columns if c not in ['ID_code', 'target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import make_scorer, accuracy_score,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = RandomForestClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [4, 6, 9], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10], \n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1,5,8]\n             }\n\n# Type of scoring used to compare parameter combinations\nauc_scorer = make_scorer(roc_auc_score)\n\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters, scoring=auc_scorer)\ngrid_obj = grid_obj.fit(X.iloc[:1000,:], y[:1000])\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X.iloc[:1000,:], y[:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(X.iloc[:1000,:])\nprint(roc_auc_score(y[:1000], predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import make_scorer, accuracy_score,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n\n# Choose the type of classifier. \nclf = RandomForestClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [4, 6, 9], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10], \n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1,5,8]\n             }\n\n# Type of scoring used to compare parameter combinations\nauc_scorer = make_scorer(roc_auc_score)\n\n# Run the grid search\n\nrandom_search_obj = RandomizedSearchCV(clf, param_distributions=parameters,\n                                   n_iter=100, cv=5)\n\n#grid_obj = GridSearchCV(clf, parameters, scoring=auc_scorer)\nrandom_search_obj = random_search_obj.fit(X.iloc[:1000,:], y[:1000])\n\n# Set the clf to the best combination of parameters\nclf = random_search_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X.iloc[:1000,:], y[:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(X.iloc[:1000,:])\nprint(roc_auc_score(y[:1000], predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bayesian Optimization\nLink to original paper: https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf"},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer\n\n### make a scorer fn\nauc_scorer = make_scorer(roc_auc_score)\n\nX = X.iloc[:1000,:]\ny = y[:1000]\n\n### define obj\ndef objective(params):\n    params = {'n_estimators': int(params['n_estimators']), 'max_depth': int(params['max_depth'])}\n    clf = RandomForestClassifier(n_jobs=4, class_weight='balanced', **params)\n    score = cross_val_score(clf, X, y, scoring=auc_scorer, cv=StratifiedKFold()).mean()\n    print(\"Gini {:.3f} params {}\".format(score, params))\n    return -score\n\n### define search space\nspace = {\n    'n_estimators': hp.quniform('n_estimators', 25, 500, 25),  ### quniform defines how values will be sampled\n    'max_depth': hp.quniform('max_depth', 1, 10, 1)            ### there are other parameteric distributions also available\n}\n\n### put together\nbest = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=3)   ### increase for best results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Hyperopt estimated optimum {}\".format(best))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"bestParams = {'n_estimators': best['n_estimators'],\n              'max_depth': best['max_depth']\n             }\nbestModel = RandomForestClassifier(n_estimators = int(best['n_estimators']),max_depth= int(best['max_depth']))\n\nbestModel = bestModel.fit(X,y)\n\npredictions = bestModel.predict(X)\nprint(roc_auc_score(y, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = 5\nkf = StratifiedKFold(n_splits=folds)  \n#kf.get_n_splits(X,y)\n\n\n\n#scores = cross_val_score(model, X, Y, cv=5, scoring='r2')\n#print (scores,np.mean(scores))\n\nlr = LogisticRegression()\n#kf = KFold(n=data.shape[0], n_folds=5, shuffle=True, random_state=8)\n\naccuracies = cross_val_score(lr, X,y, scoring='accuracy', cv = kf)\nprint (accuracies,np.mean(accuracies))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}