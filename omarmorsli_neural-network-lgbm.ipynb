{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deep Learning + LGBM + Weighted Combination\n\nThis kernel will always be running with different parameters and approaches until before the competition deadline.\n\nFeel free to upvote,fork and test the presented models with different training options, to see if a better score with the following models is possible.\n\nIf forked Please try the different combinations:\n- Only Feature Engineering ( omitting some features maybe)\n- Only Augmented\n- Augmented + Feature Engineering (Augment before or after FE)\n- Augmented + Feature Engineering + folds\n- Augmented + Feature Engineering + full\n- Combination of different prediction weights\n- etc..\n\nYou can also check here for weighted CV approach that will make a minor better prediction that you might need in the competition:\nhttps://www.kaggle.com/hjd810/introducing-weighted-cross-validation\n\nEnjoy ! \n\nAny comments are appreciated (added motivation <3)\n\n1. [Training Options](#options)\n2. [Sampling](#sample)\n3. [Feature Engineering](#fe)\n4. [LGBM Model](#lgbm)\n5. [Keras Model](#keras)\n6. [Combination Vis](#vis)\n7. [Submission](#sub)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode()\nimport plotly.graph_objs as go\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation,Dropout, BatchNormalization\nfrom sklearn.model_selection import KFold,StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import  train_test_split\nfrom keras import backend as K\nfrom keras import optimizers\nimport keras as k\nimport time\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.utils import class_weight\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Running Models Options\n<a id='options'></a>\nThe options here helps you check the different combinations for training and check which fits best."},{"metadata":{"trusted":true},"cell_type":"code","source":"sampledf = False #Uses a specific amount of rows , use this for faster training and testing functionalities and features\nfrac_sample = 0.03 #fraction of the data to use\naugmnt = False #use an augmented data set\nfold_train = True\nagmnt_between = True #augment training data between folds\nkfold_shuffle = False\nuse_perc = True #using percentiles in feature engineering\n#--------------------------------------------------------------\n#Keras options\n#Weighted Classes when training \nweighted = False\nbalanced = False #balanced weights\n#-------------------\n#train test Split\ntst_size = 0.3\n\nsub_name = 'submission'\nprint('Options Active: \\n\\t SampledDF: {} frac: {} \\n\\t Augmentation: {}\\n\\t Weighted: {}\\n\\t Balanced: {}\\\n      \\n\\t agmnt_between:{}\\n\\t Percentiles: {}'.format(sampledf,frac_sample,augmnt,weighted,balanced,agmnt_between,use_perc))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%time\ndf_t = pd.read_csv('../input/train.csv')\ndf_tst = pd.read_csv('../input/test.csv')\n\nif sampledf:\n    sub_name = sub_name+'_sampled'\n    df_train = df_t.sample(frac=(frac_sample))\n    df_test = df_tst.sample(frac=(frac_sample))\n    print('Loading Sampled df..')\nelse:\n    df_train = df_t.copy()\n    df_test = df_tst.copy()\n\nprint('Training df shape',df_train.shape)\nprint('Test df shape',df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vis_classes(labels,values,title='Target Percentages'):\n    trace=go.Pie(labels=labels,values=values)\n    layout = go.Layout(\n        title=title,\n        height=600,\n        margin=go.Margin(l=0, r=200, b=100, t=100, pad=4)   # Margins - Left, Right, Top Bottom, Padding\n        )\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\n    \n    \nlabels = [str(x) for x in list(df_train['target'].unique())]\nvalues = [(len(df_train[df_train['target'] == 0])/len(df_train))*100,(len(df_train[df_train['target'] > 0])/len(df_train))*100]    \nvis_classes(labels,values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see we are dealing with an unbalanced targets (10% vs 90%)"},{"metadata":{},"cell_type":"markdown","source":"## Sampling from the full dataset (more work on this later)\n<a id='sample'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ones = df_train[df_train['target'] > 0]\nprint('Ones',df_ones.shape)\ndf_zeros = df_train[df_train['target'] == 0].sample(frac=0.25)\nprint('Zeros',df_zeros.shape)\n#we concat both to the sampling dataframe\ndf_sampling = pd.concat([df_ones, df_zeros]).sample(frac=1) #shuffling\nprint(df_sampling.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Feature Engineering\n**Features Used:**\n* sum\n* min\n* max\n* mean\n* std\n* skew\n* kurt\n* med\n* Moving Average\n* percentiles\n<a id='fe'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#part of it Inspired by Gabriel Preda 's Kernel'\n\ndef feature_creation(df,idx,use_perc,perc_list,name_num='_1'):\n    #data metrics\n    print('  * Loading new data metrics: ', name_num)\n    df['sum'+name_num] = df[idx].sum(axis=1)  \n    df['min'+name_num] = df[idx].min(axis=1)\n    df['max'+name_num] = df[idx].max(axis=1)\n    df['mean'+name_num] = df[idx].mean(axis=1)\n    df['std'+name_num] = df[idx].std(axis=1)\n    df['skew'+name_num] = df[idx].skew(axis=1)\n    df['kurt'+name_num] = df[idx].kurtosis(axis=1)\n    df['med'+name_num] = df[idx].median(axis=1)\n    #moving average\n    print('  * Loading moving average metric: ', name_num)\n    df['ma'+name_num] =  df[idx].apply(lambda x: np.ma.average(x), axis=1)\n    #percentiles\n    print('  * Loading percentiles: ', name_num)\n    if use_perc:\n        for i in perc_list:\n            df['perc_'+str(i)] =  df[idx].apply(lambda x: np.percentile(x, i), axis=1)\n    #interactions\n    #coming..\n    \nperc_list = [1,2,5,10,25,50,60,75,80,85,95,99]\nperc_size = len(perc_list)\nstart_time = time.time()\n\nfor i,df in enumerate([df_train, df_test,df_sampling]):\n    print('Loading more features for df: {}/{}'.format(i+1,3))\n    print('Creating Metrics Part 1')\n    features_1 = df_train.columns.values[2:202]\n    feature_creation(df,features_1,use_perc,perc_list,name_num='_1') #adding columns using the train features (#200)\n    print('Creating Metrics Part 2')\n    features_2 = df_train.columns.values[2:211+perc_size] #all features included the ones added\n    feature_creation(df,features_2,use_perc,perc_list,name_num='_2') #adding columns using the train features + the new features\n    #drop repeated columns\n    df.drop(['min_2','max_2'],axis=1,inplace=True)\n    print('-'*50)\n\nprint('Features loaded !')\nprint(\"Execution --- %s seconds ---\" % (time.time() - start_time))\nprint('Train df: ', df_train.columns)\nprint('Test df: ', df_test.columns)\nprint('Number of Features: ', len(df_train.columns[2:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#thanks to https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.iloc[:,2:]\nY = df_train['target']\n\nif augmnt:\n    print('Data Augmentation: Enabled')\n    X,Y = augment(X.values,Y.values,t=2)\n    X = pd.DataFrame(X,columns=df_train.columns[2:])\n    Y = pd.Series(Y)\n    print('Augmentation Succeeded')\n    labels = [\"0\",\"1\"]\n    values = [(sum(Y == 0)/len(Y))*100,(sum(Y > 0)/len(Y))*100]    \n    vis_classes(labels,values,title ='Target Percentages After Augmentation')\n    sub_name = sub_name+'_agmted'\n\n#test train split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=tst_size, random_state=6666)\n\n#Sampling train test split\nX_smple = df_sampling.iloc[:,2:]\ny_smple = df_sampling['target']\nX_train_smple, X_test_smple, y_train_smple, y_test_smple = train_test_split(X_smple, y_smple, test_size=0.4, random_state=6)\n\nprint(\"X_train: \", X_train.shape)\nprint(\"X_test: \" ,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. LGBM Model\n<a id='lgbm'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model LGBM \ndef create_model_lgbm(X_train,y_train,X_val=None,y_val=None,random_state =24):\n    dtrain = lgb.Dataset(X_train,label=y_train)\n    param = {\n    'bagging_freq': 10, #handling overfitting\n    'bagging_fraction': 0.6,#handling overfitting - adding some noise\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.05, #handling overfitting\n    'learning_rate': 0.01, #the changes between one auc and a better one gets really small thus a small learning rate performs better\n    'max_depth':-1, \n    \"min_data_in_leaf\": 80,\n    'metric':'auc',\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': 0,\n    \"bagging_seed\" : random_state,\n    \"seed\": random_state,\n     \n    }\n    if not X_val is None:\n        dval = lgb.Dataset(X_val,label=y_val)\n        valid_sets = (dtrain,dval)\n        valid_names = ['train','valid']\n        num_boost_round = 200000\n    else:\n        valid_sets = (dtrain)\n        valid_names = ['train']\n        num_boost_round = 60000\n    model = lgb.train(param,dtrain,num_boost_round=num_boost_round,valid_sets=valid_sets,valid_names=valid_names,\n                      verbose_eval=3000,\n                     early_stopping_rounds=3000)\n    return model\n\n\n#Setting up\nlgbm_test_x = df_test.iloc[:,1:]\n\npredictions = df_test[['ID_code']]\n\nval_aucs = []\nval_pred = 0\ntarget_pred = 0\nimportand_folds = 0\nsub_train_n =3\nkf = StratifiedKFold(n_splits=5,shuffle = kfold_shuffle, random_state=1111)\nif fold_train:\n    for _fold, (trn_idx, val_idx) in enumerate(kf.split(X.values, Y.values)):\n            Xtrn, ytrn = X.iloc[trn_idx], Y.iloc[trn_idx]\n            Xval, y_val = X.iloc[val_idx], Y.iloc[val_idx]\n            #Just for info\n            ones_train = (sum(ytrn>0) / len(ytrn))*100\n            ones_val = (sum(y_val>0) / len(y_val))*100\n            print('-'*50)\n            print(\"Fold num:{}\".format(_fold + 1))\n            print('\\tTrain Perc: 1: {:.2f}%, 0: {:.2f}%'.format(ones_train,100-ones_train))\n            print('\\tValid Perc: 1 : {:.2f}%, 0:{:.2f}%'.format(ones_val,100-ones_val))\n            #augmentation for each training \n            #thanks to https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment\n            if agmnt_between:\n                val_pred = 0\n                target_pred = 0\n                for i in range(sub_train_n):\n                    print('\\tSub-Train: {}'.format(i+1))\n                    X_t, y_t = augment(Xtrn.values, ytrn.values)\n                    print('\\tAugmentation Succeeded..')\n                    X_t = pd.DataFrame(X_t)\n                    X_t = X_t.add_prefix('var_')\n                    # generate some random integers\n                    random_state = np.random.randint(0, 300, 1)\n                    print('\\tFitting Model')\n                    clf = create_model_lgbm(X_t,y_t,Xval,y_val,random_state=random_state)\n                    target_pred += clf.predict(lgbm_test_x)\n                    val_pred += clf.predict(Xval)\n            #this part could be used when the augmentation is fully applied to the training data\n            else:\n                clf = create_model_lgbm(Xtrn,ytrn,Xval,y_val)\n                val_pred  += clf.predict(lgbm_X.iloc[val_idx]) / kf.n_splits\n                target_pred += clf.predict(df_test.iloc[:,1:]) / kf.n_splits\n            \n            print('-' * 50)\n            importand_folds += clf.feature_importance()\n            val_score = roc_auc_score(y_val, val_pred/sub_train_n)\n            val_aucs.append(val_score)\n            print('\\tVal CV score : {}'.format(val_score))\n            predictions['fold{}'.format(_fold+1)] = target_pred/sub_train_n\n\nmean_cv_score = np.mean(val_aucs)\nprint ('----- Mean CV Score: {:.2} ------'.format(mean_cv_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = 60\nif fold_train:\n    indxs = np.argsort(importand_folds/ kf.n_splits)[:num_features]\nelse:\n    indxs = np.argsort(clf.feature_importance())[:num_features]\n    \nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importance()[indxs],X.columns[indxs])), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('Top {} LightGBM Features accorss folds'.format(num_features))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see , many of the engineered features are present within the top 60 important features"},{"metadata":{},"cell_type":"markdown","source":"# 2.Keras NN Model\n<a id='keras'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc\n#Model NN definition\ndef create_model_nn(in_dim,layer_size=54):\n    model = Sequential()\n    model.add(Dense(layer_size,input_dim=in_dim))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    for i in range(7):\n        model.add(Dense(layer_size))\n        model.add(BatchNormalization())\n        model.add(Activation('relu'))\n        model.add(Dropout(0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    adam = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999)\n    model.compile(optimizer=adam,loss='binary_crossentropy',metrics = [auc])    \n    return model\n\n#Class weights to handle the unbalanced dataset\n\nclass_weights = None\nif weighted:\n    sub_name = sub_name+'_weighted'\n    if balanced:\n        class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)\n    else:\n        class_weights = {\n            1:50, \n            0:1\n                }\nmodel_nn = create_model_nn(X_train.shape[1])\ncallback = EarlyStopping(monitor=\"val_auc\", patience=20, verbose=0, mode='max')\nhistory = model_nn.fit(X_train, y_train, validation_data = (X_test,y_test),epochs=100,batch_size=256,verbose=1,callbacks=[callback],class_weight=class_weights)\ntarget_pred_nn = model_nn.predict(df_test.iloc[:,1:])[:,0]\nprint('\\n Validation Max score : {}'.format(np.max(history.history['val_auc'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combination Vis\n<a id='vis'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ditribution Plots from both models \nnn_val_pred = model_nn.predict(X_test,batch_size=256)[:,0]\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1) \n\ncomb_approach_test = (0.2*target_pred_nn)+(0.8*predictions['target'])\ncomb_approach_test[comb_approach_test>1]=1\ncomb_approach_test[comb_approach_test<0]=0\n\nif fold_train:\n    plt.figure(figsize=(13, 9))\n    #validations sets\n    sns.distplot(nn_val_pred,label='NN Val Score:{:.3f}'.format(roc_auc_score(y_test,nn_val_pred)))\n    sns.distplot(val_pred,label='LGBM Val Score : {:.3f}'.format(mean_cv_score))\n    plt.title('Validation set target predictions')\n    plt.legend()\n    plt.show()\n    plt.savefig('combination_val.png')\n\nplt.figure(figsize=(13, 9))\n#target final test set\nsns.distplot(target_pred_nn,label='NN Target')\nsns.distplot(predictions['target'],label='LGBM Target')\nsns.distplot(comb_approach_test,label='Combination Prediction Target')\nplt.title('Test set target predictions')\nplt.legend()\nplt.show()\nplt.savefig('combination_target_test.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DistPlot Analysis:** \n\nWe can see from the plots how the predictions for the validation sets, and the final target test set follows closely a similar distribution.\nWhich tells us that the test set can be a resemblance of validation sets we are using. \nThen we can proceed with improving our scores in the validation set knowing that there is a high chance they will also improve in the test set.\n\n**Combination Analysis**\n\nWe can also see that the combination of both is adding some noise to the prediction, which in some cases can prove helpful when each model\nwas able to predict with some features better than the others\n\nmore testing is going on here to see how effecient a combination model can get."},{"metadata":{},"cell_type":"markdown","source":"# Submission\n<a id='sub'></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub_pred(preds,df_test,name='submission.csv'):\n    sub_df = pd.DataFrame({'ID_code':df_test['ID_code'],'target':preds})\n    sub_df.to_csv(name, index=False)\n\nsub_file =  sub_name +'.csv'\nsub_pred(predictions['target'],df_test,name=sub_file)\nprint(sub_file+'   --submitted successfully')\n\nprint('Submitting Combination File..')\nsub_pred(comb_approach_test,df_test,name='comb_submission.csv')\nprint('comb_submission.csv   --submitted successfully')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}