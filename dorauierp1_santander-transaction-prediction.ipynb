{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Learning Data Science Part 2.0\n\nThis kernel I create to train my data science skills. I want to train my step course to apply them on this data set. I never mind about the accuracy of my model, but, as long as my progress on this kernel, I try to improve that. So, task for this competition is to predict probability customer of santander who will conducted transaction on future and their nominal.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom IPython.core.interactiveshell import InteractiveShell\nimport warnings\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport gc\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = None\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')\ntestdf = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf['target'].value_counts().plot(kind='bar', title='Unbalance target variable')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\n\nfor i in range(0,50):\n    fig.add_subplot(5,10,i+1)\n    plt.title('Distribution on var_'+str(50+i))\n    sns.distplot(traindf['var_'+str(50+i)], color=\"m\")\n\nfig.tight_layout(pad=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on graph above, I think variable have normal distribution. But, they have different range. So, in the next step, i will apply standard scaler to those variable.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Build Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=[c for c in traindf.columns if c not in ['ID_code', 'target']]\ny = traindf[\"target\"]\nx = traindf[cols]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rb = RobustScaler(with_centering=True,copy=False)\nx_train = rb.fit_transform(x_train)\nx_test = rb.fit_transform(x_test)\ntransform_2 = rb.fit_transform(testdf[cols])\ntestdf[cols] = transform_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Light Gredient Boost Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'subsample': 0.95,\n    'subsample_freq': 100,\n    'num_iterations': 25000,\n    'learning_rate': 0.01,\n    'early_stopping_rounds':2500,\n    'max_bin':20,\n    'min_data_in_leaf':80,\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting' : 'gbdt',\n    'is_unbalance': True,\n    'num_threads': 8,\n    'verbosity': 1,\n    'num_leaves': 16,\n    'min_hessian': 80,\n    'tree_learner': 'serial',\n    'max_depth': 4,\n    'feature_fraction': 0.95,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = lgb.Dataset(x_train, label=y_train)\nvalid_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n\nlgbmodel = lgb.train(params, train_data,                     \n                 valid_sets=[valid_data],\n                 valid_names=['valid'],\n                 verbose_eval=1000)\nscore = lgbmodel.best_score['valid']['auc']\ny_pred = lgbmodel.predict(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test, y_pred.round(0).astype(int)))\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred.round(0).astype(int))*100))\nprint('Best AUC score {}'.format(score*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(36, input_dim=200,activation='relu',kernel_initializer='glorot_normal',bias_initializer='random_normal'))\nmodel.add(Dense(20, activation='relu',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))\nmodel.add(Dense(16, activation='relu',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))\nmodel.add(Dense(8, activation='relu',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))\nmodel.add(Dense(1, activation='sigmoid',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs=20, batch_size=1000)\n_, accuracy = model.evaluate(x_test, y_test)\nprint('Accuracy: %.2f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_classes(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(max_iter=10000, C=50)\nlogreg.fit(x_train, y_train.ravel())\n\ny_pred = logreg.predict(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test.ravel(), y_pred))\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_1 = logreg.predict(testdf[cols].to_numpy())\ny_pred_2 = model.predict_classes(testdf[cols].to_numpy())\ny_pred_3 = lgbmodel.predict(testdf[cols].to_numpy()).round(0).astype(int)\n\ntestdf['target'] = y_pred_1\ntestdf[['ID_code','target']].to_csv('SantanderSubmission1.csv', index=False)\n\ntestdf['target'] = y_pred_2\ntestdf[['ID_code','target']].to_csv('SantanderSubmission2.csv', index=False)\n\ntestdf['target'] = y_pred_3\ntestdf[['ID_code','target']].to_csv('SantanderSubmission3.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}