{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras import regularizers\nimport time\nfrom datetime import datetime\nfrom keras.optimizers import Adam\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true},"cell_type":"code","source":"traindata = pd.read_csv('../input/train.csv')\ntraindata = traindata.sample(frac=1).reset_index(drop=True)\ntrain_lable = traindata['target']\ntrain_input = traindata.drop(['target', 'ID_code'], axis=1)\nprint(\"loading done\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36eae87efca345e8321a6dfe6506159cc6a450d4","trusted":true},"cell_type":"code","source":"def split(X, Y, splitFrac):\n    n = X.shape[0]\n    nf = (int)((float)(X.shape[0]) * splitFrac)\n    xsplits = np.split(X, [n-2*nf, n-nf, n])\n    ysplits = np.split(Y, [n-2*nf, n-nf, n])\n    return xsplits[0], ysplits[0], xsplits[1], ysplits[1], xsplits[2], ysplits[2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8819e84a3bf0100d9ea37739026f3566248c14e0","trusted":true},"cell_type":"code","source":"def normalize(df, withGiven=False, meanIn = 0, varIn = 0):\n    orig_columns = df.columns\n    mean = meanIn if withGiven else df.mean(axis=0)\n    var = varIn if withGiven else df.var(axis=0)\n    newDf = pd.DataFrame()\n    for i in range(len(orig_columns)):\n        f = orig_columns[i]\n        newDf[f] = df[f]#(df[f] - mean[i])/var[i]\n        newDf['sq_'+f] = np.power(newDf[f], 2)\n        newDf['sqrt_'+f] = np.power(np.abs(newDf[f]), 0.5)\n        newDf['qube_'+f] = np.power(np.abs(newDf[f]), 3)\n    newDf.iloc[1:20,0:25].describe\n    return newDf, mean, var\n\ndef calcWeights(Y):\n    nCount = Y[Y == 0].shape[0]\n    pCount = Y[Y == 1].shape[0]\n    if nCount > pCount:\n        return { 0: 1.0, 1: nCount/pCount}\n    else:\n        return { 0: pCount/nCount, 1: 1.0}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c2a7ad0661474e4629f576bc9b1fa59e9ba5c1d","scrolled":false,"trusted":true},"cell_type":"code","source":"X, mean, var = normalize(train_input)\nY = train_lable\n\nXtrain, Ytrain, Xdev, Ydev,Xtest, Ytest = split(X, Y, 0.01)\n\nepsilon = 0.0001\nweights = class_weight.compute_class_weight('balanced',np.unique(Y), Y)\nweights = dict(enumerate(weights))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0061288044259a9b2a6128393bc618a2f046d2c6","scrolled":false,"trusted":true},"cell_type":"code","source":"def fitModel(dims, Xt, Yt, Xd, Yd, epochs, batchsize):\n    model = Sequential()\n    prevn = Xt.shape[1]\n    for (n, act, dr, reg) in dims:\n        kr2 = None if reg < epsilon else regularizers.l2(reg)\n        model.add(Dense(n, activation=act, input_dim=prevn, kernel_regularizer=kr2)) #kernel_initializer='random_uniform'\n        if dr > epsilon:\n            model.add(Dropout(dr))\n        model.add(BatchNormalization())\n        nprev = n\n\n    #opt = Adam(lr=0.001, decay=0.0001)\n    es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    start = time.time()\n    hist = model.fit(Xt, Yt, epochs=epochs, batch_size=batchsize, verbose=1, shuffle=True, validation_data=(Xd,Yd), callbacks = [es], class_weight=weights)\n    end = time.time()\n    val_acc = hist.history['val_acc'][-1] #last element\n    print(\"(\",epochs,batchsize,\")\", \"took\", (int)((end-start)*1000/1000), \"sec, acc\", val_acc, \"and loss acc hist \", hist.history['acc'])\n    return (model, hist, (end-start)*1000)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"e6562bc073d8a72d7f00cdcd9137b73e789fd88c","scrolled":true,"trusted":true},"cell_type":"code","source":"epochs = 200\nbatchsize = 300\nparams = [[(1025,  \"relu\",    0.0, 0.00),        \n           (256,   \"relu\",    0.0, 0.00),\n           (16,    \"relu\",    0.0, 0.00),\n           (1,     \"sigmoid\", 0.0, 0.00)]]\nhist = []\nfor dims in params:        \n    hist.append(fitModel(dims, Xtrain, Ytrain, Xdev, Ydev, epochs, batchsize))\nprint(hist)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9001790a069599629237ece8a1e5b88264c6c95","trusted":true},"cell_type":"code","source":"def score(model, X, Y):\n    devRaw = model.predict(X, batch_size=300, steps=None)\n    devOut = (devRaw > 0.5)*1\n    devOut = np.squeeze(np.asarray(devOut))\n    tn, fp, fn, tp = confusion_matrix(Y, devOut).ravel()\n    pOrig = sum(Y)\n    nOrig = Y.shape[0] - pOrig\n    pTarg = sum(devOut)\n    nTarg = devOut.shape[0] - pTarg\n    f1 = f1_score(Y, devOut)\n    return((fp, fn, tp, tn, pOrig, nOrig, pTarg, nTarg, f1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8dd588af29a59839ce659bc2c012187b3f2cd202","scrolled":true,"trusted":true},"cell_type":"code","source":"for i in range(len(hist)):\n    model = hist[i][0] \n    res1 = score(model, Xtrain, Ytrain)\n    res2 = score(model, Xdev, Ydev)\n    res3 = score(model, Xtest, Ytest)\n    print(i, \"train\", res1)\n    print(i, \"dev\", res2)\n    print(i, \"test\", res3)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cac441b4da5f30a159e33ea6e75b32969ad04a2","scrolled":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nclrs1=['b-', 'g-', 'r-', 'c-', 'm-', 'y-', 'k-', 'w-']\nclrs2=['b--','g--','r--','c--','m--','y--','k--','w--']\nbestModel = None\nbestAcc = 0\nfor i in range(len(hist)):\n    plt.plot(hist[i][1].history['acc'], clrs1[i])\n    plt.plot(hist[i][1].history['val_acc'], clrs1[i]+'-')\n    if bestAcc < hist[i][2]:\n        bestModel = hist[i][0] \n        bestAcc = hist[i][2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4aab526c6188b2f3d0e4e600b6d48bb974ed9ad6","trusted":true},"cell_type":"code","source":"print(\"ready to test\")\ntest_input = pd.read_csv('../input/test.csv')\ntest_input = test_input.drop(['ID_code'], axis=1)\nXsub = normalize(test_input, True, mean, var)[0]\ntargets = (bestModel.predict(Xsub, batch_size=300) > 0.5)*1\nprint(\"saving output\")\ntoSubmit = pd.read_csv('../input/sample_submission.csv')\ntoSubmit['target'] = targets\nfilename = \"sub-{:%y%m%d%H%M}.csv\".format(datetime.now())\ntoSubmit.to_csv(filename, index=False)\nprint(\"saved\", filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}