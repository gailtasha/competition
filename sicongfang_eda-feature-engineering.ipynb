{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f6cd56f94a0801ac1b8635840267c37f9a175df"},"cell_type":"markdown","source":"**Step0 - Import Libraries, Load Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe6a163dacb6f99fc9fce0723c5a6fe07afa83c6"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nrcParams = plt.rcParams.copy()\nimport seaborn as sns\nplt.rcParams = rcParams\n% matplotlib inline\nplt.rcParams[\"figure.dpi\"] = 100\nnp.set_printoptions(precision=3, suppress=True)\nplt.style.use(['fivethirtyeight'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"# Load data to dataframe\nraw_train = pd.read_csv(\"../input/train.csv\")\nraw_test = pd.read_csv(\"../input/test.csv\")\nraw_train.head(50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fb6f72c5f73e1d4624e324ae48e3ac985fc85c98"},"cell_type":"code","source":"raw_test.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bef2f7a1671f2f022342549875faf6da55dd9959"},"cell_type":"code","source":"# Create training and test data\nX_train = raw_train.drop(columns=[\"ID_code\",\"target\"])\ny_train = raw_train[[\"target\"]] \nX_test = raw_test.drop(columns=[\"ID_code\"])\ny_test = raw_test[[\"ID_code\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29ec6f9ab705d354f2e181a1d8b445f0c8362b92","scrolled":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdf321bbd7fab61038429f552b1a351442c93374"},"cell_type":"code","source":"y_train.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caa4405d3d25f5e174e80a86f5cf68c5dd0b5a6e"},"cell_type":"code","source":"# Check X training data dimensions\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78ee6db58f0f1c0006747be15ea471fdacdfb73d"},"cell_type":"markdown","source":"**Step1 - Exploration and Preparation**\n\nIn this step, I will perform the following actions:\n\n* Check the imbalance in data \n* Check missing values\n* Understand the data better using plots\n* Perform basic feature engineering which will be used accross all model sets.\n* Make some hypothesis using the plots and try to make some features representing them. Note that these features might/might not work because they are just hypothesis."},{"metadata":{"_uuid":"ecc567203d3a2273df51fd5896de7bf723d2fe03"},"cell_type":"markdown","source":"**1.1 Check Imbalance**   \nThe result below suggests high imbalance in training data. Sampling methods should be considered when developing models"},{"metadata":{"trusted":true,"_uuid":"24d21c60c9a686da344e887bcb2e56eb4928986e"},"cell_type":"code","source":"# Check y training data distribution\nsns.countplot(x=\"target\", data=y_train)\nprint(y_train['target'].value_counts()/y_train.shape[0])\nprint('{} samples are positive'.format(np.sum(y_train['target'] == 1)))\nprint('{} samples are negative'.format(np.sum(y_train['target'] == 0)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e194762803fb6de78b866877b26af302f972450f"},"cell_type":"markdown","source":"**1.2 Check missing values**  \nWe'll check nan values and zero values (may represent missing values). Also I'll add a column for number of unique values because that'll be interesting to know."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1e8d2e2110b45ead7b75da3bafd90731b299d824"},"cell_type":"code","source":"df1 = pd.concat([X_train.apply(lambda x: sum(x.isnull())).rename(\"num_missing\"),\n                 X_train.apply(lambda x: sum(x==0)).rename(\"num_zero\"),\n                 X_train.apply(lambda x: len(np.unique(x))).rename(\"num_unique\")],axis=1).sort_values(by=['num_unique'])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f137fe1229bc5cee620747ee82bbe5d61dd9f5c1","scrolled":true},"cell_type":"code","source":"df2 = pd.concat([X_test.apply(lambda x: sum(x.isnull())).rename(\"num_missing\"),\n                 X_test.apply(lambda x: sum(x==0)).rename(\"num_zero\"),\n                 X_test.apply(lambda x: len(np.unique(x))).rename(\"num_unique\")],axis=1).sort_values(by=['num_unique'])\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8684bac781c5bb5e6893bba72677cbcc6b3ee8bc"},"cell_type":"code","source":"# No missing value comfirmed\nnp.sum(df1['num_missing']!=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"900c1bab378ec8333119c9aee646c845c48b5efc"},"cell_type":"markdown","source":"Let's check if zero values should be treated as Nan values. From the density and rug plots below, the number of zero value samples are closed to that of other values. Therefore, we should not replace them with any imputed values such as average or median."},{"metadata":{"trusted":true,"_uuid":"3a9f6ae5a331d765e1c203992a05af46f4217a42"},"cell_type":"code","source":"sns.distplot(a=X_train['var_71'],rug=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36bef4aee9847ea9f09401d82c07bd4faa9e9671"},"cell_type":"code","source":"sns.distplot(a=X_train['var_131'],rug=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9eb4bf5a06b52d72e59c6954f76a8b24c37fc835"},"cell_type":"markdown","source":"**1.3 Visualize Features:**  \nWe'll make 2 plots to visualize these features:\n\n* histogram\n* box-whiskers plot with the outcome\n* counts of top 10 most occuring unique values to see if there are any dominating ones\n"},{"metadata":{"trusted":true,"_uuid":"313406028f3b232db3b77ff648ba903bbd427396"},"cell_type":"code","source":"#create a function which makes the plot:\nfrom matplotlib.ticker import FormatStrFormatter\ndef visualize_numeric(ax1, ax2, ax3, df, col, target):\n    #plot histogram:\n    df.hist(column=col,ax=ax1,bins=200)\n    ax1.set_xlabel('Histogram')\n    \n    #plot box-whiskers:\n    df.boxplot(column=col,by=target,ax=ax2)\n    ax2.set_xlabel('Transactions')\n    \n    #plot top 10 counts:\n    cnt = df[col].value_counts().sort_values(ascending=False)\n    cnt.head(10).plot(kind='barh',ax=ax3)\n    ax3.invert_yaxis()  # labels read top-to-bottom\n#     ax3.yaxis.set_major_formatter(FormatStrFormatter('%.2f')) #somehow not working \n    ax3.set_xlabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6b97337ac398a4f9371af887238ba6a663f24b4a"},"cell_type":"code","source":"for col in list(df1.index[:20]):\n    fig, axes = plt.subplots(1, 3,figsize=(10,3))\n    ax11 = plt.subplot(1, 3, 1)\n    ax21 = plt.subplot(1, 3, 2)\n    ax31 = plt.subplot(1, 3, 3)\n    fig.suptitle('Feature: %s'%col,fontsize=5)\n    visualize_numeric(ax11,ax21,ax31,raw_train,col,'target')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62057338ae94ab1503a6d399b9d94ee9b9a90c8"},"cell_type":"markdown","source":"Some interesting fact can be found in:   \n*var_68* :  periodic spikes can be observed. (Other kaggler said this column may be time. From the histgram, its periodicity supports this opnion as well).  \n*var_108* :  a peak can be found at 14.1999 and 14.2. Also, the top values are very close to each other, we may consider round them up to less decimals.  \n*var_12* : a peak can be found at 13.5545. it shows similar features as *var_108*  \n  \nGeneral insights:  \n* Most of the columns follow normal distribution  \n* Since there are lot of outliers, using a robustscalar might make more sense\n* polynomial features are not very intuitive here, but can be tried later\n"},{"metadata":{"_uuid":"2656a5ca7a37680c8f45d403ebe422ed67dfe062"},"cell_type":"markdown","source":"**1.4 Get PCA and t-SNE for visualization:**  \nPCA requires scaled data but we need not scale the data for both model sets. So we'll use a pipeline here. We saw earlier that data has outliers so we'll use the robust scaler. Its a safe bet because if the data is normal, it'll work similar to standard scaler."},{"metadata":{"trusted":true,"_uuid":"8f54aecf07239f79d3d89b3c81502eac4749be6d"},"cell_type":"code","source":"#get vars except target:\nx_vars = X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f6e1ad69fd905f85e2ecc1a354c1aa362e6a536","_kg_hide-input":false},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import RobustScaler\n\npca = make_pipeline(RobustScaler(), PCA(n_components=2))\ntrain_pca = pca.fit_transform(X_train[x_vars])\nplt.scatter(train_pca[:, 0], train_pca[:, 1], c=y_train['target'], alpha=.1)\nplt.xlabel(\"first principal component\")\nplt.ylabel(\"second principal component\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks like a highly non-linear relationship between the data and targets. Two classes are concentrated seperately.\n\nWe could try creating PCA as new features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\npca_50 = PCA(n_components=50)\n# pca_50 = Pipeline(steps=[('sampler', RobustScaler()),('pca', pca_50)])\npca_50_train = pca_50.fit_transform(X_train[x_vars])\npca_50_test = pca_50.transform(X_test[x_vars])\nprint('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.manifold import TSNE\n# from matplotlib.ticker import NullFormatter\n# from time import time\n# tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n# tsne_results = tsne.fit_transform(pca_result_50)\n\n# print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I tried to first calculate 50 principle components and applied t-SNE. Since t-SNE is very computationally expensive, we abandoned adding t-SNE component as new features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ax.set_title(\"Perplexity=%d\" % perplexity)\n# ax.scatter(Y[red, 0], Y[red, 1], c=\"r\")\n# ax.scatter(Y[green, 0], Y[green, 1], c=\"g\")\n# ax.xaxis.set_major_formatter(NullFormatter())\n# ax.yaxis.set_major_formatter(NullFormatter())\n# ax.axis('tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\ndef process_data(train_df, test_df):\n#     logger.info('Features engineering - numeric data')\n    idx = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n    for df in [test_df, train_df]:\n        for feat in idx:\n            df['r2_'+feat] = np.round(df[feat], 2)\n            df['r2_'+feat] = np.round(df[feat], 2)\n        df['sum'] = df[idx].sum(axis=1)  \n        df['min'] = df[idx].min(axis=1)\n        df['max'] = df[idx].max(axis=1)\n        df['mean'] = df[idx].mean(axis=1)\n        df['std'] = df[idx].std(axis=1)\n        df['skew'] = df[idx].skew(axis=1)\n        df['kurt'] = df[idx].kurtosis(axis=1)\n        df['med'] = df[idx].median(axis=1)\n        tmp=np.array(df[['var_0', 'var_2', 'var_26', 'var_76','var_81','var_139','var_191']])\n        kms=KMeans(n_clusters=30)\n        y=kms.fit_predict(tmp)\n        df['category'] = y\n        df['category'] = df['category'].astype('category')\n    print('Train and test shape:',train_df.shape, test_df.shape)\n    return train_df, test_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train1, X_test1 = process_data(raw_train, raw_test)\n# X_train1.head(30)\n# X_test1.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train1[['var_1','r2_var_1']].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add PCA features:\nX_train_01 = pd.concat([X_train, pd.DataFrame(train_pca,columns=['comp1_pca','comp2_pca'])],axis=1)\n#Add t-SNE features:\n# X_train = pd.concat([X_train, pd.DataFrame(tsne_results,columns=['comp1_tsne','comp2_tsne'])],axis=1)\n#get PCA test components:\ntest_pca = pca.transform(X_test[x_vars])\nX_test_01 = pd.concat([X_test, pd.DataFrame(test_pca,columns=['comp1_pca','comp2_pca'])],axis=1)\n# #get t-SNE test components:\n# test_pca_50 = pca_50.transform(X_test[x_vars])\n# test_tsne = tsne.transform(test_pca_50)\n# X_test = pd.concat([X_test, pd.DataFrame(test_pca,columns=['comp1_pca','comp2_pca'])],axis=1)\n# X_test = pd.concat([X_test, pd.DataFrame(test_tsne,columns=['comp1_tsne','comp2_tsne'])],axis=1)\n#check shape: (4 more columns added)\nX_train_01.shape, X_test_01.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step2 - ModelSet1\nIn this step, we expect you to perform the following steps relevant to the models you choose for set1:**\n\nfeature engineering  \nvalidation  \nfeature selection  \nfinal model selection  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#copy the data so that model specific feature engineering can be performed.\nrscaler = RobustScaler()\nX_train_02 = pd.DataFrame(rscaler.fit_transform(X_train))\nX_test_02 = rscaler.transform(X_test)\nX_train_02.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check correlation of features\ncorr = X_train_01.corr()\nfor i in corr.columns:\n    print('top correlation columns with {0} are : \\n{1}'.format(i,list(zip(list(corr[i][(corr[i].abs() > 0.5) & (corr[i].abs() <1.0)].index),\n                                                                         list(corr[i][(corr[i].abs() > 0.5) & (corr[i].abs() <1.0)].values)))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the correlation of the first 10 features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(X_train_01.loc[:, 'var_1':'var_10'].corr(),\n           annot=True, fmt=\".4f\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copy the data so that model specific feature engineering can be performed.\nrscaler = RobustScaler()\nX_train_02 = pd.DataFrame(rscaler.fit_transform(X_train))\nX_test_02 = rscaler.transform(X_test)\nX_train_02.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Methods to check featurn importance**  \nI show four methods to find important feature below.\n* check the feature importance using f_classif and mutual_info_classif  \n* check the feature importance using random forest\n* check the feature importance using the absolute value of coefficients of logistic regression\n* check the feature importance using permutation-importance https://www.kaggle.com/dansbecker/permutation-importance"},{"metadata":{},"cell_type":"markdown","source":"1. Lets check the feature importance using **f_classif and mutual_info_classif**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\n\nf_values, p_values = f_classif(X_train_01[x_vars], y_train['target'])\nmi_scores = mutual_info_classif(X_train_01[x_vars], y_train['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot them\nfig = plt.figure(figsize=(40, 4))\nplt.xticks(range(X_train.shape[1]), x_vars, rotation='vertical')\nline_f, = plt.plot(f_values, 'o', c='r')\nplt.ylabel(\"F value\")\nax2 = plt.twinx()\nline_s, = ax2.plot(mi_scores, 'o', alpha=.7)\nax2.set_ylabel(\"MI score\")\nplt.legend([line_s, line_f], [\"Mutual info scores\", \"F values\"], loc=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Lets check the feature importance using **logistic regression**"},{"metadata":{},"cell_type":"markdown","source":"**Generic Model Functions**  \nBefore going into modeling, we'll just define generic functions which will can use to run model and perform cross-validation.  \nNote that SVC models dont give probabilities by default so we'll use the decision function for the purpose of AUC calculation. The parameter \"prob_available\" can be used to specify whether the model has \"predict_proba\" function or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection, metrics\ndef modelfit(alg, dtrain, predictors, y_train, performCV=True, print_feature_importance=False, print_coef=False,\n             prob_available=True,export_model=False,cv_folds=5,export_name=''):\n\n    #Perform cross-validation:\n    if performCV:\n        cv_score = model_selection.cross_val_score(alg, dtrain[predictors], y_train, \n                                                   cv=cv_folds, scoring='roc_auc', n_jobs=-1)\n    \n    #Fit the algorithm on the data\n    alg.fit(dtrain[predictors], y_train)\n        \n    #Predict train set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    if prob_available:\n        dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n    else:\n        dtrain_predprob = alg.decision_function(dtrain[predictors])\n    \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy (Train) : %.4g\" % metrics.accuracy_score(y_train.values, dtrain_predictions))\n    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob))\n    \n    if performCV:\n        print(\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n        \n    #Print Feature Importance:\n    if print_feature_importance:\n        plt.figure(figsize=(5, 10))\n        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values()\n        feat_imp.plot(kind='barh', title='Feature Importances')\n        plt.xlabel('Feature Importance Score')\n        \n    #Print Coefficients:\n    if print_coef:\n        plt.figure(figsize=(5, 10))\n        coeff = pd.Series(alg.coef_[-1,:], predictors).sort_values()\n        coeff.plot(kind='barh', title='Feature Importances')\n        plt.xlabel('Coefficients')\n        \n    #export model:\n    if export_model:\n        dexport = dtest[['ID_code']]\n        dexport['target'] = dtest_predprob\n        dexport[['ID_code','target']].to_csv('final_data/%s.csv'%export_name,index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nlog_reg = LogisticRegressionCV()\n%%timeit -n1 -r1\n#get the CV score now:\nmodelfit(log_reg,X_train_01,x_vars, y_train['target'], performCV=True, print_coef=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the best parameter:\nlog_reg.scores_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Lets check the feature importance using **random forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":" # Feature importance using Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nparams = {\n    'max_leaf_nodes':list(range(10,161,10))\n}\n\nrf=RandomForestClassifier(n_estimators=100)\nparams = {\n    'max_leaf_nodes':list(range(10,161,10))\n}\n# model_rf = Pipeline(steps=[('sample',RandomUnderSampler()), ('rf',RandomForestClassifier(n_estimators=150,\n#                                                                       criterion='entropy',\n#                                                                       max_depth=5,\n#                                                                       min_samples_split=500,\n#                                                                       min_samples_leaf=50,\n#                                                                       random_state=0,\n#                                                                       class_weight='balanced_subsample'))])\ngs = GridSearchCV(rf,params,scoring='roc_auc', cv=5)\ngs.fit(X_train, y_train['target'])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(gs.cv_results_)\nres = res.pivot_table(index=\"param_max_leaf_nodes\",\n                      values=[\"mean_test_score\", \"mean_train_score\"])\nres\n\n# score_rf = np.mean(cross_val_score(model_rf, X_train, y_train, scoring='roc_auc', cv=5))\n# print('Average ROC AUC Score: {:.3f}'.format(score_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelfit(gs,X_train_01,x_vars, y_train['target'], performCV=True, print_feature_importance=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Lets check the feature importance using **Permutation Importance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nimport pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\n# Need this to display each ELI5 HTML report within the for loop.\nfrom IPython.display import display\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 314\nCV = KFold(n_splits=5)\nFEATURES = X_train.columns.tolist()\nTARGET_COL = \"target\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold, (train_idx, valid_idx) in enumerate(CV.split(X_train, y_train[TARGET_COL])):\n    clf = LGBMClassifier(random_state=SEED, n_threads=-1, \n                         eval_metric=\"auc\", n_estimators=10000)\n    clf.fit(X_train.loc[train_idx, FEATURES], \n            y_train.loc[train_idx, TARGET_COL], \n            eval_metric=\"auc\",\n            verbose=0,\n            early_stopping_rounds=1000,\n            eval_set=[(X_train.loc[valid_idx, FEATURES], \n                       y_train.loc[valid_idx, TARGET_COL])])\n    permutation_importance = PermutationImportance(clf, random_state=SEED)\n    permutation_importance.fit(X_train.loc[valid_idx, FEATURES], \n                               y_train.loc[valid_idx, TARGET_COL])\n    print(f\"Permutation importance for fold {fold}\")\n    display(eli5.show_weights(permutation_importance, feature_names = FEATURES))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c627fcf0d01b6b301fb2a69810cb27d51a120ba"},"cell_type":"code","source":"import warnings\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84126a545ac95100d9da7678c763282626ae5a55"},"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n\n# warnings.filterwarnings('ignore')\n# param_grid = {'logisticregression__C': np.logspace(-1, 1, 7)}\n# pipe = make_pipeline(RandomUnderSampler(), StandardScaler(), LogisticRegression(class_weight='balanced',\n#                                                                                 random_state=0))\n# model_01 = GridSearchCV(pipe, param_grid, cv=5)\n# model_01.fit(X_train, y_train)\n\n# score_01 = np.mean(cross_val_score(model_01, X_train, y_train, scoring='roc_auc', cv=7))\n# print('Average ROC AUC Score: {:.3f}'.format(score_01))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcd7f51682c20efec1446fad172dff1ed1c4bde9"},"cell_type":"code","source":"# y_pred_01 = model_01.predict(X_test)\n# #  print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))\n# y_test['target_01'] = y_pred_01\n# y_test_01 = y_test[['ID_code','target_01']].copy()\n# y_test_01.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41117392d77a5ea3436ff7835892707cb76ac5a4"},"cell_type":"code","source":"# from xgboost import XGBClassifier\n\n# model_02 = XGBClassifier(max_depth=2,\n#                          learning_rate=1,\n#                          min_child_weight = 1,\n#                          subsample = 0.5,\n#                          colsample_bytree = 0.1,\n#                          scale_pos_weight = round(sum(y_train.target == 1)/len(y_train.target),2),\n#                          #gamma=3,\n#                          seed=0)\n# model_02.fit(X_train, y_train.values)\n\n# score_02 = np.mean(cross_val_score(model_02, X_train, y_train.values, scoring='roc_auc', cv=7))\n# print('Average ROC AUC Score: {:.3f}'.format(score_02))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c63f958e8e8bf0e2e88dd907a8c14c53de38bcb"},"cell_type":"code","source":"# y_pred_02 = model_02.predict(X_test)\n# #  print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))\n\n# y_test['target'] = y_pred_02\n# y_test_02 = y_test[['ID_code','target']].copy()\n# y_test_02.head()\n# y_test_02.to_csv('../input/sample_submission.csv', encoding='utf-8', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70acde7b0967119d22a5c86467c92e0aaaca9c59"},"cell_type":"code","source":"# from sklearn.ensemble import ExtraTreesClassifier\n\n# model_08 = make_pipeline(RandomUnderSampler(), ExtraTreesClassifier(n_estimators=150,\n#                                                                     criterion='entropy',\n#                                                                     max_depth=8,\n#                                                                     min_samples_split=300,\n#                                                                     min_samples_leaf=15,\n#                                                                     random_state=0,\n#                                                                     class_weight='balanced_subsample'))\n# model_08.fit(X_train, y_train)\n\n# score_08 = np.mean(cross_val_score(model_08, X_train, y_train, scoring='roc_auc', cv=7))\n# print('Average ROC AUC Score: {:.3f}'.format(score_08))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}