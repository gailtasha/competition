{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport seaborn as sns\nimport lightgbm as lgb\nimport time\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.patches as patch\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import zero_one_loss\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA \nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# this\ntr = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [col for col in tr.columns if col not in ['target', 'ID_code']]\ntr_X = tr[features]\ntr_y = tr.target\nts_X = test[features]\nt_X = pd.concat([tr_X,ts_X],axis = 0,sort = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalizing data\n#tfts = [col for col in test.columns if col not in ['target', 'ID_code']]\n#test_X = test[tfts]\n#for col in tr_X.columns:\n#    tr_X[col] = ((tr_X[col] - tr_X[col].mean()) / tr_X[col].std()).astype('float32')\n#for col in test_X.columns:\n#   test_X[col] = ((test_X[col] - test_X[col].mean()) / test_X[col].std()).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check(and plot) data\n## tr['target'].value_counts()\n## ros = RandomOverSampler(random_state = 1)\n## tr1_X,tr1_y=ros.fit_resample(tr_X,tr_y)\n## Counter(tr1_y)\n#plt.hist(tr['var_68'])\n#sns.kdeplot(tr.loc[tr['target'] == 0]['var_68'],label=0)\n#sns.kdeplot(tr.loc[tr['target'] == 1]['var_68'],label=1)\n#plt.hist(tr.loc[tr['target'] == 0]['var_68'],label=0)\n#plt.hist(tr['var_73'],bins = 1000)\n#sns.kdeplot(tr_X['var_33'])\n#tr_X['var_33'].iloc[[2,3]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#randomly change 2 variables\ndef swapping(x,x1,x2):\n    if x == x1:\n        return x2\n    elif x == x2:\n        return x1\n    else:\n        return x\ndef appl(x,y,z):\n    if x == 1:\n        return y\n    else:\n        return z\nfor col in t_X.columns:\n    count = t_X[col].value_counts()\n    t_X[col+'cts'] = t_X[col].map(count)\n    t_X[col+'tqs'] = t_X[col+'cts'].apply(lambda x:appl(x,0,1))\n    #rdn1 = np.random.normal(loc = tr_X[col].mean(),scale = tr_X[col].std())\n    #rdn2 = np.random.normal(loc = tr_X[col].mean(),scale = tr_X[col].std())\n    #r1=np.argmin(abs((tr_X[col]-rdn1)))\n    #r2=np.argmin(abs((tr_X[col]-rdn2)))\n    #a1 = tr_X[col].iloc[r1]\n    #a2 = tr_X[col].iloc[r2]\n    t_X[col+'tqs'] = t_X[col] * t_X[col+'tqs'] + t_X[col].mean() * (1-t_X[col+'tqs'])\n    #tr_X[col+'tqs'] = tr_X[col+'tqs'].apply(lambda x: np.nan if x == 0 else x)\n    #tr_X[col+'uqs'] = tr_X[col].map\n    #tr_X[col+'rds'] = tr_X[col].apply(lambda x:swapping(x,a1,a2))\n    #a = a+sum(tr_X.iloc[col])-sum(tr_X.iloc[col+'rds'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featurez = [col for col in tr_X.columns if col not in [features]]\ntr_X = t_X[:200000]\nte_X = t_X[200000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalizing data\n#tfts = [col for col in test.columns if col not in ['target', 'ID_code']]\n#test_X = test[tfts]\n#for col in tr_X[features]:\n#    tr_X[col] = ((tr_X[col] - tr_X[col].mean()) / tr_X[col].std()).astype('float32')\n#for col in test_X.columns:\n#   test_X[col] = ((test_X[col] - test_X[col].mean()) / test_X[col].std()).astype('float32')\ntr_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Principle Component Analysis - doesn't work well!\n#pca = PCA(n_components=200)\n#pca_X = pca.fit_transform(tr_X)\n#t_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features = [col for col in tr.columns if col not in ['target', 'ID_code']]\n#tr_X = tr[features]\n#tr_y = tr.target\ntrain_X, val_X, train_y, val_y = train_test_split(tr_X, tr_y, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#model = DecisionTreeClassifier(random_state=0,splitter ='best',max_depth = 10)\n#model.fit(train_X,train_y)\n#preds = model.predict_proba(val_X)\n#preds_y = preds[:,1]\n#print('AUC: ', roc_auc_score(val_y, preds_y) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#model = RandomForestClassifier(random_state=0,max_depth = 10)\n#model.fit(train_X,train_y)\n#preds = model.predict_proba(val_X)\n#preds_y = preds[:,1]\n#print('AUC: ', roc_auc_score(val_y, preds_y) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Logistic Regression\n#model = LogisticRegression(class_weight='balanced', penalty='l2',n_jobs = -1, C=0.1,max_iter = 10,verbose=100)\n#model.fit(train_X,train_y)\n#preds_y = model.predict_proba(val_X)\n#preds_y = preds_y[:,1]\n#print('AUC: ', roc_auc_score(val_y, preds_y) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Linear Regression\n#model = LinearRegression().fit(train_X,train_y)\n#preds_y = model.predict(val_X)\n#print('AUC: ', roc_auc_score(val_y, preds_y) )\n#print('R2: ', model.score(val_X, val_y) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n#This method is extremely slow - still needs improvement\n# Light GBM\n#lgb_train = lgb.Dataset(train_X,train_y)\n#lgb_test = lgb.Dataset(val_X,val_y,reference = lgb_train)\n#param = {\n#    'num_leaves': 20,\n#    'verbose':1,\n#    'metric':{'auc'},\n#    'objective':'binary'\n#}\n#model = lgb.train(param,lgb_train,num_boost_round = 1000)\n#preds_y = model.predict(val_X)\n#print('AUC: ', roc_auc_score(val_y,preds_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n#This method is extremely slow - still needs improvement\n# Light GBM\nlgb_train = lgb.Dataset(train_X,train_y)\nlgb_test = lgb.Dataset(val_X,val_y,reference = lgb_train)\nparam = {\n    'num_leaves': 20,\n    'verbose':1,\n    'metric':{'auc'},\n    'objective':'binary'\n}\nmodelx = lgb.train(param,lgb_train,valid_sets = lgb_test,num_boost_round = 2000,early_stopping_rounds = 200,verbose_eval = 200)\npreds_y = modelx.predict(val_X)\nprint('AUC: ', roc_auc_score(val_y,preds_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Logistic Regression\n#modelx = LogisticRegression(class_weight='balanced', penalty='l2', C=0.1,max_iter = 1000,verbose=100)\n#modelx.fit(tr1_X,tr1_y)\n#preds_y = modelx.predict_proba(val_X)\n#print(preds_y)\n#preds_y = preds_y[:,1]\n#print('AUC: ', roc_auc_score(val_y, preds_y) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = modelx.predict(te_X)\nprint(pred)\nsub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = pred\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tr.describe()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}