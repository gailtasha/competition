{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# train=pd.read_csv('../input/train.csv')\n# test=pd.read_csv('../input/test.csv')\ndf_test = pd.read_csv('../input/test.csv')\ndf_train = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--Feature selection\nfeatures = [x for x in df_train.columns.values.tolist() if x.startswith(\"var_\")]\n#features = df_train.columns.values[2:202]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(10, 6)\nsns.distplot(df_test[features].mean(axis=0),color=\"green\", kde=True, label='test', ax=ax)\nsns.distplot(df_train[features].mean(axis=0),color=\"yellow\", kde=True,bins=120, label='train', ax=ax)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--Scaling data and store scaling values\nscaler = StandardScaler().fit(df_train[features].values)\nX = scaler.transform(df_train[features].values)\ny = df_train['target'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train and y_train\nX = X.astype(float)\ny = y.astype(float)\nX_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.20, )\nX_train.shape,  X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nimport collections, numpy\nfrom sklearn.metrics import confusion_matrix\nfrom keras.regularizers import l2\nfrom tensorflow import keras\nfrom keras.layers import Dropout\nimport matplotlib.patches as mpatches\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\nfrom keras.layers.normalization import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_cols = X_train.shape[1]\nn_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = y_train.shape[0]\ntargets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#create model\nmodel_0 = Sequential()\n\n#add model layers\nmodel_0.add(Dense(220, activation='relu', input_shape=(n_cols,))) # ‘n_cols,’. There is nothing after the comma which  \nmodel_0.add(BatchNormalization())                                                                  #  indicates that there can be any amount of rows.\nmodel_0.add(Dropout(0.25))\n\nmodel_0.add(Dense(420, activation='relu'))\nmodel_0.add(BatchNormalization())\nmodel_0.add(Dropout(0.25))\n\nmodel_0.add(Dense(420, activation='relu'))\nmodel_0.add(BatchNormalization())\nmodel_0.add(Dropout(0.25))\n\nmodel_0.add(Dense(1, activation='linear'))\n\n\n#compile model using accuracy to measure model performance\nmodel_0.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\nearly_stopping_monitor = EarlyStopping(patience=9)\n\n#train model\ntensor_baseline = model_0.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=100, \n                              callbacks=[early_stopping_monitor])\ntensor_baseline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_predictions = model_0.predict(X_test)\nmse = mean_squared_error(val_predictions, y_test)\nrmse = np.sqrt(mean_squared_error(val_predictions, y_test))\n\nprint('Model validation metrics')\nprint('MSE: %.2f' % mse)\nprint('RMSE: %.2f' % rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(loss, val_loss):\n    fig, (ax1) = plt.subplots(1, 1, sharex='col', figsize=(20,7))\n    ax1.plot(loss, label='Train loss')\n    ax1.plot(val_loss, label='Validation loss')\n    ax1.legend(loc='best')\n    ax1.set_title('Loss')\n    plt.xlabel('Epochs')\n    \nplot_metrics(tensor_baseline.history['loss'], tensor_baseline.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid = scaler.transform(df_test[features].values)\ny_valid = df_test.ID_code.values\nprediction = model_0.predict(X_valid)\nprediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame({\"ID_code\": y_valid})\nresult[\"target\"] = prediction\nresult.to_csv(\"submission.csv\", index=False)\nmodel_0.save('./my_model.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}