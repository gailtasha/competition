{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\n\nimport shap\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.ensemble.partial_dependence import plot_partial_dependence\nfrom sklearn.ensemble.partial_dependence import partial_dependence\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.decomposition import PCA\nfrom imblearn.over_sampling import SVMSMOTE\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2 # Memory total(Ram)\n    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        \n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            # Int\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            \n            # Float\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(pd.read_csv('../input/train.csv'))\ntest = reduce_mem_usage(pd.read_csv('../input/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## data wrangling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_percent_plot(data):\n    missing_col = list(data.isna().sum() != 0)\n    \n    try:\n        if True not in missing_col:\n            raise ValueError(\"There is no missing values.\")\n\n        data = data.loc[:,missing_col]\n\n        missing_percent = (data.isna().sum()/data.shape[0]) * 100\n\n        df = pd.DataFrame()\n        df['perc_missing'] = missing_percent\n        sns.barplot(x=df.perc_missing.index, y='perc_missing', data=df); plt.xticks(rotation=90)\n    except:\n        return print('There is no missing values...')\n    return list(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percent_plot(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def target_symmetry(train):    \n    target_0 = len(train.target[train.target == 0]) / len(train.target) * 100\n    target_1 = len(train.target[train.target == 1]) / len(train.target) * 100\n    print(\"Target : 0 exist {} percent in total target \\n\\\n           Target : 1 exist {} percent in total target \".format(target_0,\n                                                                target_1))\n    return sns.countplot(x='target', hue='target', data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_symmetry(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{},"cell_type":"markdown","source":"### Parameters selection"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def grid_model(params, train, target, model):\n    t_x, v_x, t_y, v_y = train_test_split(train, target, test_size  =.30, random_state =42)\n    \n    # xgbm = xgb.XGBClassifier()\n    # xgbm = GridSearchCV(xgbm, params, cv=3) \n    model.fit(t_x, t_y)\n    \n    t_pred = model.predict_proba(t_x)[:,1] # For train score\n    v_pred = model.predict_proba(v_x)[:,1] # For val score\n    \n    score = cross_val_score(model, train, target, cv=5)\n    # train_score = roc_auc_score(t_y, t_pred)\n    # val_score   = roc_auc_score(v_y, v_pred)\n\n    # print('roc_auc_score(t_y, t_pred)', train_score)\n    # print('roc_auc_score(v_y, v_pred)', val_score)\n    \n    return model, score, model.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Score using k-fold"},{"metadata":{"trusted":true},"cell_type":"code","source":"def shap_DP(df, feature):\n    return shap.dependence_plot(feature, shap_values, df)\n\ndef importance_plot(df, model, max_plot=30):\n    importances = pd.DataFrame({'features':list(df.columns), 'importance':model.feature_importances_})\n    importances.sort_values(by = 'importance', ascending = False, inplace = True)\n    sns.barplot(x = importances.features[:max_plot], y = importances.importance[:max_plot] , label = \"Total\", color = \"b\");plt.xticks(rotation = 45);plt.title('Feature importances')\n    return importances\n\ndef feature_correlation_heatmap(importances_df, start=0, last=10):\n    def heatmap(features):    \n        sns.set(style=\"white\")\n\n        # Compute the correlation matrix\n        corr = train.loc[:,features].corr()\n\n        # Generate a mask for the upper triangle\n        mask = np.zeros_like(corr, dtype=np.bool)\n        mask[np.triu_indices_from(mask)] = True\n\n        # Set up the matplotlib figure\n        f, ax = plt.subplots(figsize=(11, 9))\n\n        # Generate a custom diverging colormap\n        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n        # Draw the heatmap with the mask and correct aspect ratio\n        return sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                           square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, \n                           annot =True, annot_kws = {'size':9})\n\n    n_to_n = list(importances_df.features)[start:last]\n    n_to_n.append('target')\n    return heatmap(n_to_n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = dict(max_depth=7, \n                  leaning_rate=0.1, \n                  n_estimators=70, \n                  objective='binary:hinge', \n                  n_jobs=-1, \n                  random_state=42, \n                  importance_type ='gain', \n                  reg_lambda=0.2, \n                  early_stopping_rounds=3)\nxgbm = xgb.XGBClassifier(**params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_n_predict(x, y, test, model, cv=5, verbose=False):\n    \"\"\"Calculate train, validation score(roc_auc score)\"\"\"\n    \n    k = KFold(n_splits=cv)\n    t_score = 0\n    v_score = 0\n    \n    for t_i, v_i in k.split(x):\n        t_x, t_y = x.iloc[t_i].values, y.iloc[t_i].values\n        v_x, v_y = x.iloc[v_i].values, y.iloc[v_i].values\n        \n        model.fit(t_x, t_y)\n        \n        # Predict and calculate score for train and val\n        t_pred = model.predict_proba(t_x)[:,1] # For train score\n        v_pred = model.predict_proba(v_x)[:,1] # For val score\n\n        train_score = roc_auc_score(t_y, t_pred)\n        val_score   = roc_auc_score(v_y, v_pred)\n        \n        if verbose == True:\n            print('train score{} \\n\\\n                   val score{}'.format(train_score,\n                                       val_score))\n        \n        # Iteratively add score divided by k-fold\n        t_score += train_score / k.get_n_splits()\n        v_score += val_score   / k.get_n_splits()\n        \n    if verbose == True:\n        print(\"{}-fold average accuracy\".format(k.get_n_splits()))\n        print('train score : {} \\n\\\n                 val score : {}'.format(t_score,\n                                        v_score))\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_original= score_n_predict(train.iloc[:,2:], train.target, test.iloc[:,1:], xgbm, cv=3, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see there is trivial features approximatly 100 features cause using half features we can get similar result than to using orginal 200 features."},{"metadata":{"trusted":true},"cell_type":"code","source":"original_importances = importance_plot(train.iloc[:,2:], model_original, max_plot=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(model_original)\nshap_values = explainer.shap_values(train.iloc[:, 2:])\nshap.summary_plot(shap_values, train.iloc[:, 2:], max_display = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best 40 features \nmodel_2_a = score_n_predict(train[list(original_importances.features)[:40]], train.target, test[list(original_importances.features)[:40]], xgbm, cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in list(original_importances.features)[:40]:\n    sns.distplot(train[train.target == 1].loc[:, col], bins='auto', label=1)\n    sns.distplot(train[train.target == 0].loc[:, col], bins='auto', label=0); plt.legend();plt.show()\ndel model_2_a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# partial dependencies & correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_correlation_heatmap(original_importances, start=0, last=10)\nfeature_correlation_heatmap(original_importances, start=10, last=20)\n# feature_correlation_heatmap(original_importances, start=20, last=30)\n# feature_correlation_heatmap(original_importances, start=30, last=40)\n# feature_correlation_heatmap(original_importances, start=40, last=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in list(original_importances.features):\n    shap_DP(train.iloc[:, 2:], col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# worst 10 features\nfeature_correlation_heatmap(original_importances, start = 190, last = 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# worst 10 features\nfeatures_xgbm_worst = list(original_importances.features)[-10:]\nfor col in features_xgbm_worst:\n    shap_DP(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA & SMOTE\n- To control bias in data imbalance create extra data points using SVM-SMOTE."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(pd.read_csv('../input/train.csv'))\ntest = reduce_mem_usage(pd.read_csv('../input/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pca(train, test, n = 'mle'):\n    pca_1 = PCA(n_components=n);pca_2 = PCA(n_components=n)\n    return pd.DataFrame(pca_1.fit_transform(train)), pd.DataFrame(pca_2.fit_transform(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\npca_train, pca_test = pca(scaler.fit_transform(train.iloc[:,2:]),\n                          scaler.fit_transform(test.iloc[:,1:]), n=2)\n\nsm = SVMSMOTE(random_state=42, n_jobs=-1, sampling_strategy = 'minority')\nX_res, y_res = sm.fit_resample(pca_train, train.target)\npca_smote_train = pd.concat([pd.DataFrame(X_res), pd.DataFrame(y_res, columns=['target'])], axis=1)\n\n# Usig permuted index, shuffle rows of training data to prevent ValueError caused by imbalance data(only one label included in training)\npca_smote_train = pca_smote_train.iloc[np.random.permutation(np.arange(len(pca_smote_train)))]\npca_sm_model= score_n_predict(pca_smote_train.drop(['target'], axis=1), pca_smote_train.target, pca_test, xgbm, cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del pca_sm_model, pca_smote_train, X_res, y_res, sm, ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Using SVM-SMOTE, we could increase accuracy roughly 20%."},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(pd.read_csv('../input/train.csv'))\ntest = reduce_mem_usage(pd.read_csv('../input/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test = pd.concat([train, test], axis=0).reset_index()\ndel train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_test.fillna(-1, inplace=True) # test_target(np.nan) into -1\npoly = PolynomialFeatures(2, include_bias=False)\npoly.fit(train_test.loc[:,features_40])\nextra_features = pd.DataFrame(poly.transform(train_test.loc[:,features_40]))\n\nextra_features.rename(columns=lambda x: str(x) + '_poly_feature', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_ = pd.concat([train_test, extra_features], axis=1)\ndel train_test, extra_features\n\ntrain = train_test_[~train_test_.target.isna()]\ntest = train_test_[train_test_.target.isna()].drop(['target'], axis=1)\ndel train_test_\n\npca_train, pca_test = pca(train.iloc[:,3:], test.iloc[:,2:], n=2)\npca_model= score_n_predict(pca_train, train.target, pca_test, xgbm, cv=5, verbose=True)\ndel pca_train, pca_test, pca_model, pca_y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Polynomial feature engineering actually doesn't effect on accuracy."},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(pd.read_csv('../input/train.csv'))\ntest = reduce_mem_usage(pd.read_csv('../input/test.csv'))\ndef pre_processing(train, test, train_y, stantardization=False):\n    \n    # Standardization\n    if stantardization == True:\n        scaler = StandardScaler()\n        train  = scaler.fit_transform(train)\n        test   = scaler.fit_transform(test)\n    \n    # PCA & Over-sampling\n    train, test = pca(train, test, n=2)\n    sm = SVMSMOTE(random_state=42, n_jobs=-1, sampling_strategy = 'minority')\n    x, y = sm.fit_resample(train, train_y)\n     \n    train = pd.concat([pd.DataFrame(y, columns=['target']), pd.DataFrame(x)], axis=1)\n    \n    # Usig permuted index, shuffle rows of training data to prevent ValueError caused by imbalance data(only one label included in training)\n    train = train.iloc[np.random.permutation(np.arange(len(train)))]\n    return train, test\ntrain_id = train.ID_code\ntest_id  = test.ID_code\ntrain_y  = train.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = pre_processing(train.iloc[:,2:], test.iloc[:,1:], train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ntrain_y = train.target\ntrain  = pd.DataFrame(scaler.fit_transform(train.drop('target', axis=1)))\ntest   = pd.DataFrame(scaler.fit_transform(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'early_stopping_rounds': 3,\n 'importance_type': 'gain',\n 'leaning_rate': 0.1,\n 'max_depth': 15,\n 'n_estimators': 1400,\n 'n_jobs': -1,\n 'objective': 'binary:hinge',\n 'random_state': 42,\n 'reg_lambda': 0.2}\nxgbm = xgb.XGBClassifier(**params)\nxgbm.fit(train, train_y)\nxgbm_score, xgbm, xgbm_pred = GridSearchCV(xgbm, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbm_pred = xgbm.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = dict(C=[0.5, 0.1],\n              class_weight =['balanced', None], \n              random_state=[42], \n              solver = ['liblinear', 'newton-cg'], \n              n_jobs =[-1], \n              max_iter =[70, 100, 500, 1000])\nLR = LogisticRegression()\nLR = GridSearchCV(LR, params)\nLR, LR_score, LR_pred = grid_model(params, train, train_y, LR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = dict(C=[0.5],\n              class_weight =['balanced', None],\n              kernel = ['linear'],\n              random_state=[42],\n              max_iter =[100], \n              probability=[True])\nsvm = SVC()\nsvm = GridSearchCV(svm, params)\nsvm, svm_score, svm_pred = grid_model(params, train, train_y, svm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def submit(y_pred, name):\n    submission = pd.read_csv('../input/sample_submission.csv')\n    submission.target = y_pred\n    submission.target = submission.target.apply(lambda x: 0 if x < .5 else 1)\n    submission.to_csv('submission'+ name + '.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit(xgbm_pred[:, 1], name='xgbm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit(((xgbm_pred[:, 1] + svm_pred[:, 1] + LR_pred[:, 1]) / 3), name='xgbm_svm_LR')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}