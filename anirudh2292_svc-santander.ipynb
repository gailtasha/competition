{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['test.csv', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.metrics import precision_recall_fscore_support as score\n\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\n\nfrom time import time\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport seaborn as sb\n\n\nprint(os.listdir(\"../input\"))","execution_count":2,"outputs":[{"output_type":"stream","text":"['test.csv', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"95304a2b3b165c6f00dad68406d8bc60511d4e5d"},"cell_type":"code","source":"san_train = pd.read_csv('../input/train.csv')\nprint(san_train)","execution_count":3,"outputs":[{"output_type":"stream","text":"             ID_code  target    var_0   ...     var_197  var_198  var_199\n0            train_0       0   8.9255   ...      8.5635  12.7803  -1.0914\n1            train_1       0  11.5006   ...      8.7889  18.3560   1.9518\n2            train_2       0   8.6093   ...      8.2675  14.7222   0.3965\n3            train_3       0  11.0604   ...     10.2922  17.9697  -8.9996\n4            train_4       0   9.8369   ...      9.5031  17.9974  -8.8104\n5            train_5       0  11.4763   ...      9.7670  12.5809  -4.7602\n6            train_6       0  11.8091   ...      9.1143  10.8869  -3.2097\n7            train_7       0  13.5580   ...      9.4237   8.6624   3.4806\n8            train_8       0  16.1071   ...      8.1975  19.5114   4.8453\n9            train_9       0  12.5088   ...      7.9133  16.2375  14.2514\n10          train_10       0   5.0702   ...      9.2553  14.2914  -7.6652\n11          train_11       0  12.7188   ...      9.6745  16.7498  -3.9728\n12          train_12       0   8.7671   ...      8.4897  17.0938   4.6106\n13          train_13       1  16.3699   ...      9.0419  15.6064 -10.8529\n14          train_14       0  13.8080   ...      9.3439  24.4479  -5.1110\n15          train_15       0   3.9416   ...      8.2899  12.9116  -4.9182\n16          train_16       0   5.0615   ...      8.6367  20.2548  11.1524\n17          train_17       0   8.4199   ...      9.4560  19.4505  -5.2407\n18          train_18       0   4.8750   ...      8.5873  17.1516 -22.1940\n19          train_19       0   4.4090   ...      9.1711  14.7352   3.9133\n20          train_20       0  12.6700   ...      8.2176  22.4754 -19.9444\n21          train_21       0   8.3918   ...      7.7761  17.4662  11.3979\n22          train_22       0  10.2031   ...      9.5064   8.7281 -25.6523\n23          train_23       0  15.0029   ...      9.4714  12.8480 -10.0357\n24          train_24       0   5.9240   ...     10.2561  14.3032   2.0897\n25          train_25       0   8.2703   ...      9.5360  17.8582  -3.3911\n26          train_26       0  15.6567   ...      7.8821  19.3055  -7.5090\n27          train_27       0  10.7166   ...      7.9933  20.2128  -1.7144\n28          train_28       0   7.8010   ...      9.8715  14.0120  -4.5997\n29          train_29       1   5.3301   ...      9.4513  17.4105 -14.6897\n...              ...     ...      ...   ...         ...      ...      ...\n199970  train_199970       0  15.5794   ...      7.8741  18.4707  -6.4407\n199971  train_199971       0  14.5745   ...      7.1448  16.4238  15.5478\n199972  train_199972       0   7.4206   ...      7.6474  17.9137  -8.8790\n199973  train_199973       0   8.7758   ...      8.2211  16.1504  22.6103\n199974  train_199974       0  16.2010   ...      9.8244  17.6050   3.5219\n199975  train_199975       0   7.5238   ...      7.3537  20.0787 -15.7676\n199976  train_199976       1   7.9663   ...      8.4627  14.3604  -1.6688\n199977  train_199977       0   7.3884   ...      9.0411  15.8939   1.6908\n199978  train_199978       0  12.2015   ...      7.5484  13.1150   6.7866\n199979  train_199979       0  10.8208   ...      9.5072  17.3854  -4.0844\n199980  train_199980       0   7.9618   ...      8.2107  14.5403  -8.7837\n199981  train_199981       1  12.8140   ...      8.6519  16.0341   7.3809\n199982  train_199982       0  11.8224   ...      8.2403  15.0018 -11.7721\n199983  train_199983       0  15.3063   ...      9.7643  16.9017   6.8054\n199984  train_199984       0  11.3184   ...     10.1784  17.1267 -16.5440\n199985  train_199985       0   9.0249   ...      8.1901  18.5124 -15.6321\n199986  train_199986       1  12.0298   ...      8.8019  15.0031  -0.3659\n199987  train_199987       0   8.0438   ...      8.1765  19.5095 -13.3091\n199988  train_199988       0  10.8657   ...      8.1970  14.7355   7.4554\n199989  train_199989       0  11.7554   ...      6.8686  19.5728  10.0835\n199990  train_199990       1  14.1475   ...      9.1627  13.8077  -1.9646\n199991  train_199991       0   9.9909   ...      8.5414  13.2895  -6.7896\n199992  train_199992       0  12.2825   ...     10.1758  17.4066 -11.5244\n199993  train_199993       0  13.2152   ...      8.9709  14.5405   6.1149\n199994  train_199994       0  12.3925   ...      9.1164  16.3170  -7.5048\n199995  train_199995       0  11.4880   ...      8.5326  16.6660 -17.8661\n199996  train_199996       0   4.9149   ...      6.7419  15.9054   0.3388\n199997  train_199997       0  11.2232   ...      8.7155  13.8329   4.1995\n199998  train_199998       0   9.7148   ...     10.0342  15.5289 -13.9001\n199999  train_199999       0  10.8762   ...      8.1857  12.1284   0.1385\n\n[200000 rows x 202 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = san_train.drop(['target','ID_code'], axis=1)\n\ny = san_train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=17)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sorted(sklearn.metrics.SCORERS.keys()))","execution_count":6,"outputs":[{"output_type":"stream","text":"['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'brier_score_loss', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n('clf', SVC(kernel='rbf', gamma = 0.01, C=100))\n])\n\nparameters = {\n'clf__gamma': (0.01,0.03,0.1,0.3,1),\n'clf__C': (0.1,0.3,1,3,10,30),\n'clf__kernel':('linear','poly')\n}\n\ngrid_search = GridSearchCV(pipeline,parameters,n_jobs=2,verbose=1,scoring='accuracy')\ngrid_search.fit(X_train[:1000],y_train[:1000])\nprint('Best score: %0.3f' % grid_search.best_score_)\nprint('Best parameters set:')\nbest_parameters = grid_search.best_estimator_.get_params()\nfor param_name in sorted(best_parameters.keys()):\n    print('\\t%s: %r' % (param_name,best_parameters[param_name]))\npredictions = grid_search.predict(X_test)\nprint(classification_report(y_test,predictions))","execution_count":7,"outputs":[{"output_type":"stream","text":"Fitting 3 folds for each of 60 candidates, totalling 180 fits\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.1s\n[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:   16.9s finished\n","name":"stderr"},{"output_type":"stream","text":"Best score: 0.883\nBest parameters set:\n\tclf: SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='poly',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n\tclf__C: 0.1\n\tclf__cache_size: 200\n\tclf__class_weight: None\n\tclf__coef0: 0.0\n\tclf__decision_function_shape: 'ovr'\n\tclf__degree: 3\n\tclf__gamma: 0.01\n\tclf__kernel: 'poly'\n\tclf__max_iter: -1\n\tclf__probability: False\n\tclf__random_state: None\n\tclf__shrinking: True\n\tclf__tol: 0.001\n\tclf__verbose: False\n\tmemory: None\n\tsteps: [('clf', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='poly',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]\n              precision    recall  f1-score   support\n\n           0       0.91      0.97      0.94     17994\n           1       0.37      0.17      0.23      2006\n\n   micro avg       0.89      0.89      0.89     20000\n   macro avg       0.64      0.57      0.59     20000\nweighted avg       0.86      0.89      0.87     20000\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"san_test = pd.read_csv('../input/test.csv')\nprint(san_test)","execution_count":8,"outputs":[{"output_type":"stream","text":"            ID_code    var_0    var_1   ...     var_197  var_198  var_199\n0            test_0  11.0656   7.7798   ...     10.7200  15.4722  -8.7197\n1            test_1   8.5304   1.2543   ...      9.8714  19.1293 -20.9760\n2            test_2   5.4827 -10.3581   ...      7.0618  19.8956 -23.1794\n3            test_3   8.5374  -1.3222   ...      9.2295  13.0168  -4.2108\n4            test_4  11.7058  -0.1327   ...      7.2882  13.9260  -9.1846\n5            test_5   5.9862  -2.2913   ...      9.8117  17.1127  10.8240\n6            test_6   8.4624  -6.1065   ...      9.1509  18.4736   5.1499\n7            test_7  17.3035  -2.4212   ...     10.4855  23.4631   0.7283\n8            test_8   6.9856   0.8402   ...      9.9207  16.9865  -3.3304\n9            test_9  10.3811  -6.9348   ...      9.5788  15.8146   9.3457\n10          test_10   8.3431  -4.1427   ...     10.1361  12.1140  -2.4978\n11          test_11  10.6137  -2.1898   ...      9.2355  15.0721  -7.3475\n12          test_12  12.7465  -4.9467   ...      8.9599  16.9317 -14.0779\n13          test_13  11.7836   1.9979   ...     10.0379  20.5904   6.0166\n14          test_14   7.0360   1.6797   ...      8.2077  17.6097  -0.9141\n15          test_15  14.8595  -4.5378   ...     10.2848  17.4932   6.0800\n16          test_16  14.1732  -5.1490   ...      9.3406  21.1746  -2.0098\n17          test_17   9.0936  -8.7414   ...      9.3114  23.0545  -2.3171\n18          test_18  15.7875   0.1671   ...      9.3848  14.4007  11.2567\n19          test_19  13.3874   1.0716   ...      8.1116  20.5129   5.4945\n20          test_20   8.0259  -4.6740   ...      7.8690  18.1980  -3.7655\n21          test_21  14.3356   0.2317   ...     10.7644  18.0992  -7.6905\n22          test_22  10.4255  -6.1758   ...      9.0132  16.9635   3.2523\n23          test_23  12.3322  -6.3835   ...      8.2489  22.4405  -5.4524\n24          test_24  14.1844  -9.1044   ...      7.9695  12.6078   7.3475\n25          test_25  10.0029   0.2530   ...      6.9239  18.6460 -17.7609\n26          test_26   6.9056  -4.8626   ...      8.0712  16.6316   7.8962\n27          test_27   8.7562  -3.0647   ...      8.7277  16.8255 -18.6596\n28          test_28   9.7243  -1.5151   ...      8.6899  14.5739  16.2884\n29          test_29  13.2430   1.2738   ...      8.4667  15.1478   6.2962\n...             ...      ...      ...   ...         ...      ...      ...\n199970  test_199970  12.7260  -1.6706   ...      9.1059  19.3888  -7.6292\n199971  test_199971   9.4700  -6.7655   ...      8.2742  18.2273  -1.0124\n199972  test_199972  13.3243   1.0870   ...      9.7116  15.5697  -0.7362\n199973  test_199973  14.2830  -1.8421   ...      7.8924  16.0279   7.8535\n199974  test_199974   4.5171  -5.2068   ...      8.0088  14.3127  -1.2940\n199975  test_199975  13.4796   2.7000   ...      8.7922  19.6428 -24.7859\n199976  test_199976  12.6337  -6.9793   ...     10.6610  11.5385 -23.6067\n199977  test_199977  10.8078  -4.6108   ...     10.0748  16.0592 -14.0012\n199978  test_199978   9.9317  -2.2815   ...      7.7696  10.9202 -23.5055\n199979  test_199979  10.5933  -1.2672   ...      8.3203  13.0791  -5.1262\n199980  test_199980  13.4136   5.3912   ...      9.7953  16.9352   0.2655\n199981  test_199981   7.9218  -5.7464   ...      8.1402  19.2653 -30.3989\n199982  test_199982   7.2189   1.6606   ...      8.3144  19.3602  -3.0895\n199983  test_199983  11.8527   5.4321   ...      9.2620  14.0587   5.5770\n199984  test_199984  12.7445  -6.1135   ...      9.1933  13.7584   4.3670\n199985  test_199985  14.8983   2.1302   ...      8.9479  12.8983   8.3530\n199986  test_199986  19.2884  -2.8384   ...      8.3441  14.5823   0.7454\n199987  test_199987  11.2942   3.6321   ...      7.9463  14.1967   9.8560\n199988  test_199988   6.4535  -2.1707   ...      9.4572  13.1265  -6.5024\n199989  test_199989   9.0436  -3.0491   ...      8.1526   9.0933   0.8644\n199990  test_199990   5.5416   1.7340   ...      9.6883  12.6723 -16.4310\n199991  test_199991   8.7935  -4.0646   ...      8.6422  13.7302 -21.5712\n199992  test_199992  16.4229  -5.0254   ...     10.3218   8.2577   5.2651\n199993  test_199993  14.6764  -8.1066   ...     10.4270  17.4970 -13.0074\n199994  test_199994   8.2964  -2.3119   ...      7.6434  13.0871  -4.3982\n199995  test_199995  13.1678   1.0136   ...      9.1568  18.2102   4.8801\n199996  test_199996   9.7171  -9.1462   ...      9.1112  18.1740 -20.7689\n199997  test_199997  11.6360   2.2769   ...      9.1933  11.7905 -22.2762\n199998  test_199998  13.5745  -0.5134   ...      8.1079   8.7735  -0.2122\n199999  test_199999  10.4664   1.8070   ...     10.3378  14.3340  -7.7094\n\n[200000 rows x 201 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_orig = grid_search.predict(san_test[X_train.columns])\ny_pred_final =pd.DataFrame(y_pred_orig,columns=[\"target\"])\ndf_out = pd.concat([san_test.ID_code,y_pred_final], axis=1 )\ndf_out.to_csv('SAN_SVC.csv', index=False)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}