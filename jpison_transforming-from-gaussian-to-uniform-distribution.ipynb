{"cells":[{"metadata":{"_uuid":"eadd3c7e5676351608e7c40ac9b58537bb6cd978"},"cell_type":"markdown","source":"Transforming Features from Gaussian Distribution to Uniform Distribution...\n\nPlots density and histograms are interesting.\n\nCan they really useful to create new categorical features?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport logging\nfrom datetime import datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')\nfrom sklearn import decomposition\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# Code from: https://stackoverflow.com/questions/45028260/gaussian-to-uniform-distribution-conversion-has-errors-at-the-edges-of-uniform-d\ndef gaussian_estimation(vector):\n    mu = np.mean(vector)\n    sig = np.std(vector)\n    return mu, sig\n\n# Adjusts the data so it forms a gaussian with mean of 0 and std of 1\ndef gaussian_normalization(vector, char = None):\n    if char is None:\n        mu , sig = gaussian_estimation(vector)\n    else:\n        mu = char[0]\n        sig = char[1]\n    normalized = (vector-mu)/sig\n    return normalized\n\n# Taken from https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function\ndef CDF(x, max_i = 100):\n    sum = x\n    value = x\n    for i in np.arange(max_i)+1:\n        value = value*x*x/(2.0*i+1)\n        sum = sum + value\n    return 0.5 + (sum/np.sqrt(2*np.pi))*np.exp(-1*(x*x)/2)\n\ndef gaussian_to_uniform(vector, if_normal = False):\n    if (if_normal == False):\n        vector = gaussian_normalization(vector)\n    uni = np.apply_along_axis(CDF, 0, vector)\n    return uni\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8162f48940b02319174d56468fde05f84af7113d"},"cell_type":"code","source":"# Original DB\ntrain_df_orig = pd.read_csv(\"../input/train.csv\")\ntest_df_orig = pd.read_csv(\"../input/test.csv\")\ntarget = train_df_orig['target']\norig_features = [c for c in train_df_orig.columns if c not in ['ID_code', 'target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d754bb786b500121d0fd052895e5b4f89be6cf9d"},"cell_type":"code","source":"# Convert features to Uniform Distribution\ntrain_uniform = pd.DataFrame()\ntest_uniform = pd.DataFrame()\nbin_cnt = 10**3\nfor namecol in tqdm_notebook(orig_features):\n    train_uniform[namecol+'_unif'] = gaussian_to_uniform(train_df_orig[namecol])\n    test_uniform[namecol+'_unif'] = gaussian_to_uniform(test_df_orig[namecol]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d7218910442ce05fcea0ec9f65f45e935bcf474"},"cell_type":"code","source":"# Code thanks to: https://www.kaggle.com/youhanlee/yh-eda-i-want-to-see-all\nfrom scipy.stats import ks_2samp\ntarget_mask = train_df_orig['target'] == 1\nnon_target_mask = train_df_orig['target'] == 0 \nstatistics_array = []\nfor col in tqdm_notebook(train_uniform.columns):\n    statistic, pvalue = ks_2samp(train_uniform.loc[non_target_mask, col], train_uniform.loc[target_mask, col])\n    statistics_array.append(statistic)\n    fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n    sns.kdeplot(train_uniform.loc[non_target_mask, col], ax=ax, label='Target == 0')\n    sns.kdeplot(train_uniform.loc[target_mask, col], ax=ax, label='Target == 1')\n    ax.set_title('name: {}, statistics: {:.5f}, pvalue: {:5f}'.format(col, statistic, pvalue))\n    plt.show()\n    \n    fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n    sns.distplot(train_uniform.loc[non_target_mask, col], bins=50, kde=False, rug=False);\n    sns.distplot(train_uniform.loc[target_mask, col], bins=50, kde=False, rug=False);\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e2013af8556788e0b659bc0630bea7f34aa2635"},"cell_type":"code","source":"train_df = pd.concat([train_df_orig[orig_features],train_uniform],axis=1)\ntest_df = pd.concat([test_df_orig[orig_features],test_uniform],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eaa81ec9d5149f8d51e07eb8f25deb88b408773"},"cell_type":"code","source":"features = [c for c in train_df.columns if c not in ['target', 'ID_code']]\n\nparam = {\n    'bagging_freq': 5,          \n    'bagging_fraction': 0.30,   \n    'boost_from_average':'false',   \n    'boost': 'gbdt',\n    'feature_fraction': 0.03368,   \n    'learning_rate': 0.01,      \n    'max_depth': -1,                \n    'metric':'auc',\n    'min_data_in_leaf': 80,     \n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 4,           \n    'tree_learner': 'serial',   \n    'objective': 'binary',      \n    'verbosity': 1\n}\n\nnfolds = 5\n\nfolds = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=31415)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nAUC_l = []\niter_l = []\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 500000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, \n                    early_stopping_rounds = 250)\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n\n    AUC_l.append(roc_auc_score(target[val_idx], oof[val_idx]))\n    iter_l.append(clf.best_iteration)\n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score:{:<8.5f} CV_stats:[{:<8.5f}, {:<8.5f} ({:<8.5f}), {:<8.5f}]\".format(roc_auc_score(target, oof),np.min(AUC_l),np.mean(AUC_l), np.std(AUC_l), np.max(AUC_l)))\nscore = roc_auc_score(target, oof)\nbest_iter = np.mean(iter_l)\nbest_score_final = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d63cc6e994dd316cf53eae2cf8c9d7eccf6fb7ac"},"cell_type":"code","source":"# Submission\nsub_df = pd.DataFrame({\"ID_code\":test_df_orig[\"ID_code\"].values})\nsub_df[\"target\"] = predictions\nsub_df.to_csv('submission.csv.gz', index=False, compression='gzip')\nprint(pd.read_csv('submission.csv.gz').head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}