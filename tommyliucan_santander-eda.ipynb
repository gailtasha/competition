{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import the commonly used packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## Data manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import stats\n\n## Visualization\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n%matplotlib inline\nplt.style.use('seaborn')\n\n## Modeling\nfrom sklearn.preprocessing import StandardScaler\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD, PCA, LatentDirichletAllocation, NMF\nfrom sklearn.linear_model import Ridge,ElasticNet, SGDRegressor, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom scipy import sparse\nfrom scipy.stats import norm, skew\n\nfrom sklearn.manifold import TSNE\n\n## others\nimport copy\nimport os\nimport time\nimport warnings\nimport gc\nimport os\nimport pickle\nfrom six.moves import urllib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\nfull_data = pd.concat([train_data, test_data])\n\nprint(\"train_data:\", train_data.info())\nprint(\"test_data:\", test_data.info())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preview the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define Variables that are useful for later use"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerical features\nnum_vars = []\n# Categorical features\ncat_vars = []\nfor var, dtype in full_data.dtypes.items():\n    if \"float\" in str(dtype) or \"int\" in str(dtype):\n        num_vars.append(var)\n    if \"object\" in str(dtype):\n        cat_vars.append(var)\n\nid_var = \"ID_code\" # this is just the order of data\ncat_vars.remove(id_var)\ntarget_var = \"target\"\nnum_vars.remove(target_var)\nprint(\"There are %d numerical features: %s\" %(len(num_vars), num_vars))\nprint(\"There are %d numerical features: %s\" %(len(cat_vars), cat_vars))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA (Exploratory Data Analysis)\n* Basic statistics: count, std, min, max, mean, median, quartiles\n* Distributions\n* Missing values\n* Unique values\n* Feature correlations\n* Feature importance[](http://)"},{"metadata":{},"cell_type":"markdown","source":"## Basic statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis= 1, keys = ['total', 'percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt[\"Type\"] = types\n    return np.transpose(tt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unique values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_unique_1= train_data[num_vars].nunique().reset_index()\ntrain_unique_2 = train_unique_1.rename(columns = {\"index\":'feature', 0:'unique'}).sort_values('unique')\nsns.barplot(x = 'feature', y = 'unique', color = 'b', data = train_unique_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_unique_1= test_data[num_vars].nunique().reset_index()\ntest_unique_2 = test_unique_1.rename(columns = {\"index\":'feature', 0:'unique'}).sort_values('unique')\nsns.barplot(x = 'feature', y = 'unique', color = 'b', data = test_unique_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Standardization"},{"metadata":{},"cell_type":"markdown","source":"    - Removing the mean and scaling to unit variance: x_new = (x - u)/sigma\n    - Required by SVM/ K-means.\n    - Good for linear models, such as Linear regression, Logistic Regression, LASSO/ Ridge and NN to converge faster\n    - No need for tree models****"},{"metadata":{"trusted":true},"cell_type":"code","source":"std_scaler = StandardScaler()\n# Notice we are using full datasets in order to capture more information\nstd_scaler.fit(full_data[num_vars].values) \ntrain_std_df = pd.DataFrame(std_scaler.transform(train_data[num_vars].values), columns=num_vars)\ntest_std_df = pd.DataFrame(std_scaler.transform(test_data[num_vars].values) , columns=num_vars)\n\ntrain_std_df['target'] = train_data['target'].values\ntrain_std_df[num_vars].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_data = full_data[num_vars].corr()\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True) # Use different colors by palette\n# Draw the heatmap with the mask and correct aspect ratio\n# sns.heatmap(corr_data)    , cbar_kws={\"shrink\": .5}\nsns.heatmap(corr_data, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normality tests\nUsing scipy.stats.normaltest(). If p<0.05, the data is normally distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_norm_data = train_data[num_vars].apply(lambda x: stats.normaltest(x)[1])\nprint(\"There are %d features normally distributed.\" % ((train_norm_data<0.05).sum()))\n\nprint(\"Top 10 features with highest P value:\")\ntrain_norm_data.sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_norm_data = test_data[num_vars].apply(lambda x: stats.normaltest(x)[1])\nprint(\"There are %d features normally distributed.\" % ((test_norm_data<0.05).sum()))\n\nprint(\"Top 10 features with highest P value:\")\ntest_norm_data.sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the features with highest P value"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot var_146\nsns.distplot(train_data['var_146'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pair plotting"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train_data[num_vars[:20] + ['target']][:10000], hue='target')\n# 1: green; 0: blue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Visualization with Dimension Reduction"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Dimension reduction is used to reducing the number of random variables under consideration by obtaining a set of principal variables. \n\nThe most common approaches are \n* PCA\n* TruncatedSVD\n* TSNE\n \n TSNE is considered as the go-to algorithms for visualizing higher dimensional data.\n     https://distill.pub/2016/misread-tsne/\n "},{"metadata":{},"cell_type":"markdown","source":"#### PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npca = PCA(n_components = 2)\npca2d = pca.fit_transform(train_data[num_vars][:10000].values)\npca2d_df = pd.DataFrame({'pca_0':pca2d[:,0], 'pca_1':pca2d[:,1], 'target': train_data['target'][:10000].values})\nsns.lmplot(x='pca_0', y='pca_1', data=pca2d_df, hue='target', fit_reg=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TruncatedSVD"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n## 2D\nsvd = TruncatedSVD(n_components=2)\nsvd2d = svd.fit_transform(train_data[num_vars][:10000].values)\nsvd2d_df = pd.DataFrame({'svd_0':svd2d[:,0],'svd_1':svd2d[:,1],'target':train_data['target'][:10000].values})\nsns.lmplot(x='svd_0', y='svd_1', data=svd2d_df, hue='target', fit_reg=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TSNE"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 1D\ntsne = TSNE(n_components=1)\ntsne1d = tsne.fit_transform(train_data[num_vars][:10000].values)\ntsne1d_df = pd.DataFrame({'tsne_0':tsne1d.reshape(-1), 'target':train_data['target'][:10000].values})\nsns.distplot(tsne1d_df.query('target==0')['tsne_0'], label='target:0')\nsns.distplot(tsne1d_df.query('target==1')['tsne_0'], label='target:1')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n## 2D\ntsne = TSNE(n_components=2, perplexity = 50, n_iter = 2000)\ntsne2d = tsne.fit_transform(train_data[num_vars][:10000].values)\ntsne2d_df = pd.DataFrame({'tsne_0':tsne2d[:,0],'tsne_1':tsne2d[:,1],'target':train_data['target'][:10000].values})\nsns.lmplot(x='tsne_0', y='tsne_1', data=tsne2d_df, hue='target', fit_reg=False)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature importance"},{"metadata":{},"cell_type":"markdown","source":"## Feature importance from logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_x = train_std_df[num_vars].values\ntrain_y = train_std_df['target'].values\ntest_x = test_std_df[num_vars].values\n\nlr = LogisticRegression()\nlr.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_feature_importance = pd.DataFrame({'feature':num_vars, 'lr_importance':lr.coef_.reshape(-1), \n                                      'abs_lr_importance': abs(lr.coef_.reshape(-1))})\n                            \nlr_feature_importance.sort_values('abs_lr_importance', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature importance from LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlgb_clf = lgb.LGBMClassifier(n_jobs=-1)\nlgb_clf.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_feature_importance = pd.DataFrame({'feature':num_vars, \n                                       'lgb_importance':lgb_clf.feature_importances_.reshape(-1)})\n                                        \nlgb_feature_importance.sort_values('lgb_importance', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combined feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = pd.merge(lr_feature_importance, lgb_feature_importance, on='feature')\nfeature_importance.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource\n\noutput_notebook()\n\nTOOLTIPS = [\n    (\"Feature\", \"@feature\"),\n    (\"LR importance\", \"@abs_lr_importance\"),\n    (\"LGB importance\", \"@lgb_importance\")\n]\np = figure(plot_width=400, plot_height=400, tooltips=TOOLTIPS)\np.circle('abs_lr_importance', \n         'lgb_importance', source=ColumnDataSource(feature_importance), size=8)\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Examine Features that are important in Both analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_std_df['var_53'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# var_53 against target\nsns.distplot(train_std_df.query('target==0')['var_53'], label='target:0')\nsns.distplot(train_std_df.query('target==1')['var_53'], label='target:1')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly, we can look at another important variant"},{"metadata":{"trusted":true},"cell_type":"code","source":"# var_81 against target\nsns.distplot(train_std_df.query('target==0')['var_81'], label='target:0')\nsns.distplot(train_std_df.query('target==1')['var_81'], label='target:1')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Additional readings\n* [Applied Predictive Modeling - Chapter 3 Data Pre-Processing](http://appliedpredictivemodeling.com/toc/)\n* [机器学习特征工程实用技巧大全](https://zhuanlan.zhihu.com/p/26444240)\n* [Discover Feature Engineering](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n* [Selecting good features – Part IV: stability selection, RFE and everything side by side](http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}