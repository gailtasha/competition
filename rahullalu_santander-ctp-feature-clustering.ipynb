{"cells":[{"metadata":{"_uuid":"c876266c689ff6619b7b770fd24ec93606d0fa51"},"cell_type":"markdown","source":"\n<h2>Problem Statement</h2>\n\nIn this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted.\n\n<br><br>\nSubmissions are scored on the <b>area under the ROC curve</b>. :\n\n![area under the ROC curve](https://developers.google.com/machine-learning/crash-course/images/AUC.svg)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#IMPORTING REQUIRED LIBRARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nfrom lightgbm.sklearn import LGBMRegressor\nfrom lightgbm.sklearn import LGBMClassifier\nimport lightgbm as lgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA,KernelPCA,NMF\n\nfrom sklearn.metrics import roc_auc_score,accuracy_score\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport gc\ngc.enable()\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#All functions\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Unique_Count','Max','Min','Mean','Std','Skewness','Median']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    #df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    #df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max']=str(round(df_fa[col].max(),2))\n            df.at[col,'Min']=str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n            df.at[col,'Median']=df_fa[col].median()\n            \n        \n    return(df.fillna('-'))\n\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c649fb010cfe9db75ccf0ad2cfb2a2b284a46c6","scrolled":false},"cell_type":"code","source":"#DATASET VIEW\npath1=\"../input/\"\ndata_files=list(os.listdir(path1))\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(path1+x).st_size/(1024*1024),2))\ndf_files","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"               File_Name  Size_in_MB\n0  sample_submission.csv        2.56\n1               test.csv      287.56\n2              train.csv      288.14","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File_Name</th>\n      <th>Size_in_MB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sample_submission.csv</td>\n      <td>2.56</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test.csv</td>\n      <td>287.56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train.csv</td>\n      <td>288.14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5249b21bb798046ef0a55a45121b135c038f92d8"},"cell_type":"code","source":"%%time\n#READING AVAILABLE FILES DATASET\n#HISTORICAL TRANSACTIONS FILE IS A LARGE ONE \n#SO WE WILL BE READING IT IN PARTS\nprint('reading train dataset...')\ndf_train=pd.read_csv(path1+'train.csv')\nprint('reading test dataset...')\ndf_test=pd.read_csv(path1+'test.csv')\nprint('submission file')\ndf_submission=pd.read_csv(path1+'sample_submission.csv')","execution_count":4,"outputs":[{"output_type":"stream","text":"reading train dataset...\nreading test dataset...\nsubmission file\nCPU times: user 15.9 s, sys: 4.6 s, total: 20.5 s\nWall time: 20.5 s\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"c6386b602b73714c3e3a47ceaa7f56a619e91bf4"},"cell_type":"code","source":"#CREATING FINAL X, y and test SETS\nX=df_train.drop(['ID_code','target'],axis=1)\ny=df_train['target']\ntest=df_test.drop(['ID_code'],axis=1)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9883843e6e75c61c4a95270770ed509471599ed5"},"cell_type":"code","source":"df_combi=pd.concat([X,test],axis=0)\ndf_fs=feature_summary(df_combi)","execution_count":6,"outputs":[{"output_type":"stream","text":"DataFrame shape\nrows: 400000\ncols: 200\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"484587766133ab0a6903d06e901dc007f6f1d893"},"cell_type":"code","source":"n_clus=3\ncluster = KMeans(n_clusters=n_clus, random_state=0, n_jobs=-1)\nmodel=cluster.fit(df_fs)\ndf_fs['labels']=model.labels_","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"781cdd3f1bd2c255fdc957d301c44eed0dfd32b7"},"cell_type":"code","source":"df_fs.groupby('labels').count()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"        Unique_Count  Max  Min  Mean  Std  Skewness  Median\nlabels                                                     \n0                 28   28   28    28   28        28      28\n1                 20   20   20    20   20        20      20\n2                 24   24   24    24   24        24      24\n3                 13   13   13    13   13        13      13\n4                 30   30   30    30   30        30      30\n5                 16   16   16    16   16        16      16\n6                 17   17   17    17   17        17      17\n7                 16   16   16    16   16        16      16\n8                 21   21   21    21   21        21      21\n9                 15   15   15    15   15        15      15","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unique_Count</th>\n      <th>Max</th>\n      <th>Min</th>\n      <th>Mean</th>\n      <th>Std</th>\n      <th>Skewness</th>\n      <th>Median</th>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>21</td>\n      <td>21</td>\n      <td>21</td>\n      <td>21</td>\n      <td>21</td>\n      <td>21</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"e0ea59a11b95850b4f6320d41bf0e5bf16f1851c"},"cell_type":"code","source":"print(X.shape,y.shape,test.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(200000, 200) (200000,) (200000, 200)\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"ec8c4b83e0071f0bc5230e964b74b772503f025e"},"cell_type":"code","source":"for i in range(n_clus):\n    f_list=list(df_fs[df_fs.labels==i].index)\n    print('cluster id:',i+1,'\\tfeature cluster item count:',len(f_list))","execution_count":10,"outputs":[{"output_type":"stream","text":"cluster id: 1 \tfeature cluster item count: 28\ncluster id: 2 \tfeature cluster item count: 20\ncluster id: 3 \tfeature cluster item count: 24\ncluster id: 4 \tfeature cluster item count: 13\ncluster id: 5 \tfeature cluster item count: 30\ncluster id: 6 \tfeature cluster item count: 16\ncluster id: 7 \tfeature cluster item count: 17\ncluster id: 8 \tfeature cluster item count: 16\ncluster id: 9 \tfeature cluster item count: 21\ncluster id: 10 \tfeature cluster item count: 15\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"890ce4c54313ec0ff753ccfccc37711970696871","scrolled":false},"cell_type":"code","source":"%%time\n#CREATING FINAL MODEL WITH STRATIFIED KFOLDS\n#FOLD COUNT 10\n#TRIED XGBClassifier, LGBMClassifier, CatBoostClassifier\n#BEST SCORE ACHIEVED BY CatBoostClassifier\n\nparam = {\n    'bagging_freq': 5,          \n    'bagging_fraction': 0.38,   'boost_from_average':'false',   \n    'boost': 'gbdt',             'feature_fraction': 0.04,     'learning_rate': 0.0085,\n    'max_depth': -1,             'metric':'auc',                'min_data_in_leaf': 80,     'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,            'num_threads': 8,              'tree_learner': 'serial',   'objective': 'binary',\n    'reg_alpha': 0.1302650970728192, 'reg_lambda': 0.3603427518866501,'verbosity': -1\n}\n\n\n#DATAFRAMES FOR STORING PREDICTIONS ON TRAIN DATA AS WELL AS TEST DATA\n#CAN BE USED FOR ENSEMBLE \ndf_preds=pd.DataFrame()\ndf_preds_x=pd.DataFrame()\n\n\n\nfor i in range(n_clus):\n    f_list=list(df_fs[df_fs.labels==i].index)\n    print('Starting predicting cluster:',i+1)\n    \n    k=1\n    splits=10\n    avg_score=0\n    \n    #CREATING STRATIFIED FOLDS\n    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\n    print('\\nStarting KFold iterations...')\n    X1=X[f_list]\n    test1=test[f_list]\n    \n    for train_index,test_index in skf.split(X1,y):\n        df_X=X1.iloc[train_index,:]\n        df_y=y.iloc[train_index]\n        val_X=X1.iloc[test_index,:]\n        val_y=y.iloc[test_index]\n\n        #FITTING MODEL\n    \n\n        trn_data = lgb.Dataset(df_X, label=df_y)\n        val_data = lgb.Dataset(val_X, label=val_y)\n        model= lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 2000)\n        col_name='X_'+str(i+1)+'_'+str(k)\n#PREDICTING ON VALIDATION DATA\n        \n        preds_x=model.predict(val_X,num_iteration=model.best_iteration)\n        df_preds_x[col_name]=model.predict(X1,num_iteration=model.best_iteration)\n#CALCULATING ACCURACY\n        acc=roc_auc_score(val_y,preds_x)\n        print('Iteration:',k,'  roc_auc_score:',acc)\n        \n#         col_name='P_'+str(i+1)+'_'+str(k)\n        if k==1:\n            score=acc\n            preds=model.predict(test1,num_iteration=model.best_iteration)\n            df_preds[col_name]=preds#model.predict(test,num_iteration=model.best_iteration)\n        else:\n            preds1=model.predict(test1,num_iteration=model.best_iteration)\n            preds=preds+preds1\n            df_preds[col_name]=preds1#model.predict(test,num_iteration=model.best_iteration)\n        \n        if score<acc:\n            score=acc\n            \n        avg_score=avg_score+acc        \n        k=k+1\n    \n    print('\\n Best score:',score,' Avg Score:',avg_score/splits)\n","execution_count":11,"outputs":[{"output_type":"stream","text":"Starting predicting cluster: 1\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708143\tvalid_1's auc: 0.683282\n[2000]\ttraining's auc: 0.712722\tvalid_1's auc: 0.683696\n[3000]\ttraining's auc: 0.715874\tvalid_1's auc: 0.683356\nEarly stopping, best iteration is:\n[1721]\ttraining's auc: 0.712056\tvalid_1's auc: 0.684093\nIteration: 1   roc_auc_score: 0.6840932904263076\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708553\tvalid_1's auc: 0.679262\n[2000]\ttraining's auc: 0.712976\tvalid_1's auc: 0.679391\n[3000]\ttraining's auc: 0.715792\tvalid_1's auc: 0.679333\nEarly stopping, best iteration is:\n[1895]\ttraining's auc: 0.712655\tvalid_1's auc: 0.679776\nIteration: 2   roc_auc_score: 0.6797312144187074\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708178\tvalid_1's auc: 0.684897\n[2000]\ttraining's auc: 0.712584\tvalid_1's auc: 0.686962\n[3000]\ttraining's auc: 0.71539\tvalid_1's auc: 0.686613\nEarly stopping, best iteration is:\n[1761]\ttraining's auc: 0.711956\tvalid_1's auc: 0.687597\nIteration: 3   roc_auc_score: 0.6875972278684399\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.707998\tvalid_1's auc: 0.68744\n[2000]\ttraining's auc: 0.712261\tvalid_1's auc: 0.689441\n[3000]\ttraining's auc: 0.71517\tvalid_1's auc: 0.689534\n[4000]\ttraining's auc: 0.717879\tvalid_1's auc: 0.68871\nEarly stopping, best iteration is:\n[2206]\ttraining's auc: 0.713026\tvalid_1's auc: 0.689916\nIteration: 4   roc_auc_score: 0.6898807242276666\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708627\tvalid_1's auc: 0.677434\n[2000]\ttraining's auc: 0.712934\tvalid_1's auc: 0.678045\n[3000]\ttraining's auc: 0.716228\tvalid_1's auc: 0.678009\nEarly stopping, best iteration is:\n[1214]\ttraining's auc: 0.71002\tvalid_1's auc: 0.67881\nIteration: 5   roc_auc_score: 0.6787499688881884\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.709686\tvalid_1's auc: 0.669961\n[2000]\ttraining's auc: 0.714109\tvalid_1's auc: 0.671336\n[3000]\ttraining's auc: 0.717134\tvalid_1's auc: 0.670763\n[4000]\ttraining's auc: 0.719772\tvalid_1's auc: 0.669776\nEarly stopping, best iteration is:\n[2041]\ttraining's auc: 0.71429\tvalid_1's auc: 0.671412\nIteration: 6   roc_auc_score: 0.6714118125326674\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708783\tvalid_1's auc: 0.682336\n[2000]\ttraining's auc: 0.713006\tvalid_1's auc: 0.683053\n[3000]\ttraining's auc: 0.716087\tvalid_1's auc: 0.683028\n[4000]\ttraining's auc: 0.718866\tvalid_1's auc: 0.682481\nEarly stopping, best iteration is:\n[2226]\ttraining's auc: 0.713935\tvalid_1's auc: 0.683296\nIteration: 7   roc_auc_score: 0.6832928464957039\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708621\tvalid_1's auc: 0.677217\n[2000]\ttraining's auc: 0.713136\tvalid_1's auc: 0.678106\n[3000]\ttraining's auc: 0.716182\tvalid_1's auc: 0.677607\nEarly stopping, best iteration is:\n[1567]\ttraining's auc: 0.711619\tvalid_1's auc: 0.678434\nIteration: 8   roc_auc_score: 0.6784339835010607\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.708302\tvalid_1's auc: 0.681257\n[2000]\ttraining's auc: 0.712482\tvalid_1's auc: 0.68266\n[3000]\ttraining's auc: 0.715562\tvalid_1's auc: 0.683122\n[4000]\ttraining's auc: 0.718222\tvalid_1's auc: 0.68303\nEarly stopping, best iteration is:\n[2622]\ttraining's auc: 0.714454\tvalid_1's auc: 0.683838\nIteration: 9   roc_auc_score: 0.6838384579010903\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.707611\tvalid_1's auc: 0.68753\n[2000]\ttraining's auc: 0.71236\tvalid_1's auc: 0.688252\n[3000]\ttraining's auc: 0.715325\tvalid_1's auc: 0.688225\nEarly stopping, best iteration is:\n[1254]\ttraining's auc: 0.709408\tvalid_1's auc: 0.689063\nIteration: 10   roc_auc_score: 0.6890227716244106\n\n Best score: 0.6898807242276666  Avg Score: 0.6826052297884242\nStarting predicting cluster: 2\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.669463\tvalid_1's auc: 0.647509\n[2000]\ttraining's auc: 0.673597\tvalid_1's auc: 0.647644\n[3000]\ttraining's auc: 0.676731\tvalid_1's auc: 0.647139\nEarly stopping, best iteration is:\n[1555]\ttraining's auc: 0.672284\tvalid_1's auc: 0.64838\nIteration: 1   roc_auc_score: 0.6483795518544238\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.669826\tvalid_1's auc: 0.640662\n[2000]\ttraining's auc: 0.673963\tvalid_1's auc: 0.642357\n[3000]\ttraining's auc: 0.677079\tvalid_1's auc: 0.641097\nEarly stopping, best iteration is:\n[1982]\ttraining's auc: 0.673923\tvalid_1's auc: 0.642402\nIteration: 2   roc_auc_score: 0.6424023233286072\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.671265\tvalid_1's auc: 0.635299\n[2000]\ttraining's auc: 0.675232\tvalid_1's auc: 0.635616\nEarly stopping, best iteration is:\n[412]\ttraining's auc: 0.667174\tvalid_1's auc: 0.637749\nIteration: 3   roc_auc_score: 0.6377489705447194\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.670277\tvalid_1's auc: 0.641133\n[2000]\ttraining's auc: 0.674433\tvalid_1's auc: 0.642483\n[3000]\ttraining's auc: 0.677821\tvalid_1's auc: 0.641314\nEarly stopping, best iteration is:\n[1575]\ttraining's auc: 0.673216\tvalid_1's auc: 0.642558\nIteration: 4   roc_auc_score: 0.6425383643206979\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.670477\tvalid_1's auc: 0.632257\n[2000]\ttraining's auc: 0.67452\tvalid_1's auc: 0.635504\n[3000]\ttraining's auc: 0.677711\tvalid_1's auc: 0.634798\nEarly stopping, best iteration is:\n[1943]\ttraining's auc: 0.67436\tvalid_1's auc: 0.635608\nIteration: 5   roc_auc_score: 0.6356063208139403\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.671425\tvalid_1's auc: 0.629404\n[2000]\ttraining's auc: 0.675371\tvalid_1's auc: 0.629975\n[3000]\ttraining's auc: 0.678626\tvalid_1's auc: 0.628851\nEarly stopping, best iteration is:\n[1530]\ttraining's auc: 0.674109\tvalid_1's auc: 0.630475\nIteration: 6   roc_auc_score: 0.6304751672432721\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.669287\tvalid_1's auc: 0.648439\n[2000]\ttraining's auc: 0.673777\tvalid_1's auc: 0.649446\n[3000]\ttraining's auc: 0.676976\tvalid_1's auc: 0.649537\n[4000]\ttraining's auc: 0.679801\tvalid_1's auc: 0.647953\nEarly stopping, best iteration is:\n[2463]\ttraining's auc: 0.67528\tvalid_1's auc: 0.649964\nIteration: 7   roc_auc_score: 0.6499639379533682\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.66962\tvalid_1's auc: 0.646858\n[2000]\ttraining's auc: 0.674007\tvalid_1's auc: 0.647439\n[3000]\ttraining's auc: 0.677278\tvalid_1's auc: 0.645988\nEarly stopping, best iteration is:\n[1681]\ttraining's auc: 0.673057\tvalid_1's auc: 0.647951\nIteration: 8   roc_auc_score: 0.6479513494229796\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.670021\tvalid_1's auc: 0.645028\n[2000]\ttraining's auc: 0.674016\tvalid_1's auc: 0.647071\nEarly stopping, best iteration is:\n[411]\ttraining's auc: 0.666917\tvalid_1's auc: 0.648006\nIteration: 9   roc_auc_score: 0.6480063726571175\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.670451\tvalid_1's auc: 0.638009\n[2000]\ttraining's auc: 0.674721\tvalid_1's auc: 0.637698\nEarly stopping, best iteration is:\n[305]\ttraining's auc: 0.665247\tvalid_1's auc: 0.639279\nIteration: 10   roc_auc_score: 0.6392791083813778\n\n Best score: 0.6499639379533682  Avg Score: 0.6422351466520504\nStarting predicting cluster: 3\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.696476\tvalid_1's auc: 0.67916\n[2000]\ttraining's auc: 0.700634\tvalid_1's auc: 0.678921\n[3000]\ttraining's auc: 0.703334\tvalid_1's auc: 0.67923\nEarly stopping, best iteration is:\n[1027]\ttraining's auc: 0.696638\tvalid_1's auc: 0.679552\nIteration: 1   roc_auc_score: 0.6795520479974648\n","name":"stdout"},{"output_type":"stream","text":"Training until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.698519\tvalid_1's auc: 0.66201\n[2000]\ttraining's auc: 0.702505\tvalid_1's auc: 0.661894\nEarly stopping, best iteration is:\n[776]\ttraining's auc: 0.697394\tvalid_1's auc: 0.663165\nIteration: 2   roc_auc_score: 0.6631653305923276\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.696844\tvalid_1's auc: 0.675256\n[2000]\ttraining's auc: 0.700773\tvalid_1's auc: 0.675325\n[3000]\ttraining's auc: 0.703702\tvalid_1's auc: 0.674554\nEarly stopping, best iteration is:\n[1312]\ttraining's auc: 0.69865\tvalid_1's auc: 0.675694\nIteration: 3   roc_auc_score: 0.6756835887267387\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.696984\tvalid_1's auc: 0.677501\n[2000]\ttraining's auc: 0.700548\tvalid_1's auc: 0.677249\nEarly stopping, best iteration is:\n[632]\ttraining's auc: 0.694953\tvalid_1's auc: 0.678479\nIteration: 4   roc_auc_score: 0.6783718981523732\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.697141\tvalid_1's auc: 0.67414\n[2000]\ttraining's auc: 0.701209\tvalid_1's auc: 0.675043\n[3000]\ttraining's auc: 0.70402\tvalid_1's auc: 0.674257\nEarly stopping, best iteration is:\n[1265]\ttraining's auc: 0.698487\tvalid_1's auc: 0.675494\nIteration: 5   roc_auc_score: 0.6753955348327844\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.696491\tvalid_1's auc: 0.676061\n[2000]\ttraining's auc: 0.700306\tvalid_1's auc: 0.678042\n[3000]\ttraining's auc: 0.703148\tvalid_1's auc: 0.67793\n[4000]\ttraining's auc: 0.706051\tvalid_1's auc: 0.6768\nEarly stopping, best iteration is:\n[2236]\ttraining's auc: 0.700893\tvalid_1's auc: 0.678391\nIteration: 6   roc_auc_score: 0.6783905652393951\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.698043\tvalid_1's auc: 0.664664\n[2000]\ttraining's auc: 0.701979\tvalid_1's auc: 0.66396\nEarly stopping, best iteration is:\n[974]\ttraining's auc: 0.697927\tvalid_1's auc: 0.664984\nIteration: 7   roc_auc_score: 0.6649409428676518\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.697941\tvalid_1's auc: 0.662589\n[2000]\ttraining's auc: 0.701718\tvalid_1's auc: 0.663814\n[3000]\ttraining's auc: 0.704453\tvalid_1's auc: 0.663465\n[4000]\ttraining's auc: 0.707297\tvalid_1's auc: 0.663044\nEarly stopping, best iteration is:\n[2031]\ttraining's auc: 0.701831\tvalid_1's auc: 0.663886\nIteration: 8   roc_auc_score: 0.6638500383020971\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.697966\tvalid_1's auc: 0.668854\n[2000]\ttraining's auc: 0.701554\tvalid_1's auc: 0.669047\n[3000]\ttraining's auc: 0.704193\tvalid_1's auc: 0.669095\n[4000]\ttraining's auc: 0.706875\tvalid_1's auc: 0.668138\nEarly stopping, best iteration is:\n[2197]\ttraining's auc: 0.701956\tvalid_1's auc: 0.669529\nIteration: 9   roc_auc_score: 0.6695293635560489\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.697048\tvalid_1's auc: 0.669143\n[2000]\ttraining's auc: 0.701224\tvalid_1's auc: 0.669722\n[3000]\ttraining's auc: 0.703885\tvalid_1's auc: 0.668685\nEarly stopping, best iteration is:\n[1566]\ttraining's auc: 0.699804\tvalid_1's auc: 0.669997\nIteration: 10   roc_auc_score: 0.6699370619870394\n\n Best score: 0.6795520479974648  Avg Score: 0.6718816372253922\nStarting predicting cluster: 4\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.602332\tvalid_1's auc: 0.551663\n[2000]\ttraining's auc: 0.608564\tvalid_1's auc: 0.55037\nEarly stopping, best iteration is:\n[547]\ttraining's auc: 0.598581\tvalid_1's auc: 0.552899\nIteration: 1   roc_auc_score: 0.5528987268648144\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.601357\tvalid_1's auc: 0.561413\n[2000]\ttraining's auc: 0.607763\tvalid_1's auc: 0.560028\nEarly stopping, best iteration is:\n[231]\ttraining's auc: 0.593922\tvalid_1's auc: 0.564102\nIteration: 2   roc_auc_score: 0.5639605042985838\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.601715\tvalid_1's auc: 0.553077\n[2000]\ttraining's auc: 0.608455\tvalid_1's auc: 0.553573\nEarly stopping, best iteration is:\n[561]\ttraining's auc: 0.597809\tvalid_1's auc: 0.55512\nIteration: 3   roc_auc_score: 0.555106761910293\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.600471\tvalid_1's auc: 0.570067\n[2000]\ttraining's auc: 0.606894\tvalid_1's auc: 0.569741\nEarly stopping, best iteration is:\n[382]\ttraining's auc: 0.594191\tvalid_1's auc: 0.572028\nIteration: 4   roc_auc_score: 0.5718187550297429\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.60306\tvalid_1's auc: 0.546031\n[2000]\ttraining's auc: 0.609045\tvalid_1's auc: 0.54478\nEarly stopping, best iteration is:\n[34]\ttraining's auc: 0.570552\tvalid_1's auc: 0.549484\nIteration: 5   roc_auc_score: 0.5494836822004485\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.601486\tvalid_1's auc: 0.560059\n[2000]\ttraining's auc: 0.608134\tvalid_1's auc: 0.55842\nEarly stopping, best iteration is:\n[828]\ttraining's auc: 0.599838\tvalid_1's auc: 0.561138\nIteration: 6   roc_auc_score: 0.5611378350050747\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.600679\tvalid_1's auc: 0.568017\n[2000]\ttraining's auc: 0.607144\tvalid_1's auc: 0.566238\nEarly stopping, best iteration is:\n[552]\ttraining's auc: 0.597565\tvalid_1's auc: 0.568701\nIteration: 7   roc_auc_score: 0.5686115835497333\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.601766\tvalid_1's auc: 0.555382\n[2000]\ttraining's auc: 0.607588\tvalid_1's auc: 0.554236\nEarly stopping, best iteration is:\n[328]\ttraining's auc: 0.594843\tvalid_1's auc: 0.558194\nIteration: 8   roc_auc_score: 0.5581944916883067\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.601523\tvalid_1's auc: 0.570032\n[2000]\ttraining's auc: 0.607452\tvalid_1's auc: 0.568242\nEarly stopping, best iteration is:\n[509]\ttraining's auc: 0.597592\tvalid_1's auc: 0.57048\nIteration: 9   roc_auc_score: 0.5702915534901172\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.602166\tvalid_1's auc: 0.555828\n[2000]\ttraining's auc: 0.608482\tvalid_1's auc: 0.554505\nEarly stopping, best iteration is:\n[536]\ttraining's auc: 0.597983\tvalid_1's auc: 0.558185\nIteration: 10   roc_auc_score: 0.5581850820833764\n\n Best score: 0.5718187550297429  Avg Score: 0.560968897612049\nStarting predicting cluster: 5\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.711515\tvalid_1's auc: 0.689107\n[2000]\ttraining's auc: 0.714967\tvalid_1's auc: 0.688952\nEarly stopping, best iteration is:\n[914]\ttraining's auc: 0.711056\tvalid_1's auc: 0.689651\nIteration: 1   roc_auc_score: 0.6896513486151588\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.713959\tvalid_1's auc: 0.671374\n[2000]\ttraining's auc: 0.717248\tvalid_1's auc: 0.672939\nEarly stopping, best iteration is:\n[297]\ttraining's auc: 0.704879\tvalid_1's auc: 0.67389\nIteration: 2   roc_auc_score: 0.6738899300396468\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.712874\tvalid_1's auc: 0.676201\n[2000]\ttraining's auc: 0.716283\tvalid_1's auc: 0.677296\n[3000]\ttraining's auc: 0.719282\tvalid_1's auc: 0.677109\n[4000]\ttraining's auc: 0.722052\tvalid_1's auc: 0.675588\nEarly stopping, best iteration is:\n[2611]\ttraining's auc: 0.718154\tvalid_1's auc: 0.677544\nIteration: 3   roc_auc_score: 0.6775254079795574\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.711532\tvalid_1's auc: 0.685046\n[2000]\ttraining's auc: 0.71506\tvalid_1's auc: 0.686501\n[3000]\ttraining's auc: 0.718118\tvalid_1's auc: 0.684424\nEarly stopping, best iteration is:\n[1679]\ttraining's auc: 0.713949\tvalid_1's auc: 0.686943\nIteration: 4   roc_auc_score: 0.6869195434721889\nTraining until validation scores don't improve for 2000 rounds.\n","name":"stdout"},{"output_type":"stream","text":"[1000]\ttraining's auc: 0.712167\tvalid_1's auc: 0.685952\n[2000]\ttraining's auc: 0.715364\tvalid_1's auc: 0.686688\n[3000]\ttraining's auc: 0.718548\tvalid_1's auc: 0.686753\nEarly stopping, best iteration is:\n[1764]\ttraining's auc: 0.714633\tvalid_1's auc: 0.687094\nIteration: 5   roc_auc_score: 0.6870937696177257\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.712717\tvalid_1's auc: 0.679866\n[2000]\ttraining's auc: 0.715844\tvalid_1's auc: 0.681873\n[3000]\ttraining's auc: 0.718872\tvalid_1's auc: 0.681405\n[4000]\ttraining's auc: 0.721701\tvalid_1's auc: 0.680462\nEarly stopping, best iteration is:\n[2022]\ttraining's auc: 0.715885\tvalid_1's auc: 0.681981\nIteration: 6   roc_auc_score: 0.6819812278241919\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.712051\tvalid_1's auc: 0.686789\n[2000]\ttraining's auc: 0.715223\tvalid_1's auc: 0.687415\n[3000]\ttraining's auc: 0.718318\tvalid_1's auc: 0.686294\nEarly stopping, best iteration is:\n[1474]\ttraining's auc: 0.713604\tvalid_1's auc: 0.6881\nIteration: 7   roc_auc_score: 0.6880995522664609\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.712103\tvalid_1's auc: 0.681753\n[2000]\ttraining's auc: 0.715685\tvalid_1's auc: 0.681945\n[3000]\ttraining's auc: 0.718849\tvalid_1's auc: 0.680325\nEarly stopping, best iteration is:\n[1382]\ttraining's auc: 0.713553\tvalid_1's auc: 0.682736\nIteration: 8   roc_auc_score: 0.6827254223601282\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.711237\tvalid_1's auc: 0.68851\n[2000]\ttraining's auc: 0.714798\tvalid_1's auc: 0.689705\n[3000]\ttraining's auc: 0.718078\tvalid_1's auc: 0.688653\nEarly stopping, best iteration is:\n[1960]\ttraining's auc: 0.714675\tvalid_1's auc: 0.689848\nIteration: 9   roc_auc_score: 0.6898476035162502\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.712262\tvalid_1's auc: 0.684844\n[2000]\ttraining's auc: 0.715649\tvalid_1's auc: 0.68607\n[3000]\ttraining's auc: 0.718737\tvalid_1's auc: 0.684609\nEarly stopping, best iteration is:\n[1983]\ttraining's auc: 0.715586\tvalid_1's auc: 0.686183\nIteration: 10   roc_auc_score: 0.6861563763508902\n\n Best score: 0.6898476035162502  Avg Score: 0.68438901820422\nStarting predicting cluster: 6\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.67685\tvalid_1's auc: 0.657522\n[2000]\ttraining's auc: 0.680694\tvalid_1's auc: 0.656625\nEarly stopping, best iteration is:\n[465]\ttraining's auc: 0.674132\tvalid_1's auc: 0.657999\nIteration: 1   roc_auc_score: 0.657998512799794\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.676807\tvalid_1's auc: 0.660594\n[2000]\ttraining's auc: 0.680938\tvalid_1's auc: 0.659851\nEarly stopping, best iteration is:\n[920]\ttraining's auc: 0.676472\tvalid_1's auc: 0.660814\nIteration: 2   roc_auc_score: 0.6608138231636548\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.677633\tvalid_1's auc: 0.65293\n[2000]\ttraining's auc: 0.681371\tvalid_1's auc: 0.65317\nEarly stopping, best iteration is:\n[226]\ttraining's auc: 0.672482\tvalid_1's auc: 0.654387\nIteration: 3   roc_auc_score: 0.6543865442105757\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.675971\tvalid_1's auc: 0.667001\n[2000]\ttraining's auc: 0.680011\tvalid_1's auc: 0.666005\nEarly stopping, best iteration is:\n[290]\ttraining's auc: 0.671748\tvalid_1's auc: 0.668522\nIteration: 4   roc_auc_score: 0.6685224516660722\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.678676\tvalid_1's auc: 0.641464\n[2000]\ttraining's auc: 0.682445\tvalid_1's auc: 0.641383\nEarly stopping, best iteration is:\n[738]\ttraining's auc: 0.677579\tvalid_1's auc: 0.642341\nIteration: 5   roc_auc_score: 0.6423408527125353\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.67654\tvalid_1's auc: 0.660925\n[2000]\ttraining's auc: 0.680235\tvalid_1's auc: 0.660247\nEarly stopping, best iteration is:\n[703]\ttraining's auc: 0.67521\tvalid_1's auc: 0.661443\nIteration: 6   roc_auc_score: 0.6614428137245956\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.678143\tvalid_1's auc: 0.651045\n[2000]\ttraining's auc: 0.681905\tvalid_1's auc: 0.650461\nEarly stopping, best iteration is:\n[633]\ttraining's auc: 0.676445\tvalid_1's auc: 0.652068\nIteration: 7   roc_auc_score: 0.6520684791716792\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.67695\tvalid_1's auc: 0.657374\n[2000]\ttraining's auc: 0.680735\tvalid_1's auc: 0.657423\nEarly stopping, best iteration is:\n[420]\ttraining's auc: 0.673979\tvalid_1's auc: 0.658181\nIteration: 8   roc_auc_score: 0.6581806642164386\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.678343\tvalid_1's auc: 0.648554\n[2000]\ttraining's auc: 0.682298\tvalid_1's auc: 0.647579\nEarly stopping, best iteration is:\n[435]\ttraining's auc: 0.675444\tvalid_1's auc: 0.650768\nIteration: 9   roc_auc_score: 0.6507681525409145\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.676871\tvalid_1's auc: 0.659592\n[2000]\ttraining's auc: 0.680564\tvalid_1's auc: 0.659226\nEarly stopping, best iteration is:\n[469]\ttraining's auc: 0.673751\tvalid_1's auc: 0.660804\nIteration: 10   roc_auc_score: 0.660803648728028\n\n Best score: 0.6685224516660722  Avg Score: 0.6567325942934288\nStarting predicting cluster: 7\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.702786\tvalid_1's auc: 0.669655\n[2000]\ttraining's auc: 0.706425\tvalid_1's auc: 0.669693\n[3000]\ttraining's auc: 0.709191\tvalid_1's auc: 0.668603\nEarly stopping, best iteration is:\n[1146]\ttraining's auc: 0.703715\tvalid_1's auc: 0.67019\nIteration: 1   roc_auc_score: 0.6701898765856118\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.701069\tvalid_1's auc: 0.680809\n[2000]\ttraining's auc: 0.704879\tvalid_1's auc: 0.680915\n[3000]\ttraining's auc: 0.707529\tvalid_1's auc: 0.680056\nEarly stopping, best iteration is:\n[1191]\ttraining's auc: 0.702254\tvalid_1's auc: 0.682254\nIteration: 2   roc_auc_score: 0.682254283581813\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.701209\tvalid_1's auc: 0.681864\n[2000]\ttraining's auc: 0.704645\tvalid_1's auc: 0.682503\n[3000]\ttraining's auc: 0.707254\tvalid_1's auc: 0.681387\nEarly stopping, best iteration is:\n[1625]\ttraining's auc: 0.703576\tvalid_1's auc: 0.68309\nIteration: 3   roc_auc_score: 0.6830902463778937\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.700773\tvalid_1's auc: 0.683332\n[2000]\ttraining's auc: 0.704678\tvalid_1's auc: 0.684766\n[3000]\ttraining's auc: 0.707449\tvalid_1's auc: 0.684391\n[4000]\ttraining's auc: 0.709908\tvalid_1's auc: 0.683232\nEarly stopping, best iteration is:\n[2050]\ttraining's auc: 0.704823\tvalid_1's auc: 0.684926\nIteration: 4   roc_auc_score: 0.6849262580925279\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.700627\tvalid_1's auc: 0.686761\n[2000]\ttraining's auc: 0.704375\tvalid_1's auc: 0.686147\nEarly stopping, best iteration is:\n[982]\ttraining's auc: 0.700651\tvalid_1's auc: 0.686849\nIteration: 5   roc_auc_score: 0.6868319602653767\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.70017\tvalid_1's auc: 0.692061\n[2000]\ttraining's auc: 0.704151\tvalid_1's auc: 0.691259\n[3000]\ttraining's auc: 0.706958\tvalid_1's auc: 0.690204\nEarly stopping, best iteration is:\n[1158]\ttraining's auc: 0.701223\tvalid_1's auc: 0.692642\nIteration: 6   roc_auc_score: 0.6926416831904956\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.701953\tvalid_1's auc: 0.676755\n[2000]\ttraining's auc: 0.705695\tvalid_1's auc: 0.67698\n[3000]\ttraining's auc: 0.708482\tvalid_1's auc: 0.675864\nEarly stopping, best iteration is:\n[1494]\ttraining's auc: 0.704134\tvalid_1's auc: 0.677733\nIteration: 7   roc_auc_score: 0.6777330412971274\n","name":"stdout"},{"output_type":"stream","text":"Training until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.699697\tvalid_1's auc: 0.693316\n[2000]\ttraining's auc: 0.703502\tvalid_1's auc: 0.693843\n[3000]\ttraining's auc: 0.706167\tvalid_1's auc: 0.693309\nEarly stopping, best iteration is:\n[1378]\ttraining's auc: 0.701594\tvalid_1's auc: 0.694223\nIteration: 8   roc_auc_score: 0.6942225227392775\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.701145\tvalid_1's auc: 0.68174\n[2000]\ttraining's auc: 0.704891\tvalid_1's auc: 0.681848\n[3000]\ttraining's auc: 0.707673\tvalid_1's auc: 0.681114\nEarly stopping, best iteration is:\n[1422]\ttraining's auc: 0.70315\tvalid_1's auc: 0.68287\nIteration: 9   roc_auc_score: 0.6828696933836645\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.700838\tvalid_1's auc: 0.681731\n[2000]\ttraining's auc: 0.704326\tvalid_1's auc: 0.682752\n[3000]\ttraining's auc: 0.707147\tvalid_1's auc: 0.682469\nEarly stopping, best iteration is:\n[1664]\ttraining's auc: 0.703369\tvalid_1's auc: 0.683185\nIteration: 10   roc_auc_score: 0.6831854210250647\n\n Best score: 0.6942225227392775  Avg Score: 0.6837944986538853\nStarting predicting cluster: 8\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.680107\tvalid_1's auc: 0.670135\n[2000]\ttraining's auc: 0.683648\tvalid_1's auc: 0.670321\nEarly stopping, best iteration is:\n[189]\ttraining's auc: 0.674902\tvalid_1's auc: 0.670913\nIteration: 1   roc_auc_score: 0.6707674456354766\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.681848\tvalid_1's auc: 0.654975\n[2000]\ttraining's auc: 0.685416\tvalid_1's auc: 0.654209\nEarly stopping, best iteration is:\n[518]\ttraining's auc: 0.679691\tvalid_1's auc: 0.655352\nIteration: 2   roc_auc_score: 0.6553515010683894\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.682501\tvalid_1's auc: 0.651553\n[2000]\ttraining's auc: 0.686133\tvalid_1's auc: 0.651109\nEarly stopping, best iteration is:\n[84]\ttraining's auc: 0.675237\tvalid_1's auc: 0.653913\nIteration: 3   roc_auc_score: 0.6539127320595466\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.681326\tvalid_1's auc: 0.662391\n[2000]\ttraining's auc: 0.684965\tvalid_1's auc: 0.661981\nEarly stopping, best iteration is:\n[509]\ttraining's auc: 0.678904\tvalid_1's auc: 0.663114\nIteration: 4   roc_auc_score: 0.6630587750519221\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.681798\tvalid_1's auc: 0.659926\n[2000]\ttraining's auc: 0.685245\tvalid_1's auc: 0.659832\n[3000]\ttraining's auc: 0.688338\tvalid_1's auc: 0.658964\nEarly stopping, best iteration is:\n[1177]\ttraining's auc: 0.682548\tvalid_1's auc: 0.660348\nIteration: 5   roc_auc_score: 0.660328430111809\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.679934\tvalid_1's auc: 0.675677\n[2000]\ttraining's auc: 0.683512\tvalid_1's auc: 0.674473\nEarly stopping, best iteration is:\n[295]\ttraining's auc: 0.675983\tvalid_1's auc: 0.676431\nIteration: 6   roc_auc_score: 0.6762907253615192\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.681066\tvalid_1's auc: 0.666866\n[2000]\ttraining's auc: 0.684584\tvalid_1's auc: 0.666816\nEarly stopping, best iteration is:\n[118]\ttraining's auc: 0.674476\tvalid_1's auc: 0.667246\nIteration: 7   roc_auc_score: 0.6672460377379362\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.682128\tvalid_1's auc: 0.658945\n[2000]\ttraining's auc: 0.685896\tvalid_1's auc: 0.657523\nEarly stopping, best iteration is:\n[626]\ttraining's auc: 0.680142\tvalid_1's auc: 0.659511\nIteration: 8   roc_auc_score: 0.6595109776299161\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.681955\tvalid_1's auc: 0.660324\n[2000]\ttraining's auc: 0.685437\tvalid_1's auc: 0.660126\nEarly stopping, best iteration is:\n[289]\ttraining's auc: 0.677801\tvalid_1's auc: 0.661707\nIteration: 9   roc_auc_score: 0.6614260286741902\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.681825\tvalid_1's auc: 0.657269\n[2000]\ttraining's auc: 0.685511\tvalid_1's auc: 0.656395\nEarly stopping, best iteration is:\n[287]\ttraining's auc: 0.678078\tvalid_1's auc: 0.658131\nIteration: 10   roc_auc_score: 0.6581311004316042\n\n Best score: 0.6762907253615192  Avg Score: 0.6626023753762309\nStarting predicting cluster: 9\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.653418\tvalid_1's auc: 0.628082\n[2000]\ttraining's auc: 0.659036\tvalid_1's auc: 0.627279\nEarly stopping, best iteration is:\n[806]\ttraining's auc: 0.652044\tvalid_1's auc: 0.629035\nIteration: 1   roc_auc_score: 0.6289394835615707\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.654235\tvalid_1's auc: 0.619054\n[2000]\ttraining's auc: 0.659364\tvalid_1's auc: 0.618068\nEarly stopping, best iteration is:\n[475]\ttraining's auc: 0.649797\tvalid_1's auc: 0.620612\nIteration: 2   roc_auc_score: 0.6204991108047114\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.654394\tvalid_1's auc: 0.613595\n[2000]\ttraining's auc: 0.65937\tvalid_1's auc: 0.612011\nEarly stopping, best iteration is:\n[276]\ttraining's auc: 0.646382\tvalid_1's auc: 0.615758\nIteration: 3   roc_auc_score: 0.6154822330813967\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.654283\tvalid_1's auc: 0.617423\n[2000]\ttraining's auc: 0.659022\tvalid_1's auc: 0.617215\n[3000]\ttraining's auc: 0.663185\tvalid_1's auc: 0.616484\nEarly stopping, best iteration is:\n[1156]\ttraining's auc: 0.654856\tvalid_1's auc: 0.618386\nIteration: 4   roc_auc_score: 0.6183419478483071\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.654215\tvalid_1's auc: 0.616372\n[2000]\ttraining's auc: 0.65931\tvalid_1's auc: 0.615849\nEarly stopping, best iteration is:\n[861]\ttraining's auc: 0.652972\tvalid_1's auc: 0.617328\nIteration: 5   roc_auc_score: 0.6171544169093388\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.6545\tvalid_1's auc: 0.616713\n[2000]\ttraining's auc: 0.659685\tvalid_1's auc: 0.614831\nEarly stopping, best iteration is:\n[896]\ttraining's auc: 0.653806\tvalid_1's auc: 0.617554\nIteration: 6   roc_auc_score: 0.617524523021358\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.65382\tvalid_1's auc: 0.617569\n[2000]\ttraining's auc: 0.658729\tvalid_1's auc: 0.616889\nEarly stopping, best iteration is:\n[511]\ttraining's auc: 0.649569\tvalid_1's auc: 0.619471\nIteration: 7   roc_auc_score: 0.6194711821658798\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.653892\tvalid_1's auc: 0.623224\n[2000]\ttraining's auc: 0.659125\tvalid_1's auc: 0.622356\n[3000]\ttraining's auc: 0.663054\tvalid_1's auc: 0.620561\nEarly stopping, best iteration is:\n[1274]\ttraining's auc: 0.655146\tvalid_1's auc: 0.623874\nIteration: 8   roc_auc_score: 0.6237987936913543\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.653676\tvalid_1's auc: 0.618094\n[2000]\ttraining's auc: 0.658833\tvalid_1's auc: 0.618053\nEarly stopping, best iteration is:\n[275]\ttraining's auc: 0.645827\tvalid_1's auc: 0.620755\nIteration: 9   roc_auc_score: 0.6205273323961019\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.653235\tvalid_1's auc: 0.621121\n[2000]\ttraining's auc: 0.658429\tvalid_1's auc: 0.62123\nEarly stopping, best iteration is:\n[804]\ttraining's auc: 0.652119\tvalid_1's auc: 0.622215\nIteration: 10   roc_auc_score: 0.6222140445814844\n\n Best score: 0.6289394835615707  Avg Score: 0.6203953068061503\nStarting predicting cluster: 10\n\nStarting KFold iterations...\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.638548\tvalid_1's auc: 0.603724\n[2000]\ttraining's auc: 0.643089\tvalid_1's auc: 0.603119\nEarly stopping, best iteration is:\n[202]\ttraining's auc: 0.630591\tvalid_1's auc: 0.604611\n","name":"stdout"},{"output_type":"stream","text":"Iteration: 1   roc_auc_score: 0.604610846053209\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.639263\tvalid_1's auc: 0.599264\n[2000]\ttraining's auc: 0.643659\tvalid_1's auc: 0.599246\nEarly stopping, best iteration is:\n[192]\ttraining's auc: 0.631468\tvalid_1's auc: 0.600107\nIteration: 2   roc_auc_score: 0.6001071846039105\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.638162\tvalid_1's auc: 0.607565\n[2000]\ttraining's auc: 0.642462\tvalid_1's auc: 0.606644\nEarly stopping, best iteration is:\n[298]\ttraining's auc: 0.633224\tvalid_1's auc: 0.609157\nIteration: 3   roc_auc_score: 0.6091570220050387\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.637169\tvalid_1's auc: 0.619057\n[2000]\ttraining's auc: 0.641442\tvalid_1's auc: 0.619629\nEarly stopping, best iteration is:\n[873]\ttraining's auc: 0.63643\tvalid_1's auc: 0.619704\nIteration: 4   roc_auc_score: 0.6197037049328123\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.638248\tvalid_1's auc: 0.612949\n[2000]\ttraining's auc: 0.642796\tvalid_1's auc: 0.612391\nEarly stopping, best iteration is:\n[183]\ttraining's auc: 0.629817\tvalid_1's auc: 0.615889\nIteration: 5   roc_auc_score: 0.6156952591129953\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.639062\tvalid_1's auc: 0.601059\n[2000]\ttraining's auc: 0.643328\tvalid_1's auc: 0.601218\nEarly stopping, best iteration is:\n[263]\ttraining's auc: 0.632762\tvalid_1's auc: 0.605172\nIteration: 6   roc_auc_score: 0.6051723870917785\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.637851\tvalid_1's auc: 0.60638\n[2000]\ttraining's auc: 0.642253\tvalid_1's auc: 0.60573\nEarly stopping, best iteration is:\n[955]\ttraining's auc: 0.637532\tvalid_1's auc: 0.606942\nIteration: 7   roc_auc_score: 0.6068689072702081\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.638328\tvalid_1's auc: 0.60625\n[2000]\ttraining's auc: 0.642874\tvalid_1's auc: 0.604753\nEarly stopping, best iteration is:\n[272]\ttraining's auc: 0.631736\tvalid_1's auc: 0.607588\nIteration: 8   roc_auc_score: 0.6075877975326258\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.637673\tvalid_1's auc: 0.613941\n[2000]\ttraining's auc: 0.642056\tvalid_1's auc: 0.611691\nEarly stopping, best iteration is:\n[675]\ttraining's auc: 0.635821\tvalid_1's auc: 0.615472\nIteration: 9   roc_auc_score: 0.6154723975572957\nTraining until validation scores don't improve for 2000 rounds.\n[1000]\ttraining's auc: 0.637445\tvalid_1's auc: 0.61227\n[2000]\ttraining's auc: 0.642022\tvalid_1's auc: 0.609169\nEarly stopping, best iteration is:\n[738]\ttraining's auc: 0.635848\tvalid_1's auc: 0.612536\nIteration: 10   roc_auc_score: 0.6125364984861066\n\n Best score: 0.6197037049328123  Avg Score: 0.6096912004645981\nCPU times: user 6h 53min 19s, sys: 23min 1s, total: 7h 16min 21s\nWall time: 2h 37min 53s\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"fba8202fda9c0ccec95164f836345a402b4ab36c"},"cell_type":"code","source":"%%time\n#CREATING SUMBISSION FILE\ndf_preds_x.to_csv('X_features.csv',index=False)\ndf_preds.to_csv('test_features.csv',index=False)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0bd9b65d473f5b2009a4cf8d4f6477e6d227552"},"cell_type":"code","source":"# %%time\n\n# X=df_preds_x\n# test=df_preds\n\n# model=LogisticRegression()\n# k=1\n# splits=15\n# avg_score=0\n\n# #CREATING STRATIFIED FOLDS\n# skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\n# print('\\nStarting KFold iterations...')\n# for train_index,test_index in skf.split(X,y):\n#     df_X=X.iloc[train_index,:]\n#     df_y=y.iloc[train_index]\n#     val_X=X.iloc[test_index,:]\n#     val_y=y.iloc[test_index]\n\n# #FITTING MODEL\n    \n#     model.fit(df_X,df_y)\n    \n    \n# #PREDICTING ON VALIDATION DATA\n    \n#     preds_x=pd.Series(model.predict_proba(val_X)[:,1])\n# #CALCULATING ACCURACY\n#     acc=roc_auc_score(val_y,preds_x)\n#     print('Iteration:',k,'  roc_auc_score:',acc)\n#     if k==1:\n#         score=acc\n#         preds=pd.Series(model.predict_proba(test)[:,1])\n        \n#     else:\n#         preds1=pd.Series(model.predict_proba(test)[:,1])\n#         preds=preds+preds1\n        \n#         if score<acc:\n#             score=acc\n            \n#     avg_score=avg_score+acc        \n#     k=k+1\n# print('\\n Best score:',score,' Avg Score:',avg_score/splits)\n# #TAKING AVERAGE OF PREDICTIONS\n# preds=preds/splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preds.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"      X_1_1     X_1_2     X_1_3    ...       X_10_8    X_10_9   X_10_10\n0  0.070566  0.064870  0.068104    ...     0.142279  0.112210  0.113277\n1  0.098904  0.093015  0.089776    ...     0.139663  0.100514  0.094433\n2  0.120730  0.123034  0.121144    ...     0.135746  0.094226  0.091033\n3  0.138212  0.138517  0.140876    ...     0.147566  0.115629  0.123277\n4  0.130977  0.131687  0.136001    ...     0.140927  0.107447  0.104352\n\n[5 rows x 100 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_1_1</th>\n      <th>X_1_2</th>\n      <th>X_1_3</th>\n      <th>X_1_4</th>\n      <th>X_1_5</th>\n      <th>X_1_6</th>\n      <th>X_1_7</th>\n      <th>X_1_8</th>\n      <th>X_1_9</th>\n      <th>X_1_10</th>\n      <th>X_2_1</th>\n      <th>X_2_2</th>\n      <th>X_2_3</th>\n      <th>X_2_4</th>\n      <th>X_2_5</th>\n      <th>X_2_6</th>\n      <th>X_2_7</th>\n      <th>X_2_8</th>\n      <th>X_2_9</th>\n      <th>X_2_10</th>\n      <th>X_3_1</th>\n      <th>X_3_2</th>\n      <th>X_3_3</th>\n      <th>X_3_4</th>\n      <th>X_3_5</th>\n      <th>X_3_6</th>\n      <th>X_3_7</th>\n      <th>X_3_8</th>\n      <th>X_3_9</th>\n      <th>X_3_10</th>\n      <th>X_4_1</th>\n      <th>X_4_2</th>\n      <th>X_4_3</th>\n      <th>X_4_4</th>\n      <th>X_4_5</th>\n      <th>X_4_6</th>\n      <th>X_4_7</th>\n      <th>X_4_8</th>\n      <th>X_4_9</th>\n      <th>X_4_10</th>\n      <th>...</th>\n      <th>X_7_1</th>\n      <th>X_7_2</th>\n      <th>X_7_3</th>\n      <th>X_7_4</th>\n      <th>X_7_5</th>\n      <th>X_7_6</th>\n      <th>X_7_7</th>\n      <th>X_7_8</th>\n      <th>X_7_9</th>\n      <th>X_7_10</th>\n      <th>X_8_1</th>\n      <th>X_8_2</th>\n      <th>X_8_3</th>\n      <th>X_8_4</th>\n      <th>X_8_5</th>\n      <th>X_8_6</th>\n      <th>X_8_7</th>\n      <th>X_8_8</th>\n      <th>X_8_9</th>\n      <th>X_8_10</th>\n      <th>X_9_1</th>\n      <th>X_9_2</th>\n      <th>X_9_3</th>\n      <th>X_9_4</th>\n      <th>X_9_5</th>\n      <th>X_9_6</th>\n      <th>X_9_7</th>\n      <th>X_9_8</th>\n      <th>X_9_9</th>\n      <th>X_9_10</th>\n      <th>X_10_1</th>\n      <th>X_10_2</th>\n      <th>X_10_3</th>\n      <th>X_10_4</th>\n      <th>X_10_5</th>\n      <th>X_10_6</th>\n      <th>X_10_7</th>\n      <th>X_10_8</th>\n      <th>X_10_9</th>\n      <th>X_10_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.070566</td>\n      <td>0.064870</td>\n      <td>0.068104</td>\n      <td>0.067225</td>\n      <td>0.081491</td>\n      <td>0.067331</td>\n      <td>0.059878</td>\n      <td>0.071672</td>\n      <td>0.054394</td>\n      <td>0.079120</td>\n      <td>0.124517</td>\n      <td>0.128814</td>\n      <td>0.115187</td>\n      <td>0.129152</td>\n      <td>0.128814</td>\n      <td>0.130017</td>\n      <td>0.132282</td>\n      <td>0.131762</td>\n      <td>0.116402</td>\n      <td>0.134512</td>\n      <td>0.084227</td>\n      <td>0.090862</td>\n      <td>0.082301</td>\n      <td>0.093486</td>\n      <td>0.082602</td>\n      <td>0.070275</td>\n      <td>0.085812</td>\n      <td>0.077310</td>\n      <td>0.074173</td>\n      <td>0.077920</td>\n      <td>0.109935</td>\n      <td>0.157218</td>\n      <td>0.107412</td>\n      <td>0.119623</td>\n      <td>0.399889</td>\n      <td>0.106892</td>\n      <td>0.107007</td>\n      <td>0.128543</td>\n      <td>0.111742</td>\n      <td>0.109739</td>\n      <td>...</td>\n      <td>0.087021</td>\n      <td>0.086582</td>\n      <td>0.083058</td>\n      <td>0.077776</td>\n      <td>0.092997</td>\n      <td>0.085629</td>\n      <td>0.088854</td>\n      <td>0.087607</td>\n      <td>0.082498</td>\n      <td>0.078980</td>\n      <td>0.182424</td>\n      <td>0.115071</td>\n      <td>0.298014</td>\n      <td>0.111361</td>\n      <td>0.124466</td>\n      <td>0.138342</td>\n      <td>0.249687</td>\n      <td>0.114829</td>\n      <td>0.141227</td>\n      <td>0.140216</td>\n      <td>0.123763</td>\n      <td>0.114497</td>\n      <td>0.142660</td>\n      <td>0.127198</td>\n      <td>0.123673</td>\n      <td>0.119868</td>\n      <td>0.116530</td>\n      <td>0.130626</td>\n      <td>0.144473</td>\n      <td>0.114946</td>\n      <td>0.175798</td>\n      <td>0.182056</td>\n      <td>0.136277</td>\n      <td>0.107782</td>\n      <td>0.187740</td>\n      <td>0.147520</td>\n      <td>0.115161</td>\n      <td>0.142279</td>\n      <td>0.112210</td>\n      <td>0.113277</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.098904</td>\n      <td>0.093015</td>\n      <td>0.089776</td>\n      <td>0.097998</td>\n      <td>0.097381</td>\n      <td>0.092715</td>\n      <td>0.090661</td>\n      <td>0.097050</td>\n      <td>0.087037</td>\n      <td>0.103094</td>\n      <td>0.092518</td>\n      <td>0.087070</td>\n      <td>0.110452</td>\n      <td>0.094117</td>\n      <td>0.089219</td>\n      <td>0.093135</td>\n      <td>0.085449</td>\n      <td>0.087852</td>\n      <td>0.109096</td>\n      <td>0.128893</td>\n      <td>0.104790</td>\n      <td>0.104934</td>\n      <td>0.108734</td>\n      <td>0.106469</td>\n      <td>0.101862</td>\n      <td>0.106142</td>\n      <td>0.106430</td>\n      <td>0.101421</td>\n      <td>0.106686</td>\n      <td>0.100962</td>\n      <td>0.097470</td>\n      <td>0.153972</td>\n      <td>0.098066</td>\n      <td>0.110915</td>\n      <td>0.399360</td>\n      <td>0.092302</td>\n      <td>0.097216</td>\n      <td>0.119957</td>\n      <td>0.098238</td>\n      <td>0.097143</td>\n      <td>...</td>\n      <td>0.181912</td>\n      <td>0.185036</td>\n      <td>0.195963</td>\n      <td>0.213871</td>\n      <td>0.161845</td>\n      <td>0.175280</td>\n      <td>0.194353</td>\n      <td>0.187978</td>\n      <td>0.188687</td>\n      <td>0.183800</td>\n      <td>0.185187</td>\n      <td>0.115042</td>\n      <td>0.298191</td>\n      <td>0.113669</td>\n      <td>0.115583</td>\n      <td>0.140080</td>\n      <td>0.249566</td>\n      <td>0.114307</td>\n      <td>0.140729</td>\n      <td>0.140207</td>\n      <td>0.126341</td>\n      <td>0.123732</td>\n      <td>0.146925</td>\n      <td>0.138644</td>\n      <td>0.134717</td>\n      <td>0.133785</td>\n      <td>0.123935</td>\n      <td>0.147015</td>\n      <td>0.149295</td>\n      <td>0.125096</td>\n      <td>0.172323</td>\n      <td>0.176885</td>\n      <td>0.130348</td>\n      <td>0.095007</td>\n      <td>0.182618</td>\n      <td>0.142013</td>\n      <td>0.091884</td>\n      <td>0.139663</td>\n      <td>0.100514</td>\n      <td>0.094433</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.120730</td>\n      <td>0.123034</td>\n      <td>0.121144</td>\n      <td>0.113547</td>\n      <td>0.113859</td>\n      <td>0.121755</td>\n      <td>0.129983</td>\n      <td>0.117492</td>\n      <td>0.122565</td>\n      <td>0.113182</td>\n      <td>0.133972</td>\n      <td>0.139413</td>\n      <td>0.121862</td>\n      <td>0.135802</td>\n      <td>0.140350</td>\n      <td>0.138283</td>\n      <td>0.147307</td>\n      <td>0.146542</td>\n      <td>0.123443</td>\n      <td>0.138297</td>\n      <td>0.094341</td>\n      <td>0.094791</td>\n      <td>0.099364</td>\n      <td>0.098091</td>\n      <td>0.095903</td>\n      <td>0.089977</td>\n      <td>0.093510</td>\n      <td>0.087683</td>\n      <td>0.089202</td>\n      <td>0.093072</td>\n      <td>0.094114</td>\n      <td>0.152333</td>\n      <td>0.093236</td>\n      <td>0.109392</td>\n      <td>0.398630</td>\n      <td>0.085554</td>\n      <td>0.094567</td>\n      <td>0.119126</td>\n      <td>0.096976</td>\n      <td>0.095796</td>\n      <td>...</td>\n      <td>0.218416</td>\n      <td>0.225553</td>\n      <td>0.272791</td>\n      <td>0.318352</td>\n      <td>0.225003</td>\n      <td>0.244469</td>\n      <td>0.259474</td>\n      <td>0.263360</td>\n      <td>0.258268</td>\n      <td>0.283482</td>\n      <td>0.180508</td>\n      <td>0.107258</td>\n      <td>0.295179</td>\n      <td>0.107132</td>\n      <td>0.098530</td>\n      <td>0.132627</td>\n      <td>0.246600</td>\n      <td>0.102513</td>\n      <td>0.135015</td>\n      <td>0.135946</td>\n      <td>0.088385</td>\n      <td>0.097736</td>\n      <td>0.134336</td>\n      <td>0.080379</td>\n      <td>0.085739</td>\n      <td>0.087348</td>\n      <td>0.096579</td>\n      <td>0.078672</td>\n      <td>0.134711</td>\n      <td>0.089597</td>\n      <td>0.169354</td>\n      <td>0.174280</td>\n      <td>0.128304</td>\n      <td>0.091046</td>\n      <td>0.180708</td>\n      <td>0.138937</td>\n      <td>0.088432</td>\n      <td>0.135746</td>\n      <td>0.094226</td>\n      <td>0.091033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.138212</td>\n      <td>0.138517</td>\n      <td>0.140876</td>\n      <td>0.146041</td>\n      <td>0.132746</td>\n      <td>0.139809</td>\n      <td>0.144608</td>\n      <td>0.141547</td>\n      <td>0.146545</td>\n      <td>0.130408</td>\n      <td>0.086905</td>\n      <td>0.079167</td>\n      <td>0.105468</td>\n      <td>0.084721</td>\n      <td>0.082633</td>\n      <td>0.080779</td>\n      <td>0.085321</td>\n      <td>0.084737</td>\n      <td>0.109831</td>\n      <td>0.128016</td>\n      <td>0.091587</td>\n      <td>0.095960</td>\n      <td>0.090021</td>\n      <td>0.099807</td>\n      <td>0.088319</td>\n      <td>0.089318</td>\n      <td>0.094374</td>\n      <td>0.088331</td>\n      <td>0.083061</td>\n      <td>0.089747</td>\n      <td>0.108390</td>\n      <td>0.157710</td>\n      <td>0.110091</td>\n      <td>0.118120</td>\n      <td>0.399793</td>\n      <td>0.116357</td>\n      <td>0.110462</td>\n      <td>0.131063</td>\n      <td>0.109789</td>\n      <td>0.108224</td>\n      <td>...</td>\n      <td>0.072277</td>\n      <td>0.070723</td>\n      <td>0.065130</td>\n      <td>0.060738</td>\n      <td>0.076285</td>\n      <td>0.070264</td>\n      <td>0.069011</td>\n      <td>0.068268</td>\n      <td>0.067713</td>\n      <td>0.064054</td>\n      <td>0.183905</td>\n      <td>0.108440</td>\n      <td>0.296622</td>\n      <td>0.114589</td>\n      <td>0.111310</td>\n      <td>0.137201</td>\n      <td>0.247884</td>\n      <td>0.107719</td>\n      <td>0.139012</td>\n      <td>0.139318</td>\n      <td>0.117851</td>\n      <td>0.124905</td>\n      <td>0.148774</td>\n      <td>0.127300</td>\n      <td>0.130172</td>\n      <td>0.131023</td>\n      <td>0.120191</td>\n      <td>0.125785</td>\n      <td>0.150427</td>\n      <td>0.125494</td>\n      <td>0.180796</td>\n      <td>0.185964</td>\n      <td>0.140205</td>\n      <td>0.131235</td>\n      <td>0.193046</td>\n      <td>0.150921</td>\n      <td>0.130904</td>\n      <td>0.147566</td>\n      <td>0.115629</td>\n      <td>0.123277</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.130977</td>\n      <td>0.131687</td>\n      <td>0.136001</td>\n      <td>0.137065</td>\n      <td>0.119341</td>\n      <td>0.144837</td>\n      <td>0.153203</td>\n      <td>0.139273</td>\n      <td>0.152464</td>\n      <td>0.122179</td>\n      <td>0.107935</td>\n      <td>0.109445</td>\n      <td>0.118477</td>\n      <td>0.106610</td>\n      <td>0.111446</td>\n      <td>0.109770</td>\n      <td>0.111133</td>\n      <td>0.120148</td>\n      <td>0.114903</td>\n      <td>0.132790</td>\n      <td>0.099885</td>\n      <td>0.097258</td>\n      <td>0.097308</td>\n      <td>0.104050</td>\n      <td>0.097512</td>\n      <td>0.103051</td>\n      <td>0.101691</td>\n      <td>0.101901</td>\n      <td>0.099453</td>\n      <td>0.097682</td>\n      <td>0.121916</td>\n      <td>0.161172</td>\n      <td>0.121506</td>\n      <td>0.126726</td>\n      <td>0.400470</td>\n      <td>0.119174</td>\n      <td>0.118926</td>\n      <td>0.134179</td>\n      <td>0.119572</td>\n      <td>0.117538</td>\n      <td>...</td>\n      <td>0.079893</td>\n      <td>0.079187</td>\n      <td>0.073687</td>\n      <td>0.071661</td>\n      <td>0.082282</td>\n      <td>0.079263</td>\n      <td>0.076306</td>\n      <td>0.077041</td>\n      <td>0.076805</td>\n      <td>0.073102</td>\n      <td>0.176193</td>\n      <td>0.095478</td>\n      <td>0.293634</td>\n      <td>0.095473</td>\n      <td>0.078146</td>\n      <td>0.127847</td>\n      <td>0.243699</td>\n      <td>0.091074</td>\n      <td>0.129417</td>\n      <td>0.128677</td>\n      <td>0.086337</td>\n      <td>0.098277</td>\n      <td>0.133243</td>\n      <td>0.082856</td>\n      <td>0.085767</td>\n      <td>0.084685</td>\n      <td>0.097609</td>\n      <td>0.080260</td>\n      <td>0.133633</td>\n      <td>0.091046</td>\n      <td>0.172437</td>\n      <td>0.179817</td>\n      <td>0.134714</td>\n      <td>0.104779</td>\n      <td>0.185455</td>\n      <td>0.145262</td>\n      <td>0.102388</td>\n      <td>0.140927</td>\n      <td>0.107447</td>\n      <td>0.104352</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"a278f9fcb35f6bef5ba5682a0058c273e74865c7","scrolled":true},"cell_type":"code","source":"%%time\n#PREPARING SUBMISSION\ndf_submission['target']=df_preds.mean(axis=1)\ndf_submission","execution_count":29,"outputs":[{"output_type":"stream","text":"CPU times: user 80 ms, sys: 0 ns, total: 80 ms\nWall time: 81.6 ms\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"5ab297e9650c467cbc56ce1c0b6e6dae2b8efdde"},"cell_type":"code","source":"#CREATING SUMBISSION FILE\ndf_submission.to_csv('submission.csv',index=False)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"            ID_code    target\n0            test_0  0.117467\n1            test_1  0.124543\n2            test_2  0.133745\n3            test_3  0.120209\n4            test_4  0.117072\n5            test_5  0.107997\n6            test_6  0.108284\n7            test_7  0.125165\n8            test_8  0.105301\n9            test_9  0.108563\n10          test_10  0.123171\n11          test_11  0.114445\n12          test_12  0.118620\n13          test_13  0.114974\n14          test_14  0.107132\n15          test_15  0.119293\n16          test_16  0.121770\n17          test_17  0.115963\n18          test_18  0.123365\n19          test_19  0.112272\n20          test_20  0.128457\n21          test_21  0.118193\n22          test_22  0.113182\n23          test_23  0.115443\n24          test_24  0.109548\n25          test_25  0.116719\n26          test_26  0.126148\n27          test_27  0.113416\n28          test_28  0.124577\n29          test_29  0.118878\n...             ...       ...\n199970  test_199970  0.119310\n199971  test_199971  0.120649\n199972  test_199972  0.108737\n199973  test_199973  0.113754\n199974  test_199974  0.108523\n199975  test_199975  0.119526\n199976  test_199976  0.125986\n199977  test_199977  0.124259\n199978  test_199978  0.113819\n199979  test_199979  0.121935\n199980  test_199980  0.116171\n199981  test_199981  0.118762\n199982  test_199982  0.115111\n199983  test_199983  0.114632\n199984  test_199984  0.111995\n199985  test_199985  0.121921\n199986  test_199986  0.136331\n199987  test_199987  0.114038\n199988  test_199988  0.112645\n199989  test_199989  0.114323\n199990  test_199990  0.107310\n199991  test_199991  0.108730\n199992  test_199992  0.124444\n199993  test_199993  0.111922\n199994  test_199994  0.120437\n199995  test_199995  0.117515\n199996  test_199996  0.109423\n199997  test_199997  0.110167\n199998  test_199998  0.121068\n199999  test_199999  0.118597\n\n[200000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>0.117467</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>0.124543</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>0.133745</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>0.120209</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>0.117072</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>test_5</td>\n      <td>0.107997</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>test_6</td>\n      <td>0.108284</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>test_7</td>\n      <td>0.125165</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>test_8</td>\n      <td>0.105301</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>test_9</td>\n      <td>0.108563</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>test_10</td>\n      <td>0.123171</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>test_11</td>\n      <td>0.114445</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>test_12</td>\n      <td>0.118620</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>test_13</td>\n      <td>0.114974</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>test_14</td>\n      <td>0.107132</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>test_15</td>\n      <td>0.119293</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>test_16</td>\n      <td>0.121770</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>test_17</td>\n      <td>0.115963</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>test_18</td>\n      <td>0.123365</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>test_19</td>\n      <td>0.112272</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>test_20</td>\n      <td>0.128457</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>test_21</td>\n      <td>0.118193</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>test_22</td>\n      <td>0.113182</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>test_23</td>\n      <td>0.115443</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>test_24</td>\n      <td>0.109548</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>test_25</td>\n      <td>0.116719</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>test_26</td>\n      <td>0.126148</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>test_27</td>\n      <td>0.113416</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>test_28</td>\n      <td>0.124577</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>test_29</td>\n      <td>0.118878</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199970</th>\n      <td>test_199970</td>\n      <td>0.119310</td>\n    </tr>\n    <tr>\n      <th>199971</th>\n      <td>test_199971</td>\n      <td>0.120649</td>\n    </tr>\n    <tr>\n      <th>199972</th>\n      <td>test_199972</td>\n      <td>0.108737</td>\n    </tr>\n    <tr>\n      <th>199973</th>\n      <td>test_199973</td>\n      <td>0.113754</td>\n    </tr>\n    <tr>\n      <th>199974</th>\n      <td>test_199974</td>\n      <td>0.108523</td>\n    </tr>\n    <tr>\n      <th>199975</th>\n      <td>test_199975</td>\n      <td>0.119526</td>\n    </tr>\n    <tr>\n      <th>199976</th>\n      <td>test_199976</td>\n      <td>0.125986</td>\n    </tr>\n    <tr>\n      <th>199977</th>\n      <td>test_199977</td>\n      <td>0.124259</td>\n    </tr>\n    <tr>\n      <th>199978</th>\n      <td>test_199978</td>\n      <td>0.113819</td>\n    </tr>\n    <tr>\n      <th>199979</th>\n      <td>test_199979</td>\n      <td>0.121935</td>\n    </tr>\n    <tr>\n      <th>199980</th>\n      <td>test_199980</td>\n      <td>0.116171</td>\n    </tr>\n    <tr>\n      <th>199981</th>\n      <td>test_199981</td>\n      <td>0.118762</td>\n    </tr>\n    <tr>\n      <th>199982</th>\n      <td>test_199982</td>\n      <td>0.115111</td>\n    </tr>\n    <tr>\n      <th>199983</th>\n      <td>test_199983</td>\n      <td>0.114632</td>\n    </tr>\n    <tr>\n      <th>199984</th>\n      <td>test_199984</td>\n      <td>0.111995</td>\n    </tr>\n    <tr>\n      <th>199985</th>\n      <td>test_199985</td>\n      <td>0.121921</td>\n    </tr>\n    <tr>\n      <th>199986</th>\n      <td>test_199986</td>\n      <td>0.136331</td>\n    </tr>\n    <tr>\n      <th>199987</th>\n      <td>test_199987</td>\n      <td>0.114038</td>\n    </tr>\n    <tr>\n      <th>199988</th>\n      <td>test_199988</td>\n      <td>0.112645</td>\n    </tr>\n    <tr>\n      <th>199989</th>\n      <td>test_199989</td>\n      <td>0.114323</td>\n    </tr>\n    <tr>\n      <th>199990</th>\n      <td>test_199990</td>\n      <td>0.107310</td>\n    </tr>\n    <tr>\n      <th>199991</th>\n      <td>test_199991</td>\n      <td>0.108730</td>\n    </tr>\n    <tr>\n      <th>199992</th>\n      <td>test_199992</td>\n      <td>0.124444</td>\n    </tr>\n    <tr>\n      <th>199993</th>\n      <td>test_199993</td>\n      <td>0.111922</td>\n    </tr>\n    <tr>\n      <th>199994</th>\n      <td>test_199994</td>\n      <td>0.120437</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>test_199995</td>\n      <td>0.117515</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>test_199996</td>\n      <td>0.109423</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>test_199997</td>\n      <td>0.110167</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>test_199998</td>\n      <td>0.121068</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>test_199999</td>\n      <td>0.118597</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 2 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}