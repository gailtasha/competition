{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This is a learning kernal **\nif you have any notice please put it in comment ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost as xgb\n\nimport os\nprint(os.listdir(\"../input/santander-customer-transaction-prediction\"))\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')\ntest_data =  pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=[train_data,test_data]\nfor i in a :\n    print (i.shape)\n    \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot=train_data[\"target\"].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we note that 10% of data =1 \n![](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def mis_val (data):\n    a=[]\n\n    for f in data.columns:\n        a.append(train_data[f].isnull().sum())\n\n\n    print('check for missing data: ',a)\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mis_val(train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we note that there in not missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mis_val(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(train_data.iloc[:,2:],train_data.target)\n\nplt.figure(figsize=(17,14))\n\nplt.plot(rf.feature_importances_)\nplt.xticks(np.arange(train_data.iloc[:,2:].shape[1]), train_data.iloc[:,2:].columns.tolist(), rotation=90)\nfeature_importances=list(rf.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h=pd.DataFrame(feature_importances,columns=['x'])\nh.sort_values(by=['x'],ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there are top features which has big effect on target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"h.sort_values(by=['x'],ascending=True).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features =['var_81','var_12','var_139','var_53','var_110','var_26','var_174','var_22'\n          ,'var_164','var_109']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('mean',train_data.var_81.mean())\nprint('std',train_data.var_81.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features:\n    print (train_data[feature].nunique())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we note that var_12 has less unique numbers ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.var_12.value_counts().head(40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_12_unique = train_data.var_12.unique()\nvar_12_unique_sorted = np.sort(var_12_unique)\n                           \na=np.diff(var_12_unique_sorted)\npd.DataFrame(a).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"hhhh we play  0.0001 has repeated so much let's continue playing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"c=np.diff(a/0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(c).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train_data.loc[train_data['target'] == 0]\nt1 = train_data.loc[train_data['target'] == 1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nplt.subplots(2,5,figsize=(12,10))\nfor feature in features:\n    i+=1\n    plt.subplot(2,5,i)\n    sns.distplot(a=(t0[feature]),label=0, kde=False)\n    sns.distplot(a=(t1[feature]),label=1, kde=False)\n    plt.legend()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_scatter(df1, df2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(2,5,figsize=(14,14))\n\n    for feature in features:\n        i += 1\n        plt.subplot(2,5,i)\n        plt.scatter(df1[feature], df2[feature], marker='+')\n        plt.xlabel(feature, fontsize=9)\n    plt.show();\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will plot the distribution between the most important features in train and test ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_scatter(train_data,test_data,features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"almsot the same distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def coo_between_target_feat(df1, features,feats):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(5,5,figsize=(14,14))\n\n    for feature in features:\n        for x in feats:\n            i += 1\n            plt.subplot(5,5,i)\n            plt.scatter(df1[feature], df1[x], marker='o')\n            plt.xlabel(feature, fontsize=8)\n            plt.ylabel(x,fontsize=8)\n    plt.show();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat=['var_105','var_17','var_10','var_158','var_7']\nfeats=['var_31','var_42','var_140','var_74','var_30']\ncoo_between_target_feat(train_data,feat,feats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_enc =  pd.DataFrame(index = train_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\ndup_cols = {}\n\n\nfor i, c1 in enumerate(tqdm_notebook(train_enc.columns)):\n    for c2 in train_enc.columns[i + 1:]:\n        if c2 not in dup_cols and np.all(train_enc[c1] == train_enc[c2]):\n            dup_cols[c2] = c1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dup_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there is no dublicated columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_counts = train_data.nunique(dropna = False)\nfeats_counts.sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No constant values to drop ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train_data.iloc[:,2:],train_data.target\nX_1=train_data.loc[train_data.target==1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123,shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_cls = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.01,\n                max_depth = 3, alpha = 10, n_estimators = 10,gamma=0,reg_lambda= 1, scale_pos_weight= 5)\n\nxg_cls.fit(X_train,y_train)\npreds = xg_cls.predict(X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CM = confusion_matrix(y_test, preds)\nprint('Confusion Matrix is : \\n', CM)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we note that the algorithm can't estimate the target=1 \nso there is aproblem in splitting data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\npredss=xg_reg.predict(test_data.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nGBRModel = GradientBoostingRegressor(n_estimators=100,max_depth=2,learning_rate = 1.5 ,random_state=33)\nGBRModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('GBRModel Train Score is : ' , GBRModel.score(X_train, y_train))\nprint('GBRModel Test Score is : ' , GBRModel.score(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob = GBRModel.predict(test_data.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame({\"ID_code\":test_data[\"ID_code\"].values})\nsub_df[\"target\"] = y_pred_prob\nsub_df.to_csv(\"asa.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='7'>References</a>    \n\n[1] https://www.kaggle.com/gpreda/santander-eda-and-prediction \n* and hands on Ml book \n* and how to win a data science competition course ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}