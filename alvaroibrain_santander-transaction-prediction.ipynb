{"cells":[{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Kaggle's scikit-opt is old, has bugs\n!pip install scikit-optimize -U","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport shap\nimport eli5\n\nfrom matplotlib import pyplot as plt\nfrom tqdm.notebook import tqdm as notebook\nfrom tqdm import tqdm\n\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"shap.initjs();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Santander prediction challenge\n\nThis challenge consist on predicting whether a client of the bank will make or not a transaction in the future given a set of values.\n\n> As you know, Data Science it's an iterative process, so I'll be updating this notebook if I get better result than the posted ones. ()\n\nThe competition was already closed when I created the notebook, but I wanted to give a try and see how far I could get on my own.\n\n** What you'll find here **\n\n1. Data analysis\n2. Model baseline: LightGBM (default)\n3. Feature engineering\n4. Model tuning (after feature engineering)\n5. Model training\n\nLet's begin by loading the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TRAIN_CSV = '../input/santander-customer-transaction-prediction/train.csv'\nPATH_TEST_CSV = '../input/santander-customer-transaction-prediction/test.csv'\n\ntrain_df = pd.read_csv(PATH_TRAIN_CSV)\ntest_df = pd.read_csv(PATH_TEST_CSV)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data analysis\n\nFirst, it's important to see what the data it's about."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 200 predictors (which aren't explained, so knowing what's happening will be more difficult) and a target we have to predict. "},{"metadata":{"trusted":true},"cell_type":"code","source":"num_samples = train_df.groupby('target')['target'].count()\nnum_samples.plot.pie(title='Number of samples per category', autopct=\"%.0f%%\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_matrix = train_df.iloc[:,2:].corr()\nfig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(correlation_matrix, ax=ax);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Several things:\n\n- There is a great imbalance between the classes. I will take care of that later (if needed).\n- The data has been anonymized (already said), but since there is no correlation between variables, I think that extra processing steps have been taken. Even, it could also be synthetic or fabricated from real data."},{"metadata":{},"cell_type":"markdown","source":"Studying the distribution for each variable..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Commented for kernel commit speedup\n#fig, ax = plt.subplots(2, figsize=(30,10))\n#for i in tqdm(range(200)):\n#    var_name = f\"var_{i}\"\n#    sns.distplot(train_df[var_name], ax=ax[0], label=var_name)\n#    sns.distplot(test_df[var_name], ax=ax[1], label=var_name)\n#ax[0].set_title(\"KDEs of TRAIN variables.\")\n#ax[1].set_title(\"KDEs of TEST variables.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distributiuon of several variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for example, this ones\nvariables = ['var_0', 'var_23', 'var_89', 'var_112', 'var_152', 'var_199']\nfig, ax = plt.subplots(2,3, figsize=(16,8))\nfor i in range(len(variables)):\n    var_name = variables[i]\n    sns.distplot(train_df[var_name], ax=ax[i//3, i%3], label='train')\n    sns.distplot(test_df[var_name], ax=ax[i//3, i%3], label='test')\n    ax[i//3, i%3].set_title(f\"Distribution of variable {var_name}\")\n    ax[i//3, i%3].legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Differences between categories (WIDGET)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from IPython.html.widgets import *\nfrom ipywidgets import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_kde(var_index):\n    sns.distplot(train_df.loc[train_df['target'] == 0, 'var_'+str(var_index)], label='0')\n    sns.distplot(train_df.loc[train_df['target'] == 1, 'var_'+str(var_index)], label='1')\n    plt.legend()\n    plt.show()\n\ninteract(plot_kde, var_index=np.arange(200));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Above is an interactive IPython widget. If you can't see it, Fork the notebook and run the cell. It shows the difference between distributions of positive/negative transactions with a dropdown to select what variable to display.\n\nHowever, we can see that (for example in var_6), there are noticeable differences on the distribution"},{"metadata":{},"cell_type":"markdown","source":"Given the data distribution and the fact that ALL the features are uncorrelated, I think that this data has been transformed (projected onto another space/resampled...).\n\nI suppose that the original data had, at least, some categorical features, so I will check that by counting repeated values on each feature..."},{"metadata":{"trusted":true},"cell_type":"code","source":"nuniq_train_true = train_df[train_df['target'] == 1].iloc[:, 2:].nunique(axis=0)\nnuniq_train_false = train_df[train_df['target'] == 0].iloc[:, 2:].nunique(axis=0)\n\nnuniq_train_true /= len(train_df[train_df['target'] == 1])\nnuniq_train_false /= len(train_df[train_df['target'] == 0])\n\nfig, ax = plt.subplots(figsize=(30,5))\nax.bar(np.arange(start=0, stop=400, step=2), height=nuniq_train_true, color='red', label='1')\nax.bar(np.arange(stop=400, start=1, step=2), height=nuniq_train_false, color='blue', label='0', alpha=.7)\nax.set_title(\"Number of different values per varibale on each category (normalized)\")\nax.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another way of see the same (maybe more clear)"},{"metadata":{"trusted":true},"cell_type":"code","source":"len_true_samples = len(train_df[train_df['target']==1])\nunique_ratios = train_df[train_df['target']==1].iloc[:,2:].apply(lambda c: len(c.unique()) / len_true_samples, axis=0)\nfig, ax = plt.subplots(figsize=(30,30))\nsns.barplot(y=unique_ratios.index.tolist(), x=1-unique_ratios.values, ax=ax)\nax.set_title('Percentage of repeated values for each variable FOR TRUE SAMPLES');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_false_samples = len(train_df[train_df['target']==0])\nunique_ratios = train_df[train_df['target']==0].iloc[:,2:].apply(lambda c: len(c.unique()) / len_false_samples, axis=0)\nfig, ax = plt.subplots(figsize=(30,30))\nsns.barplot(y=unique_ratios.index.tolist(), x=1-unique_ratios.values, ax=ax)\nax.set_title('Percentage of repeated values for each variable FOR FALSE SAMPLES');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some Thoughts\n\n- The data seems to have been generated by some process of taking the real values and then, projecting them onto other space.\n  * There are repeated values (even though they are real numbers), so maybe they originally come categorical variables.\n- The FALSE data could had been augmentated\n    - When discriminating by type, the number of repeated values for the 0 samples is higher. This is an indicator that this data could had augmentated (through bootstraping techniques, for example).\n- var_68 seems to be highly repeated on TRUE and FALSE samples (distributions point that the values are focused around $5.02$)"},{"metadata":{},"cell_type":"markdown","source":"## Data splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_names = [f'var_{i}' for i in range(200)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test = train_test_split(train_df, test_size=0.4, random_state=196)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train shape: {X_train.shape}\")\nprint(f\"Test shape: {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some evaluation utilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n\ndef metrics_summary(y_real, y_pred):\n    \"\"\" Returns a  figure with the ROC curve, the Accuracy and AUC metrics (in the figure title)\"\"\"\n    fpr, tpr, thresholds = roc_curve(y_real, y_pred)\n    \n    fig, ax = plt.subplots(1, figsize=(5,5))\n    ax.plot(fpr, tpr, color='red')\n    ax.plot([0,1], [0,1], color='black', linestyle='--')\n    ax.set_title('ROC Curve')\n    plt.close()\n    \n    acc = accuracy_score(np.array(y_pred>.5, dtype='int'), y_real)\n    auc = roc_auc_score(np.array(y_pred>.5, dtype='int'), y_real)\n    \n    print(f\"- ACC {acc}\\n- AUC {auc}\")\n    \n    return fig\n\n\ndef predict_submission(model):\n    \"\"\" Takes a model and predicts on the test split. Returns the submission DataFrame\"\"\"\n    preds = model.predict_proba(test_df.drop(\"ID_code\", axis=1))[:,1]\n    return pd.DataFrame({'ID_code':test_df['ID_code'], 'target':preds})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline: Gradient Boosting (using all features and no CV)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bst = lgbm.LGBMClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nbst.fit(X_train[input_names], X_train['target']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = bst.predict_proba(X_test[input_names])[:,1]\nmetrics_summary(X_test['target'], preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.87 AUC. Let's see if we can achieve a higher value"},{"metadata":{},"cell_type":"markdown","source":"**Studying the result:**\n\nI will use the built-in explainer by LightGBM and then make an estimation using SHAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.DataFrame({'Feature': input_names, 'Importance':bst.feature_importances_}).sort_values('Importance', ascending=False)\n\nfig, ax = plt.subplots(figsize=(30,30))\nsns.barplot(y=importances.Feature, x=importances.Importance, ax=ax)\nax.set_title('Feature importances');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using SHAP estimations for 1k training samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"vals = X_train[input_names].sample(1000)\nexplainer = shap.TreeExplainer(bst, data=vals, model_output='probability', feature_perturbation='interventional')\nshap_values = explainer.shap_values(vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interact(lambda var: shap.dependence_plot(f\"var_{var}\", shap_values, vals), var=np.arange(200));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example, estimating which features are more important at this particular example\nshap.force_plot(explainer.expected_value, shap_values[110,:], vals.iloc[110,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclussions\n\nThere are a considerable number of variables that have not been used. It would be interesting to remove them.\n\nUsing SHAP, (interact widget), I found that some variables (68, 136, ...) do not affect to the model's outputs."},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering: Applying the lessons from the analysis\n\nThe thing that most catches my attention is the repetition of the values. I have two theories ATM: \n  - (Several) Original values were categorical\n  - Data has been augmentated using bootstraping\n  \nI will create an extra feature for each one of the originals to encode this repetition information (freq. encoding of the features) and train the same base model to see if that helps"},{"metadata":{"trusted":true},"cell_type":"code","source":"var_names = [f'var_{i}' for i in range(200)] \nvar_enc_names = [f'var_{i}_freq' for i in range(200)] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_hist_frequencies(dataframe):\n    hist_vars = {}\n    for v in var_names:\n        hist_vars[v] = dataframe[v].value_counts()\n    return hist_vars\n\ndef encode_freqs(dataframe, return_calc_hist = False):\n    \"\"\"Adds 200 more feature with the frequency encodings of the variables\"\"\"\n    # Build histogram of frequencies of each variable\n    hist_vars = {}\n    for v in var_names:\n        hist_vars[v] = dataframe[v].value_counts()\n        dataframe[v+\"_freq\"] = dataframe[v].map(hist_vars[v])\n    \n    if return_calc_hist:\n        return dataframe, hist_vars\n    return dataframe\n\ndef encode_freqs_with_hist(dataframe, histogram_data):\n    dataframe = dataframe.copy()\n    for v in var_names:\n        dataframe[v+\"_freq\"] = dataframe[v].map(histogram_data[v])\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histogram_vars = get_hist_frequencies(pd.concat([train_df[var_names], test_df[var_names]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_encoded = encode_freqs_with_hist(train_df, histogram_vars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test = train_test_split(train_df_encoded, test_size=0.4, random_state=196)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the same base model on the new data\n\n> (Not using CV because I want to rapid prototype ideas)"},{"metadata":{"trusted":true},"cell_type":"code","source":"bst = lgbm.LGBMClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nbst.fit(X_train[var_names+var_enc_names], X_train['target']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = bst.predict_proba(X_test[var_names+var_enc_names])[:,1]\nmetrics_summary(X_test['target'], preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The frequency encoding made an improvement of 0.02 AUC with respect to the baseline. Let's see if the new features are actually useful"},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.DataFrame({'Feature': var_names+var_enc_names, 'Importance':bst.feature_importances_}).sort_values('Importance', ascending=False)\nfig, ax = plt.subplots(figsize=(30,80))\nsns.barplot(y=importances.Feature, x=importances.Importance, ax=ax)\nax.set_title('Feature importances');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It doesn't seem that the new features drastically improve the model. The gain on AUC has to be due to the few new features the model uses, but the difference is so minimal that adding 200 plus features is not worth it."},{"metadata":{},"cell_type":"markdown","source":"(I'm pretty sure of the theories of value repetitions, though)\n\n\nLet's fine-tune the model with the base data to see if we can break the 0.9 barrier."},{"metadata":{},"cell_type":"markdown","source":"### Bayesian optimization\n\nI'm using a 3-fold CV to search optim params"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skopt import BayesSearchCV\nfrom skopt.space import Real, Categorical, Integer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_space = {\n    \"feature_fraction\": Real(0.001, 0.4),\n    \"max_depth\": Integer(10, 25)\n}\n\nbase_params = {\n    \"boost_from_average\": \"false\",\n    \"metric\" : \"auc\",\n    \"tree_learner\": \"serial\",\n}\n\noptimizer_args = {\n    'acq_func': \"EI\",\n    'n_initial_points': 15,\n    'acq_optimizer': 'sampling'\n}\n\n\nmodel = lgbm.LGBMClassifier(**base_params)\n\nbayes_search = BayesSearchCV(\n    estimator=model,\n    search_spaces=search_space,\n    n_iter=32,\n    cv=3,\n    n_jobs=-1,\n    scoring='roc_auc',\n    optimizer_kwargs=optimizer_args,\n    random_state=2343\n)\n\ndef on_step(optim_result):\n    score = bayes_search.best_score_\n    print(\"Best score: %s \" % (score,))\n    if score >= 0.98:\n        print('Interrupting!')\n        return True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# disabled for time execution reasons\n#%%time\n#bayes_search.fit(X_train[var_names+var_enc_names], X_train['target'], callback=on_step);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I disabled the former cell for commit execution time reasons, but I paste the execution output here:"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"\"\"\"\nBest score: 0.8819925481391506 \nBest score: 0.8819925481391506 \nBest score: 0.8819925481391506 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8824897736221471 \nBest score: 0.8826816117256729 \nBest score: 0.8826816117256729 \nBest score: 0.8826816117256729 \nCPU times: user 1min 18s, sys: 26.5 s, total: 1min 45s\nWall time: 19min 5s\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#params_model.update(bayes_search.best_params_)\n#params_model\n\n# These are the best hyperparams obtained using bayesian optimization\nparams_model = {\n 'boost_from_average': 'false',\n 'metric': 'auc',\n 'tree_learner': 'serial',\n 'feature_fraction': 0.10927610745498884,\n 'max_depth': 10,\n 'n_estimators': 100\n}\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model on the entire training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgbm.LGBMClassifier(**params_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel.fit(X_train[var_names+var_enc_names], X_train['target']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict_proba(X_test[var_names+var_enc_names])[:,1]\nmetrics_summary(X_test['target'], preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Its interesting how the `feature_fraction` hyperparam shows that it is the most important one. As we force each tree to use less features from the total, the overall ensemble works better. It seems that there are some few important variables (among the 200s) that really matter..."},{"metadata":{},"cell_type":"markdown","source":"## EXTRA: Meta modelling\n\nOn the former part, I found that the GB works best if only few variables are used to build each tree, so I'm going to make one last try :\n\nI'm going to fit 200 simple models, each one with both a particular var and its frequency encoded representation, and later merge all predictions using a simple logistic regression model (what is known as meta modelling)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.base import BaseEstimator\n\nfrom scipy.special import logit\n\nclass MetaModel(BaseEstimator):\n    \"\"\" Estimator which contains 200 models that are fitted with each var and var_encoded\"\"\"\n    def __init__(self):\n        super(MetaModel)\n        self.models = []\n        self.merger = LogisticRegression(solver='lbfgs')\n    \n    def fit(self, X, y, var_names, var_enc_names):\n        #Train boosting models\n        for v, venc in notebook(zip(var_names, var_enc_names)):\n            model = lgbm.LGBMClassifier(**{\n                     'boost_from_average': 'false',\n                     'metric': 'auc',\n                     'tree_learner': 'serial',\n                     'max_depth': 10,\n                     'n_estimators': 100\n                }\n            )\n            model.fit(X[[v, venc]], y)\n            self.models.append(model)\n        \n        # Train merger\n        preds = self._ensemble_predict(X, var_names, var_enc_names)\n        self.merger.fit(preds, y)\n        \n\n        return self\n    \n    def predict(self, X, var_names, var_enc_names):\n        predictions = self._ensemble_predict(X, var_names, var_enc_names)\n        preds = self.merger.predict_proba(predictions)[:, 1]\n    \n        return preds\n    \n    def _ensemble_predict(self, X, var_names, var_enc_names):\n        index = 0\n        predictions = np.zeros((len(X), len(self.models)))\n        for v, venc in notebook(zip(var_names, var_enc_names)):\n            model = self.models[index]\n            predictions[:, index] = model.predict_proba(X[[v, venc]])[:,1]    \n            index+=1\n        return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_names = [f\"var_{i}\" for i in range(200)]\nvar_enc_names = [i+\"_freq\" for i in var_names]\n\nmmodel = MetaModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mmodel.fit(X_train, X_train['target'], var_names, var_enc_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = mmodel.predict(X_test, var_names, var_enc_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_summary(X_test['target'], preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## THE END"},{"metadata":{},"cell_type":"markdown","source":"The original dataset has been anonymized, and I'm pretty sure that, at least, some of the columns were original categorical variables (because the number of different values on the train/test sets). I tried to exploit that and got around 0.90 AUC, which its not bad. However, this can be further improved (as the competiton LB shows). "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}