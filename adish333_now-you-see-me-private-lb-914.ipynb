{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import gc\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sys\nimport warnings\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\ndebug = False\nwarnings.simplefilter('ignore')\nplt.style.use('seaborn')\nrandom_state = 333","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reverse(train_df, test_df):\n    reverse_list = [\n        0, 1, 2, 3, 4, 5, 6, 8, 11, 15, 16, 18, 19,\n        22, 24, 25, 26, 32, 35, 37, 40, 48,\n        49, 51, 52, 53, 55, 60, 62, 66, 67, \n        69, 70, 71, 74, 78, 79, 82, 89, 90, 91, 94,\n        95, 97, 99, 105, 106, 110, 111, 112, 118,\n        119, 125, 128, 130, 133, 134, 135, 137, 138, 140,\n        144, 145, 147, 151, 155, 157, 159, 162, 163,\n        164, 167, 168, 170, 171, 173, 175, 179, 180,\n        181, 184, 187, 189, 190, 191, 195, 196, 199\n    ]\n    reverse_list = ['var_%d' % i for i in reverse_list]\n    for col in reverse_list:\n        train_df[col] = train_df[col] * (-1)\n        test_df[col] = test_df[col] * (-1)\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv', index_col='ID_code')\ntest_df = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv', index_col='ID_code')\npublic = np.load('../input/helpingdata/public_LB.npy')\nprivate = np.load('../input/helpingdata/private_LB.npy')\nfake = np.load('../input/helpingdata/synthetic_samples_indexes.npy')\ntarget = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = reverse(train_df, test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_idx = np.sort(np.concatenate((public, private)))\nreal_idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_real = test_df.iloc[real_idx]\ntest_real.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nconcat_df = pd.concat((train_df, test_real))\nfeatures = train_df.columns[1:]\nif debug:\n    features = features[:3]\nfor i, feature in enumerate(features):\n    print('Calculating var_{}'.format(i), end='\\r')\n    n_dups_dict = concat_df.loc[:, feature].value_counts().to_dict()\n    train_df.loc[:, 'count_{}'.format(feature)] = [n_dups_dict.get(value, 1) * np.sign(value)  for value in train_df.loc[:, feature]]\n    test_df.loc[:, 'count_{}'.format(feature)] = [n_dups_dict.get(value, 1) * np.sign(value) for value in test_df.loc[:, feature]]\n    train_df.loc[:, '{}_x_count_{}'.format(feature, feature)] = train_df.loc[:, feature] * np.absolute(train_df.loc[:, 'count_{}'.format(feature)])\n    test_df.loc[:, '{}_x_count_{}'.format(feature, feature)] = test_df.loc[:, feature] * np.absolute(test_df.loc[:, 'count_{}'.format(feature)])\n    \n    train_df.loc[:, 'count_inverse_{}'.format(feature)] = [(1 / n_dups_dict.get(value, 1)) * np.sign(value)  for value in train_df.loc[:, feature]]\n    test_df.loc[:, 'count_inverse_{}'.format(feature)] = [(1 / n_dups_dict.get(value, 1)) * np.sign(value) for value in test_df.loc[:, feature]]\n    train_df.loc[:, '{}_x_count_inverse_{}'.format(feature, feature)] = train_df.loc[:, feature] * np.absolute(train_df.loc[:, 'count_inverse_{}'.format(feature)])\n    test_df.loc[:, '{}_x_count_inverse_{}'.format(feature, feature)] = test_df.loc[:, feature] * np.absolute(test_df.loc[:, 'count_inverse_{}'.format(feature)])\n\nprint(train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(len(features)):\n#     sns.distplot(train_df.loc[train_df.target == 0, 'count_var_{}'.format(i)], hist=False)\n#     sns.distplot(train_df.loc[train_df.target == 1, 'count_var_{}'.format(i)], hist=False)\n#     plt.show()\n#     sns.distplot(train_df.loc[train_df.target == 0, 'var_{}_x_count_var_{}'.format(i,i)], hist=False)\n#     sns.distplot(train_df.loc[train_df.target == 1, 'var_{}_x_count_var_{}'.format(i,i)], hist=False)\n#     plt.show()\n#     sns.distplot(train_df.loc[train_df.target == 0, 'count_inverse_var_{}'.format(i)], hist=False)\n#     sns.distplot(train_df.loc[train_df.target == 1, 'count_inverse_var_{}'.format(i)], hist=False)\n#     plt.show()\n#     sns.distplot(train_df.loc[train_df.target == 0, 'var_{}_x_count_inverse_var_{}'.format(i,i)], hist=False)\n#     sns.distplot(train_df.loc[train_df.target == 1, 'var_{}_x_count_inverse_var_{}'.format(i,i)], hist=False)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"boosting\": 'gbdt',\n    \"max_depth\" : -1,\n    \"num_leaves\" : 7,\n    \"learning_rate\" : 0.01,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\" : 1,\n    \"feature_fraction\" : 0.3,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\" : 10,\n    \"tree_learner\": \"serial\",\n    \"boost_from_average\": \"false\",\n    \"bagging_seed\" : random_state,\n    \"verbosity\" : 1,\n    \"seed\": random_state\n}","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%%time\ndf_train = train_df.reset_index()\ndf_test = test_df.reset_index()\n\nif debug:\n    df_train = df_train[:1000]\n    df_test = df_test[:1000]\n    target = target[:1000]\n    \nskf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=random_state) # keep splits = 10 for best results\noof = df_train[['ID_code', 'target']]\noof['predict'] = 0\npredictions = df_test[['ID_code']]\nval_aucs = []\nfeature_importance_df = pd.DataFrame()\nfeatures = [col for col in df_train.columns if col not in ['target', 'ID_code']]\nX_test = df_test[features].values\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df_train, target)):\n    X_train, y_train = df_train.iloc[trn_idx][features], df_train.iloc[trn_idx]['target']\n    X_valid, y_valid = df_train.iloc[val_idx][features], df_train.iloc[val_idx]['target']\n    print(\"shape of training data: \", X_train.shape)\n    trn_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    evals_result = {}\n    lgb_clf = lgb.train(lgb_params,\n                    trn_data,\n                    100000,\n                    valid_sets = [trn_data, val_data],\n                    early_stopping_rounds=1000,\n                    verbose_eval = 1000,\n                    evals_result=evals_result\n                   )\n    p_valid = lgb_clf.predict(X_valid, num_iteration=lgb_clf.best_iteration)\n    yp = lgb_clf.predict(X_test, num_iteration=lgb_clf.best_iteration)\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] =  [col for col in X_train.columns]\n    fold_importance_df[\"importance\"] = lgb_clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    oof['predict'][val_idx] = p_valid\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    predictions['fold{}'.format(fold+1)] = yp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_auc = np.mean(val_aucs)\nstd_auc = np.std(val_aucs)\nall_auc = roc_auc_score(oof['target'], oof['predict'])\nprint(\"Mean auc: %.5f, std: %.5f. All auc: %.5f.\" % (mean_auc, std_auc, all_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('lgb_all_predictions.csv', index=None)\nsub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\nsub_df[\"target\"] = predictions['target']\nsub_df.to_csv(\"submission.csv\", index=False)\noof.to_csv('lgb_oof.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}