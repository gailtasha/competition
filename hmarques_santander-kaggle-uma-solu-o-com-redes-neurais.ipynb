{"cells":[{"metadata":{"id":"ilV8_PfCXF32"},"cell_type":"markdown","source":"#Estudo de caso do Kaggle - Banco Santander\n#Uma abordagem com Redes Neurais construído no Keras\n\n**Henrique Dias Marques - Analista Master - Petrobras**\n<br/>\n**Em meio a Pandemia de 2020**\n\n\nNesta competição hospedada no Kaggle, o Banco Santander nos propôs um problema muito comum em qualquer atividade comercial, cujo propósito é avaliar os potenciais clientes nas ofertas de produtos e serviços. Especificamente o banco apresenta 200 características diferentes para cada cliente as quais serão consideradas para averiguar se os mesmos irão no futuro realizar determinada transação com o banco. Sempre visando dar atenção aos potenciais clientes, a estratégia do banco foi procurar a comunidade de Cientistas da Dados do mundo para estabelecer o melhor modelo que respondesse esta questão.\n\nA base de dados é bem extensa pois possui 200 mil exemplos de clientes para a construção do modelo na fase de treinamento e apresenta a mesma quantidade para realizarmos os testes nos modelos. O problema é de classificação binária [0, 1] com aprendizagem supervisionada, onde o Banco apresenta o resultado do que aconteceu com 200 mil clientes.\n\nUm aspecto interessante deste caso é que as 200 características dos clientes, apresentadas pelo Banco Santander, não possui a informação de seu metadado. Não sabemos o que significam as 200 características! Isto mostra o quão interessante são os algorítmos de Machine Learning, capazes de lidar e aprender com números que expressam informações de uma natureza só conhecida pelo seu resultado final: [1] - o cliente realizou a transação no futuro e [0] - o cliente desistiu da transação.","execution_count":null},{"metadata":{"id":"MSkym6q3Xjp8"},"cell_type":"markdown","source":"#Carregando as bibliotecas\n\nVamos iniciar com a carga de bibliotecas necessárias para o desenvolvimento do modelo. À medida que o código for sendo explicado você entenderá a razão das bibliotecas aqui importadas.","execution_count":null},{"metadata":{"id":"Zmmff2hvX3GH","executionInfo":{"status":"ok","timestamp":1593270726517,"user_tz":180,"elapsed":2786,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"4d78829d-fd0d-41f6-8f37-4c4326403f88","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.initializers import TruncatedNormal, RandomUniform, RandomNormal\nfrom keras.constraints import unit_norm, max_norm\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, precision_score, \\\n            recall_score, f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"jtYDOZ09YEku"},"cell_type":"markdown","source":"#Carga de dados\n\nO código abaixo realiza a carga dos dados em dataframes - Pandas - para uso no treinamento e predição. Cria também variáveis que serão utilizadas na construção da solução. O X_test_index se faz necessário porque na criação do arquivo de submissão ao Kaggle ele será usado como índice no arquivo.\n\nPara exercitar este exemplo, substitua o caminho da pasta para sua condição específica.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"WsxI2MCIPtnM","executionInfo":{"status":"ok","timestamp":1593270995306,"user_tz":180,"elapsed":13772,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"e0a796bd-78aa-4270-ca6e-39457dbcec05","trusted":true},"cell_type":"code","source":"print ('\\nRealizando carga de dados....\\n')\nX_train = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/train.csv\", index_col='ID_code')\nX_test = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/test.csv\", index_col='ID_code')\nprint ('\\nCarga de dados concluída....\\n')\n\n\nprint ('\\nPreparando os conjuntos de treinamento e teste....\\n')\ny_train = X_train.target\nX_train.drop(['target'], axis=1, inplace=True)\nX_test_index = X_test.index\n","execution_count":null,"outputs":[]},{"metadata":{"id":"L4DNEmY8Qanx","executionInfo":{"status":"ok","timestamp":1593270816752,"user_tz":180,"elapsed":702,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"e995f97e-eb17-4a61-e67e-9e1b96c0553d","trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"CvJ7J8E9RyV9","executionInfo":{"status":"ok","timestamp":1593270818944,"user_tz":180,"elapsed":567,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"10b98864-b05c-4ab7-908a-5f9b403d0c3b","trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"EUHCV-iyYaOe"},"cell_type":"markdown","source":"<br />\nÉ importante verificarmos se há dados nulos ou ausentes nestes conjuntos. Os códigos abaixo avaliam isto e conclui que não há. Também logo a seguir vou \"plotar\" alguns gráficos que representam algumas das 200 características dos dados de treinamento e que depois você também poderá verificar nos dados de teste. É fácil notar que todas elas possuem uma distribuição normal. \n\n<br />","execution_count":null},{"metadata":{"id":"5au0pKgLTk2B","executionInfo":{"status":"ok","timestamp":1593270823187,"user_tz":180,"elapsed":712,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"825b3454-4d5c-47d0-90b9-ebea303ac58f","trusted":true},"cell_type":"code","source":"sum(X_train.columns.isnull())","execution_count":null,"outputs":[]},{"metadata":{"id":"f2bQ87kvYeqT","executionInfo":{"status":"ok","timestamp":1593270824419,"user_tz":180,"elapsed":592,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"ba5387ef-e70b-4b70-f008-f638a5ec28c6","trusted":true},"cell_type":"code","source":"sum(X_test.columns.isnull())","execution_count":null,"outputs":[]},{"metadata":{"id":"YTg7Y-HwYiKr","executionInfo":{"status":"ok","timestamp":1593270828749,"user_tz":180,"elapsed":3492,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"969e8889-0922-4afa-c543-2b1e8d38a955","trusted":true},"cell_type":"code","source":"sns.set()\nplt.figure(figsize=(30,3))\npos = 0\nfor col in X_train.columns.values[0:9]:\n        pos+=1\n        plt.subplot(190+pos)\n        plt.hist(X_train[col], density=True, bins=60)\n        plt.title(col)\n        plt.ylabel('Probability')\n        plt.xlabel('Data')\nprint ('\\nGráficos das primeiras colunas...\\n')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"rZ-_rMGfTuYf"},"cell_type":"markdown","source":"#Feature Engineering\n<br/>\nNesta sessão vou colocar um insight que tive baseado na ideia de que dados com desvios padrões pequenos possuirão pouca interferência nos resultados, portanto será melhor termos estes dados como valores ordinais. então a ideia será discretizá-los e transformá-los em colunas one-hot. O std_threshold é o desvio padrão máximo que aceitaremos em uma catacterística. Portanto todas as colunas com desvio padrão menor que std_threshold serão convertidos em valores discretos de acordo com o número de bins. \n\nOs valores discretos são transformados em características \"dummies\" no padrão one-hot(veja parâmetro 'discretizer')\n\n","execution_count":null},{"metadata":{"id":"oSZQ8-iOT5Ax","trusted":true},"cell_type":"code","source":"std_threshold = 8\nbins = 6","execution_count":null,"outputs":[]},{"metadata":{"id":"pacVtcmdTjDx","executionInfo":{"status":"ok","timestamp":1593271009292,"user_tz":180,"elapsed":641,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"a60a9de5-5c75-46b4-c4cb-4094c0504a18","trusted":true},"cell_type":"code","source":"print ('\\nEstabelecendo as metricas para criação e features...\\n')\n\n    \n#n_unicos_train = X_train.nunique()\n#n_unicos_test = X_test.nunique()\n    \nstd_train = X_train.std(axis=0)\nstd_test = X_test.std(axis=0)\n    \ncol_train_interested = np.where(std_train >= std_threshold)\ncol_test_interested = np.where(std_test >= std_threshold)\n    \ncol_train_for_bins = np.where(std_train < std_threshold)\ncol_test_for_bins = np.where(std_test < std_threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"Qg57GYkQUgsp","executionInfo":{"status":"ok","timestamp":1593271023819,"user_tz":180,"elapsed":8249,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"922742ed-6432-4241-c7e0-ae406d61d3c2","trusted":true},"cell_type":"code","source":"print ('\\nDiscricionando colunas com valores pequenos de Desvio Padrão...\\n')\n     \nX_train_e = X_train[std_train.index[(col_train_for_bins)]]\nX_test_e = X_test[std_test.index[(col_test_for_bins)]]\n    \ndiscretizer = preprocessing.KBinsDiscretizer(n_bins=bins, encode='onehot', strategy='uniform')\n    \ndiscretizer.fit(X_train_e)\nsparse_matrix = discretizer.transform(X_train_e)\ntrain_onehot = sparse_matrix.todense()\n\ndiscretizer.fit(X_test_e)\nsparse_matrix = discretizer.transform(X_test_e)\ntest_onehot = sparse_matrix.todense()\n\n\nprint ('\\nEliminando colunas com std < std_threshold ...\\n')\n    \nX_train = X_train[std_train.index[(col_train_interested)]]\nX_test = X_test[std_test.index[(col_test_interested)]]","execution_count":null,"outputs":[]},{"metadata":{"id":"HvDsalPtWFhr","executionInfo":{"status":"ok","timestamp":1593271029180,"user_tz":180,"elapsed":783,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"0f98d289-39a2-4780-e1f0-0ff354ba4667","trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"dGHt0EpQZC1S"},"cell_type":"markdown","source":"#Normalização.\nA normalização é um item essencial - para a performance da execução do treinamento - quando trabalhamos com Redes Neurais e também com outros algorítmos de Machine Learning que utilizam funções sigmoidais ou regressões logísticas. Ela também visa permitir que determinadas características dos dados não se sobreponham às outras.\n\nPara facilitar nosso trabalho vamos utilizar bibliotecas do SciKit Learn que realizam tais operações com facilidades. No código abaixo utlizamos o método StandardScaler do módulo preprocessing para este fim. É importante notar que a saída destas funções retornam um conjunto de arrays (numpy arrays) e não mais dataframes.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Número de características com valores de desvio padrão maiores que std_threshold\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"QryqR5GLY7Th","trusted":true},"cell_type":"code","source":"scaler =  preprocessing.StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"SX6ES5VaZJ4A","executionInfo":{"status":"ok","timestamp":1593271153346,"user_tz":180,"elapsed":593,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"5919ad0f-f185-4399-d442-1495fde316a1","trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"id":"mTT1MdamWy6H"},"cell_type":"markdown","source":"Adicionando características que foram discretizadas. Já estão no formato one-hot ","execution_count":null},{"metadata":{"id":"o7TlIFRpWxP3","executionInfo":{"status":"ok","timestamp":1593271164860,"user_tz":180,"elapsed":6890,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"62d1647a-b682-4fbe-fea1-751bd1b8ab80","trusted":true},"cell_type":"code","source":"print ('\\nConcatenando as matrizes...\\n')   \nX_train = np.concatenate((X_train, train_onehot), axis=1)\nX_test = np.concatenate((X_test, test_onehot), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"2yHAE2TnXMHN","executionInfo":{"status":"ok","timestamp":1593271190127,"user_tz":180,"elapsed":647,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"a69fc2c1-bc6b-4519-ec11-83b003b7ab3a","trusted":true},"cell_type":"code","source":"X_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"id":"EBjEQZZSZSw_"},"cell_type":"markdown","source":"#Aplicando o primeiro modelo com \"cross-validation\"\nNeste exercício inicial vamos aplicar uma estrutura de rede que estabeleci após sucessivos testes para definição dos melhores hyerparâmetros da Rede Neural. Utilizei no modelo as bibliotecas do Keras - uma poderosa ferramenta para construção de Redes Neurais que executa instruções sobre o TensorFlow. O seu modelo sequencial é mais simples de codificação além do fácil entendimento das diversas camadas que foram escolhidas, portanto, optei por esta abordagem. Para o entedimento deste código pressuponho que o leitor já possui toda a base teórica de construção de Redes Neurais. O otimizador escolhido foi o Adam, depois que realizei sucessivos testes com outros otimizadores, dentre eles o SGD e RMSprop.\n\nA solução neste momento também será realizada com o uso de validação cruzada - parâmetro 'validation_split'. Este processo de divisão de dados de treinamento é essencial para avaliarmos a performance do modelo. \n\nO modelo utiliza duas técnicas para regularização que é o \"dropout\" e o \"kernel_constraint\", pois verificamos nos sucessivos testes como facilmente nos defrontamos com \"overfitting\" durante a fase de treinamento. Verifique que no parâmetro 'metrics' inserimos nossas função 'Roc_auc' e 'average_precision' citadas no inicio deste artigo. Com estas funções é possível availarmos o desempenho do processo de aprendizado ao longo da execução do código. Os resultados ficam armazenados no callback - history.","execution_count":null},{"metadata":{"id":"tFXLFQOiZM3Q","executionInfo":{"status":"ok","timestamp":1593283131818,"user_tz":180,"elapsed":1383447,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"36fd4a50-2d4c-4090-ce4c-f39f21faba44","trusted":true},"cell_type":"code","source":"input_len = X_train.shape[1]\n\n\n    \nmodel = Sequential([\n#Dense(input_len, input_shape=(input_len,)),\nDense(256, input_shape=(input_len,)),\nActivation('relu'),\nDropout(0.5),\nDense(128, kernel_initializer='random_normal', activation = 'relu',  kernel_constraint=unit_norm()),\nDropout(0.5),\nDense(64, kernel_initializer='random_normal', activation = 'relu',  kernel_constraint=unit_norm()),\nDropout(0.3),\nDense(32, kernel_initializer='random_normal', activation = 'relu',  kernel_constraint=unit_norm()),\nDropout(0.1),\nDense(1),\nActivation('sigmoid'),\n])\n    \n    \nopt = optimizers.Adam(learning_rate=0.00005)    \n#opt = optimizers.Adam(learning_rate=0.001)\n    \n        \nmodel.compile(optimizer=opt,\n              loss= 'binary_crossentropy',\n              metrics=['accuracy'])\n    \nprint(model.summary())\n\n\nhistory = model.fit(X_train, y_train, \\\n                epochs= 120,\\\n                batch_size=1024,\\\n                validation_split=0.1,\\\n                )\n           ","execution_count":null,"outputs":[]},{"metadata":{"id":"PUPei1qmakl8"},"cell_type":"markdown","source":"Os gráficos a seguir nos dão uma melhor avaliação do que ocorreu durante o treinamento. Temos as visões de acurácia e do 'loss' para as duas sessões dos dados: treinamento e validação.","execution_count":null},{"metadata":{"id":"KXnLq8USamG1","executionInfo":{"status":"ok","timestamp":1593283156984,"user_tz":180,"elapsed":2364,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"bfd74f37-2fff-417b-ca71-a35e14d7ef31","trusted":true},"cell_type":"code","source":"sns.set()\nplt.figure(figsize=(15, 7))\n\nplt.subplot(141)\nplt.plot(history.history['accuracy'], label='ACC')\nplt.plot(history.history['val_accuracy'], label='Val_ACC')\nplt.xlabel('Epochs')\nplt.ylabel('Acurácia')\nplt.legend()\n\n\nplt.subplot(142)\nplt.plot(history.history['loss'], label='LOSS')\nplt.plot(history.history['val_loss'], label='Val_LOSS')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"DIwE0X2ZaqXC"},"cell_type":"markdown","source":"A partir dos gráficos acima podemos concluir algumas questões:\n\n* Embora o modelo continua crescente na sua performance nos sucessivos 'epochs' o \nmesmo não acontece nos dados de validação.\n* O 'loss' deixa de cair em torno de 30 a 40 epochs\nAs métricas nos dados de validação demonstram queda crescente após 10 epochs.\n\nFica claro que mesmo adotando um conjunto de ações para evitar o 'overfitting' o modelo claramente não consegue generalizar quando submetido aos dados de validação. As melhores abordagens para solução deste problema publicado em diversas documentações de Machine Learning sugerem que devemos trabalhar em duas vertentes:\n\n* Acrescentar mais dados de treinamento ao modelo.\n* Repensar a estrutura da rede\n\nAntes de aplicarmos algumas das soluções acima, vamos aplicar uma técnica muito comum e fácil de realizar - o 'early stopping'. Pelos gráficos vericamos que o modelo tem boa performance até 40 epochs. No código abaixo realizaremos novamente o treinamento e submeteremos o arquivo ao Kaggle para confrontar o resultado. Desta vez sem a validação cruzada, claro!\n\n","execution_count":null},{"metadata":{"id":"NgUmQOE8baep","executionInfo":{"status":"ok","timestamp":1593285185866,"user_tz":180,"elapsed":735948,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"b13c646f-0a4f-4dc0-e622-bf27188c3c08","trusted":true},"cell_type":"code","source":"input_len = X_train.shape[1]\n\n\nmodel = Sequential([\n#Dense(input_len, input_shape=(input_len,)),\nDense(256, input_shape=(input_len,)),\nActivation('relu'),\nDropout(0.5),\nDense(128, kernel_initializer='random_normal', activation = 'relu',  kernel_constraint=unit_norm()),\nDropout(0.5),\nDense(64, kernel_initializer='random_normal', activation = 'relu',  kernel_constraint=unit_norm()),\nDropout(0.3),\nDense(32, kernel_initializer='random_normal', activation = 'relu',  kernel_constraint=unit_norm()),\nDropout(0.1),\nDense(1),\nActivation('sigmoid'),\n])\n    \n    \nopt = optimizers.Adam(learning_rate=0.00005)    \n#opt = optimizers.Adam(learning_rate=0.001)\n    \n        \nmodel.compile(optimizer=opt,\n             loss= 'binary_crossentropy',\n              metrics=['accuracy'])\n    \nprint(model.summary())\n\n\nhistory = model.fit(X_train, y_train, \\\n                epochs= 40,\\\n                batch_size=1024,\\\n                #validation_split=0.1,\\\n                #class_weight = compute_class_weight('balanced', y_train.sum(), len(y_train))\n                )","execution_count":null,"outputs":[]},{"metadata":{"id":"ZGFPF3j-cGBe"},"cell_type":"markdown","source":"# Envio do arquivo ao kaggle.\nVamos agora aplicar o modelo treinado na base de teste e avaliar como será o seu resultado. O código abaixo envia as predições do modelo de acordo com o formado estabelecido nas competições.\n\n","execution_count":null},{"metadata":{"id":"HDaa0jjNdQA-","executionInfo":{"status":"ok","timestamp":1593285198088,"user_tz":180,"elapsed":524,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"9c688ba7-92ac-4c44-d27f-6ed003e356b9","trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"kmNQ6YIBcIgY","executionInfo":{"status":"ok","timestamp":1593285243915,"user_tz":180,"elapsed":33754,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"08550f94-fffa-4a67-a40f-a50b3dd1528c","trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\n   \npred = predictions.reshape((200000,))\noutput = pd.DataFrame({'ID_code': X_test_index, 'target': pred})\noutput.to_csv('ANN_Santander_GColab_fet_Eng_TPU_3.csv', index=False)\nprint(\"O arquivo para envio ao Kaggle foi salvo com sucesso!\")","execution_count":null,"outputs":[]},{"metadata":{"id":"oE4JsCcFcNn2","executionInfo":{"status":"ok","timestamp":1593285277556,"user_tz":180,"elapsed":703,"user":{"displayName":"Henrique Marques","photoUrl":"","userId":"04526412285454721918"}},"outputId":"5366b81a-1214-4b98-9ee0-d3f007604542","trusted":true},"cell_type":"code","source":"predictions[0:10]","execution_count":null,"outputs":[]},{"metadata":{"id":"kejZoXoHcUE2"},"cell_type":"markdown","source":"# Conclusão\nA aplicação de uma Rede Neural para a solução proposta pelo Banco Santander apresenta uma boa resposta para os dados originais como foram fornecidos. A performance ainda está distante das melhores resultados apresentados na competição que se deu no ano passado, mas que utilizaram outras abordagens de Machine Learning - como o LightGBM que é bastante usado como algoritmo venceder pelas equipes que participam do Kaggle - e um extenso trabalho de preparação dos dados. Vale salientar que neste exemplo não adotei nenhuma destas abordagem, e portanto, poderemos melhorar ainda mais esta performance com a utilização de Feature Engineearing ou mesmo modificando a estrutura da Rede Neural.\n\nNa próxima publicação sobre esta competição irei mostrar como um pouco de Feature Engeeneearing sobre os dados de Treinamento e Testes será possível obter um ganho na performance.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}