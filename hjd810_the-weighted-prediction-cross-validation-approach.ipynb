{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Short Intro to Weighted Cross-Validation"},{"metadata":{},"cell_type":"markdown","source":"#### This kernel is introducing a weighted approach to Cross-validation which oddly I don't see many kagglers using or maybe revealing.\n\n## Formulation: \n    The final predictions are weighted according to the scores of the validation set per fold\n$\\textbf{v} = MinMax\\;(\\;vector \\; of max \\; validation\\; scores\\; per\\; fold\\;)$ range = [min=0,max=1] <br> \n$\\textbf{p} = matrix \\;(\\;n\\_folds,\\; n\\_predictions\\;)$<br> \n$\\textbf{R} =  \\frac{1}{n\\_folds} \\sum_i (\\textbf{v}  \\circ  \\textbf{p})_i$ <br> \n\n\n\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.axes_style(\"darkgrid\")\nfrom sklearn.model_selection import KFold,StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import  train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- \nFor the sake of just introducting the approach we will be using a fast lgbm model with a sample from the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_t = pd.read_csv('../input/train.csv')\ndf_tst = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frac_sample =1\ndf_train = df_t.copy().sample(frac=(frac_sample))\ndf_test = df_tst.copy().sample(frac=(frac_sample))\nX = df_train.iloc[:,2:]\ny = df_train['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\nprint('Train : ' , X_train.shape)\nprint('Test : ' , X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model LGBM \nparam = {\n    'bagging_freq': 8, #handling overfitting\n    'bagging_fraction': 0.4, #handling overfitting - adding some noise\n    'boost_from_average':True,\n    'boost': 'gbdt',\n    'feature_fraction': 0.4, #handling overfitting\n    'learning_rate': 0.01, #the changes between one auc and a better one gets really small thus a small learning rate performs better\n    'max_depth': 2,  #smaller trees less overfitting\n    'metric':'auc',\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': 0\n    }\n\nlgbm_X = X_train\nlgbm_y = y_train\nlgbm_test_x = X_test\nlgbm_test_y = y_test\nval_pred = []\nimportand_folds = np.zeros(lgbm_X.shape[1])\ntest_pred_lgbm = []\ntarget_pred = []\nkf = KFold(n_splits=23,random_state=1346)\nfor _fold, (trn_idx, val_idx) in enumerate(kf.split(lgbm_X.values, lgbm_y.values)):\n            Xtrn, ytrn = lgbm_X.iloc[trn_idx], lgbm_y.iloc[trn_idx]\n            Xval, y_val = lgbm_X.iloc[val_idx], lgbm_y.iloc[val_idx]\n            #-----------------------------------------\n            print('Fold: ', _fold)\n            dtrain = lgb.Dataset(Xtrn,label=ytrn)\n            dval = lgb.Dataset(Xval,label=y_val)\n            clf = lgb.train(param,dtrain,num_boost_round=5000,valid_sets=(dtrain,dval),valid_names=['train','valid'],\n                      verbose_eval=500,\n                     early_stopping_rounds=250)\n            #----------------------------------------\n            importand_folds += clf.feature_importance()\n            #validation score\n            val_pred.append(clf.best_score['valid']['auc'])\n            #save the test prediction per fold\n            test_pred_lgbm.append(clf.predict(lgbm_test_x))\n            print('-'*50)\n            target_pred.append(clf.predict(df_test.iloc[:,1:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler \ndef weight_pred(preds,vals,n_splits,range_features =(0.9,1) ):\n    ## Setting Up predictions dataframe\n    df_pred = pd.DataFrame(preds)\n    df_pred.columns = ['pred_'+str(x) for x in range(df_pred.shape[1])]\n    \n    \n    #Min Max scaling for the max fold validation values\n    #the feature range plays the role of a hyper-parameter to balance the effect of the validation set on the test set\n    scaler = MinMaxScaler(feature_range=range_features).fit(np.array([vals]).T)\n    val_scaled = scaler.transform(np.array([vals]))\n    \n    #multiply scaled values by  each row in the dataframe which represent a fold\n    df_scaled = df_pred.mul(val_scaled.tolist()[0],axis=0)\n    \n    #sum and divide\n    df_pred_final = df_pred.sum(axis=0) / n_splits\n    df_scaled_final = df_scaled.sum(axis=0) / n_splits\n    return df_pred,df_scaled,df_pred_final,df_scaled_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing predictions\ndf_pred,df_scaled,df_pred_final,df_scaled_final = weight_pred(test_pred_lgbm,val_pred,kf.n_splits)\n\n#target predictions\n_1,_2,df_test_pred_final,df_test_scaled_final = weight_pred(target_pred,val_pred,kf.n_splits)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions DistPlot Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(20,12))\nfor fold in range(df_pred.shape[0]):\n    sns.distplot(df_pred.iloc[fold],label='fold_'+str(fold) + 'val-score: {:.2}'.format(val_pred[fold]),ax=ax1, hist=False)\n    sns.distplot(df_scaled.iloc[fold],label='fold: '+str(fold) + '  val_score: {:.2}'.format(val_pred[fold]),ax=ax2,hist=False)\nax1.set_title('Non-Weigted Predictions')\nax2.set_title('Weigted Predictions')\nplt.tight_layout()\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the extra noise the weighting applies in the right plot"},{"metadata":{},"cell_type":"markdown","source":"# Evaluation\n\nThe Evaluation should be run on multiple prediction samples, but this is an intro so I'm excused :D\n\nOr.....you can try it yourself.....that also works :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scores\nnormal_score = roc_auc_score(y_test,df_pred_final.values)\nweighted_score = roc_auc_score(y_test,df_scaled_final.values)\nprint('Test Scores')\nprint('-'*50)\nprint('Normal Score :   {:.10}'.format(normal_score))\nprint('Weighted Score : {:.10}'.format(weighted_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let check the test scores difference depending on the range given\nrng  = [(0.5,1),(0.6,1),(0.7,1),(0.8,1),(0.9,1),(0.5,0.8),(0.6,0.8),(0.2,0.8)]\nwt_scores = []\nnon_wt_scores =  []\nfor r in rng:\n    df_pred,df_scaled,df_pred_final,df_scaled_final = weight_pred(test_pred_lgbm,val_pred,kf.n_splits,range_features = r)\n    non_wt_scores.append(roc_auc_score(y_test,df_pred_final.values))\n    wt_scores.append(roc_auc_score(y_test,df_scaled_final.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,9))\nsns.lineplot(x=range(len(non_wt_scores)),y=non_wt_scores,label='Non-Weighted')\nsns.lineplot(x=range(len(wt_scores)),y=wt_scores,label='Weighted')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This can also prove to have better performance when dealing with a larger distributed range for predictions, and that's why we can see only a minor improvement regarding the prediction for this dataset. "},{"metadata":{},"cell_type":"markdown","source":"Thank you ! Any Feedback Appreciated "},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub_pred(preds,df_test,name='submission.csv'):\n    sub_df = pd.DataFrame({'ID_code':df_test['ID_code'],'target':preds})\n    sub_df.to_csv(name, index=False)\n\n    \nsub_file = 'scaled_pred.csv'\nsub_pred(df_test_scaled_final.values,df_test,name=sub_file)\nprint(sub_file+'-submitted successfully')\n\nsub_file = 'non_scaled_pred.csv'\nsub_pred(df_test_pred_final.values,df_test,name=sub_file)\nprint(sub_file+'-submitted successfully')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}