{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/gpreda/santander-eda-and-prediction/data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport gc, os, logging, datetime, warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import StratifiedKFold\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nPATH ='/kaggle/input/santander-customer-transaction-prediction/'\ntrain_df = pd.read_csv(PATH+\"train.csv\") #(200000, 202)\ntest_df = pd.read_csv(PATH+\"test.csv\") #(200000, 201)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing(data):\n    total = data.isnull().sum()\n    length=data.shape[0]\n    percentage=total*100/data.count()\n    miss = pd.concat([total, percentage], axis=1, keys=['Total', 'Percentage'])\n    types= []\n    for col in data.columns:\n        dtypes=str(data[col].dtype)\n        types.append(dtypes)\n    miss['Types'] = types\n    return miss.T\n    \nmissing(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corrmat = train_df.T[:10].corr()\n# fig, axes = plt.subplots(figsize=(20, 15))\n# fig, axes = sns.heatmap(corrmat, vmin=0, vmax=1)\n# fig.show()\n\ndef plot_features(df1, df2, features):\n    i = 1\n    fig, ax = plt.subplots(4, 4, figsize=(14,14))\n    for f in features:\n        plt.subplot(4,4,i)\n        plt.scatter(df1[f], df2[f], marker='+', label=f)\n        plt.xlabel(f, fontsize=9)\n        i+=1\n    plt.show()\n\nfeats = ['var_0','var_1','var_2','var_3','var_4','var_5','var_6','var_7','var_8','var_9','var_10','var_11','var_12','var_13','var_14','var_15']\nplot_features(train_df, test_df, feats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df['target'], palette='Set3')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ones = train_df['target'].value_counts()[1]\nprint(\"There are {}% target with value 1\".format(100*ones/train_df['target'].count()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_dist(df1, df2, features):\n    sns.set_style(\"whitegrid\")\n    fig, axes = plt.subplots(5,5,figsize=(20,24))\n    t0 = train_df.loc[train_df['target']==0]\n    t1 = train_df.loc[train_df['target']==1]\n    i=0\n    for f in features:\n        i+=1\n        plt.subplot(5,5,i)\n        sns.distplot(t0[f], hist=False, label=\"0\")\n        sns.distplot(t1[f], hist=False, label=\"1\")\n    plt.show()\n\nfeatures = ['var_%s'%i for i in range(0,25)]\nplot_dist(train_df, test_df, features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot mean distribution of all variables over all training samples\n# Per row\nplt.subplots(1,2,figsize=(16,6))\nfeatures = train_df.columns.values[102:202]\nplt.subplot(1,2,1)\nsns.distplot(train_df[features].mean(axis=1), hist=True, bins=50, kde=True, rug=True, label='Train')\nplt.subplot(1,2,2)\nsns.distplot(test_df[features].mean(axis=1), bins=50, kde=True, rug=True, label='Test')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of mean values per column in the train and test set\nplt.subplots(1,2,figsize=(16,6))\nfeatures = train_df.columns.values[102:202]\nplt.subplot(1,2,1)\nsns.distplot(train_df[features].mean(axis=0), hist=True, bins=50, kde=True, rug=True, label='Train')\nplt.legend()\n\nplt.subplot(1,2,2)\nsns.distplot(test_df[features].mean(axis=0), bins=50, kde=True, rug=True, label='Test')\nplt.legend()\n\nplt.figure(figsize=(16,6))\nsns.distplot(train_df[features].mean(axis=0), color=\"magenta\", label='Train', bins=120)\nsns.distplot(test_df[features].mean(axis=0), color=\"darkblue\", label='Test', bins=120)\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot mean distribution of all variables over all training samples\n# Per row\nplt.subplots(1,2,figsize=(16,6))\nfeatures = train_df.columns.values[102:202]\nplt.subplot(1,2,1)\nsns.distplot(train_df[features].std(axis=1), hist=True, bins=50, kde=True, rug=True, label='Train')\nplt.subplot(1,2,2)\nsns.distplot(test_df[features].std(axis=1), bins=50, kde=True, rug=True, label='Test')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train_df[features].min(axis=1), color='black', bins=120, label=\"Train\")\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(test_df[features].min(axis=1), color='red', bins=120, label=\"Test\")\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew per row in the train and test set\")\nsns.distplot(train_df[features].skew(axis=1), color='orange', kde=True, bins=120, label='Train')\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew per row in the train and test set\")\nsns.distplot(test_df[features].skew(axis=1), color='red', kde=True, bins=120, label='Train')\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corre = train_df.drop(['target', 'ID_code'], axis=1).corr().abs().unstack().sort_values(kind='quicksort').reset_index()\ntype(corre)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corre = corre[corre['level_0']!=corre['level_1']]\n# Least correlated\ncorre.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most correlated\ncorre.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.4,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.05,\n    'learning_rate': 0.01,\n    'max_depth': -1,  \n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': 1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\ntrain_df = pd.read_csv(PATH+\"train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(train_df))\n\nK = 10 # Number of splits\nskf = StratifiedKFold(n_splits=K, shuffle=False, random_state=1226)\n\ny = train_df['target']\nX = train_df.drop(['target', 'ID_code'], axis=1)\nfeatures = list(X.columns)\n\ndata_split = skf.split(X.values, y.values)\nfeature_importance_df = pd.DataFrame()\n\npredictions = np.zeros(len(test_df))\n\ntest = test_df.drop(['ID_code'], axis=1)\n\nfor k, (train, val) in enumerate(data_split):\n    print(\"Fold {}\".format(k))\n    X_train, X_val = X.loc[train], X.loc[val]\n    y_train, y_val = y.loc[train], y.loc[val]\n    \n    train_data = lgb.Dataset(X_train, y_train)\n    val_data = lgb.Dataset(X_val, y_val)\n    \n    num_round = 1000000\n    clf = lgb.train(params, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=1000, early_stopping_rounds=3000)\n    oof[val] = clf.predict(X_val.astype('float32'), num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"Importance\"] = clf.feature_importance()\n    fold_importance_df[\"Fold\"] = k+1\n    \n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test, num_iteration=clf.best_iteration)/skf.n_splits\n    lgb.save(clf, \"model.txt\")\n\nprint(\"CV Score: {%8.5f}\".format(roc_auc_score(target, oof)))\n# train_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:150].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(14,28))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged/folds)')\nplt.tight_layout()\nplt.savefig('FI.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}