{"cells":[{"metadata":{},"cell_type":"markdown","source":"I have recently checked the following tweet:\n\n<blockquote class=\"twitter-tweet\" data-lang=\"fr\"><p lang=\"en\" dir=\"ltr\">stop plotting histograms.</p>&mdash; Hugo Bowne-Anderson (@hugobowne) <a href=\"https://twitter.com/hugobowne/status/1111657955248783366?ref_src=twsrc%5Etfw\">29 mars 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n\n\nIndeed, an [ECDF](https://en.wikipedia.org/wiki/Empirical_distribution_function) \nis often easier to explore and think about. Here is a [**blog post**](https://ericmjl.github.io/blog/2018/7/14/ecdfs/) explaining some of the logic behind this claim.   \n\nLet's see how it translates to this competition's dataset!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pylab as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\nN_FEATURES = 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ecdf(s):\n    \"\"\" An ECDF computation function using pandas methods.\"\"\"\n    value_counts_s = s.value_counts()\n    return value_counts_s.sort_index().cumsum().div(len(s))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef optimal_fd_bins(s):\n    \"\"\" \n    Optimal number of bins using the FD rule of thumb: \n    https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule\n    \"\"\"\n    # Computeing the interquartile range: \n    # https://en.wikipedia.org/wiki/Interquartile_range\n    q1 = s.quantile(0.25)\n    q3 = s.quantile(0.75)\n    iqr = q3 - q1\n    width = 2 * iqr / (len(s) ** 0.33)\n    return int((s.max() - s.min()) / width)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for i in range(N_FEATURES):\n    col = 'var_' + str(i)\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    \n    # ECDF\n    ecdf(train_df.loc[lambda df: df.target == 0, col]).plot(ax=ax[0], label=\"0\")\n    ecdf(train_df.loc[lambda df: df.target == 1, col]).plot(ax=ax[0], label=\"1\")\n    ax[0].set_title(f\"ECDF for {col}\")\n    ax[0].legend()\n    \n    # Histogram\n    bins = optimal_fd_bins(train_df[col])\n    train_df.loc[lambda df: df.target == 0, col].plot(kind=\"hist\", bins=bins, ax=ax[1], \n                                                      label=\"0\")\n    train_df.loc[lambda df: df.target == 1, col].plot(kind=\"hist\", bins=bins, ax=ax[1], \n                                                      label=\"1\")\n    ax[1].set_title(f\"Freedman–Diaconis histogram for {col}\")\n    ax[1].legend()      \n    \n    plt.show()\n    fig.clf()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the above plots, it appears that:\n\n* it is indeed easier to see how much two distriubtions differ by inspecting\nthe ecdfs.  \n* median values (and othe statistics) are easier to observe. \n\nSomething to try: plot the ECDF for a normal distribution having the same mean\nand standard deviation and compare it with the ones plotted above. \n\nIf you have more suggestions, leave them in the comments section. \n\nThanks. :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}