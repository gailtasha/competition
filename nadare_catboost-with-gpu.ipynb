{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from gc import collect\n# Data manipulation and set-up\nimport numpy as np\nimport pandas as pd\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\n# Modelling (including set-up & evaluation)\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\n\n# Ignore warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 2434\nnp.random.seed(random_state)\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = train[['ID_code', 'target']]\noof['predict'] = 0\npredictions = test[['ID_code']]\nval_aucs = []\nfeature_importance = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [col for col in train.columns if col not in ['target', 'ID_code']]\nX_test = test[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nall_df = pd.concat([train.iloc[:, 2:], test.iloc[:, 1:]]) \nunique_maps = dict()\nfor col in tqdm(list(all_df)):\n    map_ = all_df[col].value_counts()\n    unique_maps[col] = map_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as st\ndelta_dics = {}\ndelta2_dics = {}\nfor col in ['var_108']:\n    kde = st.gaussian_kde(all_df[col])\n    uvar = np.unique(np.hstack([all_df[col].unique(), all_df[col].unique() + .0001, all_df[col].unique() - .0001]))\n    uvar.sort()\n    gs = []\n    for i in tqdm(range(-(-uvar.shape[0]//20))):\n        gs.extend(list(kde(uvar[20*i:20*(i+1)])))\n    dic_ = {uvar[i]: gs[i]-gs[i-1] for i in range(1, uvar.shape[0])}\n    delta_dics[col] = dic_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def FE(X):\n    unique_df = pd.DataFrame()\n    for col in unique_maps.keys():\n        unique_df[\"unique_\" + col] = X[col].map(unique_maps[col])\n    #X[\"rotated_0\"] = (scl.transform(X.values) @ R)[:, 0]\n    X[\"var_uniques\"] = (unique_df <= 2).mean(axis=1)\n    #X[\"var_duplicates\"] = (unique_df).mean(axis=1)\n    for col in unique_maps.keys():\n        X[col + \"_uniques\"] = unique_df[\"unique_\" + col]\n    from datetime import datetime\n    epoch_datetime = pd.datetime(1900, 1, 1)\n    s = (X['var_68']*10000 - 7000 + epoch_datetime.toordinal()).astype(int).map(datetime.fromordinal)\n    #X[\"dayofweek\"] = s.dt.dayofweek\n    X[\"dayofyear\"] = s.dt.dayofyear\n    for key in ['var_108']:\n        X[key + \"_delta\"] = X[key].map(delta_dics[key])\n    return  X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in tqdm(range(t)):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t//6):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor, Pool, CatBoostClassifier\n\nfeatures = [col for col in train.columns if col not in ['target', 'ID_code']]\nX_test = test[features]\nX_test = FE(X_test)\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n    X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx]['target']\n    X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx]['target']\n    \n    N = 5\n    p_valid,yp = 0,0\n    X_valid = FE(X_valid)\n    for i in range(N):\n        X_t, y_t = augment(X_train.values, y_train.values, t=12)\n        X_t = pd.DataFrame(X_t)\n        X_t = X_t.add_prefix('var_')\n        X_t = FE(X_t)\n        dev_pool = Pool(X_t,\n                        y_t)\n        val_pool = Pool(X_valid,\n                        y_valid)\n        evals_result = {}\n        model = CatBoostClassifier(eval_metric=\"AUC\",\n                                   custom_loss='Logloss',\n                                   depth=3,\n                                   subsample=.2,\n                                   l2_leaf_reg=1,\n                                   verbose=1000,\n                                   early_stopping_rounds=500,\n                                   bootstrap_type=\"Bernoulli\",\n                                   learning_rate=0.02,\n                                   task_type=\"GPU\",\n                                   random_seed=2434 + fold*5 + i,\n                                   od_type=\"Iter\",                           \n                                   iterations=60000,\n                                   )\n        model.fit(dev_pool, eval_set=val_pool)\n        p_valid += model.predict_proba(X_valid)[:, 1]\n        yp += model.predict_proba(X_test)[:, 1]\n        del X_t, dev_pool\n        collect()\n    oof['predict'][val_idx] = p_valid/N\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    \n    predictions['fold{}'.format(fold+1)] = yp/N","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('cat_all_predictions.csv', index=None)\nsub = pd.DataFrame({\"ID_code\":test[\"ID_code\"].values})\nsub[\"target\"] = predictions['target']\nsub.to_csv(\"cat_submission.csv\", index=False)\noof.to_csv('cat_oof.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resdf = pd.DataFrame([model.feature_importances_,\n              model.feature_names_]).T.sort_values(0, ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_feat = [f\"var_{i}\" for i in range(200)]\nsearch_cols = resdf[resdf[1].isin(original_feat)][1].tolist()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}