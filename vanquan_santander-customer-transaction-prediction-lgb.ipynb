{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"http://peoplesdispatch.org/wp-content/uploads/2019/01/Sartander-Bank.jpg\"></center>"},{"metadata":{},"cell_type":"markdown","source":"<h1><center>Santander Customer Transaction Prediction</center></h1>\n<br>\n\n**Mission**: Nhận diện khách hàng sẽ thực hiện giao dịch trong tương lai, bất kể số lượng tiền đã giao dịch trước đó.\n\n**Dataset**: Dataset 200,000 dòng với 200 numeric feature giấu tên, biến target binary và cột ID_code (test dataset không có target).\n\n<center><b>train_set</b></center>\n\n|          |     ID_code|target|  var_0|  var_1|...|var_199|\n|       ---|         ---|   ---|    ---|    ---|---|    ---|\n|     **0**|     train_0|     0| 8.9255|-6.7863|...|-1.0914|\n|       ...|         ...|   ...|    ...|    ...|...|    ...|\n|**199999**|train_199999|     1|5.19352| 3.2105|...|-5.2415|\n\n<br>\n\n<center><b>test_set</b></center>\n\n|          |    ID_code|  var_0|  var_1|...|var_199|\n|       ---|        ---|    ---|    ---|---|    ---|\n|     **0**|     test_0| 8.9255|-6.7863|...|-1.0914|\n|       ...|        ...|    ...|    ...|...|    ...|\n|**199999**|test_199999|5.19352| 3.2105|...|-5.2415|\n\n<br>\n**Đánh giá**: Sử dụng ROC AUC để đánh giá kết quả submission.\n## About Algorithm: LightGBM\nLightGBM là model **Gradient Boosting** do Microsoft phát triển dựa trên công thức Machine Learning dạng cây. LGB có các ưu điểm:\n* Tốc độ train model nhanh hơn và hiệu quả cao hơn\n* Giảm chi phí tài nguyên bộ nhớ.\n* Cải thiện độ chính xác.\n* Hỗ trợ GPU learning.\n* Có khả năng làm việc với data lớn.\n\n*[Nguồn](https://lightgbm.readthedocs.io/en/latest/)*\n\nLGBM rất nhạy cảm với overfitting và rất dễ overfit data nhỏ. LGBM được một số người khuyến cáo sử dụng với dữ liệu lớn hơn 10,000 dòng.\n\n## 1. EDA"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import modules\nimport logging, os, pandas as pd, numpy as np\nimport matplotlib.pyplot as plt, seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\n# Load datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore features stats\n# Tổng quan dataset\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features histogram in train dataset\n# Histogram của 100 biến đầu tiên trong train dataset\nslot = 1\nplt.figure(figsize=(30, 30))\nfor i in range(2,102):\n    plt.subplot(10, 10, slot)\n    train.iloc[:, i].hist()\n    slot += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram của 100 biến tiếp theo trong train dataset\nslot = 1\nplt.figure(figsize=(30, 30))\nfor i in range(102, 202):\n    plt.subplot(10, 10, slot)\n    train.iloc[:, i].hist()\n    slot += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target distribution\nsns.countplot(train['target'])\nprint(train.target.value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of target within each feature\n# Phân bố target theo từng biến\ndef plot_feat_dist(df1, df2, label1, label2, feat):\n    i = 0\n    sns.set_style('whitegrid')\n    fig, ax = plt.subplots(10, 10, figsize=(30, 30))\n    \n    for feat in feat:\n        i += 1\n        plt.subplot(10, 10, i)\n        sns.distplot(df1[feat], hist=False, label=label1)\n        sns.distplot(df2[feat], hist=False, label=label2)\n        plt.xlabel(feat)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First 100 features\n# Phân bố target trong 100 biến đầu\ntrain0 = train.loc[train.target == 0]\ntrain1 = train.loc[train.target == 1]\nfeat = train.columns.values[2:102]\n\nplot_feat_dist(train0, train1, '0', '1', feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next 100 features\n# Phân bố target trong 100 biến sau\nfeat = train.columns.values[102:202]\nplot_feat_dist(train0, train1, '0', '1', feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of statistical value per row/column by train and test dataset.\n# Đồ thị phân bố giá trị của hàng/cột trong train và test dataset.\ndef train_test_dist(agg):\n    features = train.columns.values[2:202]\n    plt.figure(figsize=(30,8))\n    sns.set_style('whitegrid')\n    \n    plt.subplot(1,2,1)\n    sns.distplot(train[features].apply(func=agg, axis=1), kde=True, color='g', bins=120, label='train')\n    sns.distplot(test[features].apply(func=agg, axis=1), kde=True, color='b', bins=120, label='test')\n    plt.legend()\n    plt.title('Distribution of {} values per row in the train and test set'.format(agg))\n\n    plt.subplot(1,2,2)\n    sns.distplot(train[features].apply(func=agg, axis=0), kde=True, color='g', bins=120, label='train')\n    sns.distplot(test[features].apply(func=agg, axis=0), kde=True, color='b', bins=120, label='test')\n    plt.legend()\n    plt.title('Distribution of {} values per column in the train and test set'.format(agg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_dist('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_dist('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_dist('min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_dist('max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_dist('skew')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_dist('kurtosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of statistical value per row/column in the train dataset, grouped by value of target.\n# Đồ thị phân bố giá trị của hàng/cột nhóm theo target trong train dataset.\ndef train_dist(agg):\n    t0 = train.loc[train['target'] == 0]\n    t1 = train.loc[train['target'] == 1]\n    features = train.columns.values[2:202]\n    plt.figure(figsize=(30,12))\n    sns.set_style('whitegrid')\n    \n    plt.subplot(1,2,1)\n    sns.distplot(t0[features].apply(func=agg, axis=1), kde=True,bins=120, color='r',label='target = 0')\n    sns.distplot(t1[features].apply(func=agg, axis=1), kde=True,bins=120, color='darkblue', label='target = 1')\n    plt.legend()\n    plt.title('Distribution of {} values per row in the train set'.format(agg))\n    \n    plt.subplot(1,2,2)\n    sns.distplot(t0[features].apply(func=agg, axis=0), kde=True,bins=120, color='r', label='target = 0')\n    sns.distplot(t1[features].apply(func=agg, axis=0), kde=True,bins=120, color='darkblue', label='target = 1')\n    plt.title('Distribution of {} values per column in the train set'.format(agg))\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dist('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dist('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dist('min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dist('max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dist('skew')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dist('kurtosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features correlation -- Tương quan các biến\nfeatures = [c for c in train.columns.values if c not in ['ID_code', 'target']]\ncorr = train[features].corr().abs().unstack().sort_values().reset_index()\ncorr = corr[corr.level_0 != corr.level_1]\ncorr.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Duplicated value -- Kiểm tra xem trong các biến có xuất hiện nhiều giá trị trùng nhau không\ndef dupl_max_df(df):\n    dupl_max = []\n    \n    for feature in features:\n        values = df[feature].value_counts()\n        dupl_max.append([feature, values.max(), values.idxmax()])\n\n    dupl_max = pd.DataFrame(dupl_max, columns=['feature', '# dupl', 'value dupl']).sort_values(by='# dupl', ascending=False).T\n    return dupl_max","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dupl_max_df(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dupl_max_df(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Feature Engineering\n# Tạo thêm biến\nfor df in [train, test]:\n    df['sum'] = df[features].sum(axis=1)  \n    df['min'] = df[features].min(axis=1)\n    df['max'] = df[features].max(axis=1)\n    df['mean'] = df[features].mean(axis=1)\n    df['std'] = df[features].std(axis=1)\n    df['skew'] = df[features].skew(axis=1)\n    df['kurt'] = df[features].kurtosis(axis=1)\n    df['med'] = df[features].median(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape[1], test.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Modeling\nNhư đã nói đầu tiên, project này sẽ sử dụng sử dụng model LightGBM để dự đoán.\n\nTrước hết, cần xác định các thông số cần thiết cho model, được gói trong biến `params`."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in train.columns.values if c not in ['ID_code', 'target']]\ntarget = train['target']\n\nparams = {\n    'bagging_freq': 2,\n    'bagging_fraction': 0.8,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.1403,\n    'learning_rate': 0.07,\n    'max_depth': 7,  \n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 19,\n    'num_leaves': 14,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': -1,\n    'lambda_l1': 1.7916,\n    'lambda_l2': 4.7454,\n    'min_gain_to_split': 0.0319\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Quick training -- Train nhanh model trên train dataset với 100 iterations\nval_size = 0.3\nX_train, X_val, y_train, y_val = train_test_split(train[features], train['target'], test_size = val_size, random_state=42) # Chia file train dataset\n\niterations = 100\nval_pred = np.zeros([int(len(train)*val_size), len(features)])\ntest_pred = np.zeros([200000, len(features)])\n\ni = 0\nfor feature in features: # loop over all features -- Train model với từng biến để tăng tốc độ train mà vẫn đảm bảo hiệu quả\n    print(feature)\n    feat = [feature]\n    train_data = lgb.Dataset(X_train[feat], y_train)\n    gbm = lgb.train(params, train_data, iterations, verbose_eval=-1)\n    val_pred[:, i] = gbm.predict(X_val[feat], num_iteration=gbm.best_iteration)\n    test_pred[:, i] = gbm.predict(test[feat], num_iteration=gbm.best_iteration)\n    i += 1\n\nscore = roc_auc_score(y_val, (val_pred).sum(axis=1))\nprint('CV score: ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Final training and predicting -- Training lần cuối dự đoán target cho test dataset\nfolds = StratifiedKFold(n_splits=10, shuffle=False, random_state=42)\n\noof = np.zeros(len(train))\npred = np.zeros(len(test))\nfeature_important_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['target'])):\n    print('Fold: {}'.format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n    \n    num_round = 100000\n    clf = lgb.train(params, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=1000, early_stopping_rounds=3000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_important_df = pd.DataFrame()\n    fold_important_df['feature'] = features\n    fold_important_df['importance'] = clf.feature_importance()\n    fold_important_df['fold'] = fold_ + 1\n    feature_important_df = pd.concat([feature_important_df, fold_important_df], axis=0)\n    \n    pred = clf.predict(test[features], num_iteration=clf.best_iteration)/folds.n_splits # Kết quả dự đoán target test dataset\n    \nprint('CV score: {:.5f}'.format(roc_auc_score(target, oof)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = pred\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submision.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}