{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Santander Customer Transaction Prediction"},{"metadata":{},"cell_type":"markdown","source":"This kernel is a work in progress, taking inspiration from:<br>\n<b>LightGBM with GPU support:</b> https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm<br>\n<b>Data Augmentation:</b> https://www.kaggle.com/jiweiliu/fast-inplace-shuffle-for-augmentation"},{"metadata":{},"cell_type":"markdown","source":"## Re-compile LGBM with GPU support"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm<br>\n!git clone --recursive https://github.com/Microsoft/LightGBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get install -y -qq libboost-all-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd LightGBM/python-package/;python3 setup.py install --precompile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Onto the challenge"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data manipulation and set-up\nimport numpy as np\nimport pandas as pd\n\n# Statistics\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom statistics import mode\nfrom scipy.special import boxcox1p\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\n# Modelling (including set-up & evaluation)\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\n\n# Ignore warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting random seed\nrandom_state = 42\nnp.random.seed(random_state)\n\n# Import data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature engineering\n# Saving train & test shapes\n# ntrain = train.shape[0]\n# ntest = test.shape[0]\n\n# New all encompassing dataset\n# all_data = pd.concat((train, test)).reset_index(drop=True)\n\n# Transform target to object\n# all_data['target'] = all_data['target'].astype('object')\n\n# Extracting continuous features\n# numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check for skewness\n# skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n# skewness = pd.DataFrame({'Skew' :skewed_feats})\n# skewness.head(5)","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"             Skew\nvar_168  0.268064\nvar_2    0.261596\nvar_179  0.245240\nvar_163  0.238993\nvar_0    0.230558\nvar_191  0.206873\nvar_181  0.206860\nvar_29   0.199634\nvar_60   0.192672\nvar_16   0.189631\nvar_62   0.184090\nvar_25   0.176084\nvar_26   0.167691\nvar_125  0.157443\nvar_22   0.156535\nvar_6    0.153715\nvar_157  0.152165\nvar_24   0.143808\nvar_184  0.143112\nvar_89   0.142886\nvar_41   0.141402\nvar_95   0.141397\nvar_175  0.138077\nvar_110  0.130488\nvar_133  0.126483\nvar_99   0.126307\nvar_55   0.125143\nvar_177  0.123240\nvar_105  0.122847\nvar_195  0.121628\nvar_160  0.113824\nvar_38   0.108804\nvar_69   0.103827\nvar_137  0.103517\nvar_186  0.101178\nvar_170  0.100946\nvar_121  0.097740\nvar_77   0.093537\nvar_107  0.089984\nvar_156  0.087848\nvar_192  0.087447\nvar_18   0.086841\nvar_120  0.086405\nvar_33   0.086377\nvar_7    0.085234\nvar_119  0.085013\nvar_79   0.084889\nvar_46   0.084428\nvar_155  0.083815\nvar_151  0.083180","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>var_168</th>\n      <td>0.268064</td>\n    </tr>\n    <tr>\n      <th>var_2</th>\n      <td>0.261596</td>\n    </tr>\n    <tr>\n      <th>var_179</th>\n      <td>0.245240</td>\n    </tr>\n    <tr>\n      <th>var_163</th>\n      <td>0.238993</td>\n    </tr>\n    <tr>\n      <th>var_0</th>\n      <td>0.230558</td>\n    </tr>\n    <tr>\n      <th>var_191</th>\n      <td>0.206873</td>\n    </tr>\n    <tr>\n      <th>var_181</th>\n      <td>0.206860</td>\n    </tr>\n    <tr>\n      <th>var_29</th>\n      <td>0.199634</td>\n    </tr>\n    <tr>\n      <th>var_60</th>\n      <td>0.192672</td>\n    </tr>\n    <tr>\n      <th>var_16</th>\n      <td>0.189631</td>\n    </tr>\n    <tr>\n      <th>var_62</th>\n      <td>0.184090</td>\n    </tr>\n    <tr>\n      <th>var_25</th>\n      <td>0.176084</td>\n    </tr>\n    <tr>\n      <th>var_26</th>\n      <td>0.167691</td>\n    </tr>\n    <tr>\n      <th>var_125</th>\n      <td>0.157443</td>\n    </tr>\n    <tr>\n      <th>var_22</th>\n      <td>0.156535</td>\n    </tr>\n    <tr>\n      <th>var_6</th>\n      <td>0.153715</td>\n    </tr>\n    <tr>\n      <th>var_157</th>\n      <td>0.152165</td>\n    </tr>\n    <tr>\n      <th>var_24</th>\n      <td>0.143808</td>\n    </tr>\n    <tr>\n      <th>var_184</th>\n      <td>0.143112</td>\n    </tr>\n    <tr>\n      <th>var_89</th>\n      <td>0.142886</td>\n    </tr>\n    <tr>\n      <th>var_41</th>\n      <td>0.141402</td>\n    </tr>\n    <tr>\n      <th>var_95</th>\n      <td>0.141397</td>\n    </tr>\n    <tr>\n      <th>var_175</th>\n      <td>0.138077</td>\n    </tr>\n    <tr>\n      <th>var_110</th>\n      <td>0.130488</td>\n    </tr>\n    <tr>\n      <th>var_133</th>\n      <td>0.126483</td>\n    </tr>\n    <tr>\n      <th>var_99</th>\n      <td>0.126307</td>\n    </tr>\n    <tr>\n      <th>var_55</th>\n      <td>0.125143</td>\n    </tr>\n    <tr>\n      <th>var_177</th>\n      <td>0.123240</td>\n    </tr>\n    <tr>\n      <th>var_105</th>\n      <td>0.122847</td>\n    </tr>\n    <tr>\n      <th>var_195</th>\n      <td>0.121628</td>\n    </tr>\n    <tr>\n      <th>var_160</th>\n      <td>0.113824</td>\n    </tr>\n    <tr>\n      <th>var_38</th>\n      <td>0.108804</td>\n    </tr>\n    <tr>\n      <th>var_69</th>\n      <td>0.103827</td>\n    </tr>\n    <tr>\n      <th>var_137</th>\n      <td>0.103517</td>\n    </tr>\n    <tr>\n      <th>var_186</th>\n      <td>0.101178</td>\n    </tr>\n    <tr>\n      <th>var_170</th>\n      <td>0.100946</td>\n    </tr>\n    <tr>\n      <th>var_121</th>\n      <td>0.097740</td>\n    </tr>\n    <tr>\n      <th>var_77</th>\n      <td>0.093537</td>\n    </tr>\n    <tr>\n      <th>var_107</th>\n      <td>0.089984</td>\n    </tr>\n    <tr>\n      <th>var_156</th>\n      <td>0.087848</td>\n    </tr>\n    <tr>\n      <th>var_192</th>\n      <td>0.087447</td>\n    </tr>\n    <tr>\n      <th>var_18</th>\n      <td>0.086841</td>\n    </tr>\n    <tr>\n      <th>var_120</th>\n      <td>0.086405</td>\n    </tr>\n    <tr>\n      <th>var_33</th>\n      <td>0.086377</td>\n    </tr>\n    <tr>\n      <th>var_7</th>\n      <td>0.085234</td>\n    </tr>\n    <tr>\n      <th>var_119</th>\n      <td>0.085013</td>\n    </tr>\n    <tr>\n      <th>var_79</th>\n      <td>0.084889</td>\n    </tr>\n    <tr>\n      <th>var_46</th>\n      <td>0.084428</td>\n    </tr>\n    <tr>\n      <th>var_155</th>\n      <td>0.083815</td>\n    </tr>\n    <tr>\n      <th>var_151</th>\n      <td>0.083180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's apply the box-cox transformation to correct for skewness\n# skewed_features = skewness.index\n# lam = 0.3\n# for feature in skewed_features:\n#     all_data[feature] = boxcox1p(all_data[feature], lam)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check\n# numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n# skewness = pd.DataFrame({'Skew' :skewed_feats})\n# skewness.head(5)","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"             Skew\nvar_25   0.142535\nvar_125  0.119913\nvar_91   0.045102\nvar_133  0.039579\nvar_15  -0.000447\nvar_156 -0.004911\nvar_181 -0.010593\nvar_126 -0.027922\nvar_161 -0.030870\nvar_79  -0.033287\nvar_103 -0.049659\nvar_130 -0.053067\nvar_43  -0.059511\nvar_6   -0.075372\nvar_59  -0.088952\nvar_34  -0.092581\nvar_121 -0.098181\nvar_57  -0.105549\nvar_53  -0.106785\nvar_169 -0.109875\nvar_150 -0.114855\nvar_153 -0.117679\nvar_2   -0.127167\nvar_144 -0.140765\nvar_177 -0.141625\nvar_148 -0.142676\nvar_23  -0.143855\nvar_50  -0.145888\nvar_77  -0.149513\nvar_68  -0.152825\nvar_12  -0.163664\nvar_197 -0.189235\nvar_105 -0.193850\nvar_7   -0.195089\nvar_61  -0.202231\nvar_111 -0.208820\nvar_175 -0.210809\nvar_166 -0.212993\nvar_66  -0.216563\nvar_42  -0.227371\nvar_108 -0.227886\nvar_71  -0.230315\nvar_104 -0.232570\nvar_157 -0.233556\nvar_26  -0.236119\nvar_194 -0.244734\nvar_28  -0.244851\nvar_85  -0.245298\nvar_94  -0.256473\nvar_4   -0.257103","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>var_25</th>\n      <td>0.142535</td>\n    </tr>\n    <tr>\n      <th>var_125</th>\n      <td>0.119913</td>\n    </tr>\n    <tr>\n      <th>var_91</th>\n      <td>0.045102</td>\n    </tr>\n    <tr>\n      <th>var_133</th>\n      <td>0.039579</td>\n    </tr>\n    <tr>\n      <th>var_15</th>\n      <td>-0.000447</td>\n    </tr>\n    <tr>\n      <th>var_156</th>\n      <td>-0.004911</td>\n    </tr>\n    <tr>\n      <th>var_181</th>\n      <td>-0.010593</td>\n    </tr>\n    <tr>\n      <th>var_126</th>\n      <td>-0.027922</td>\n    </tr>\n    <tr>\n      <th>var_161</th>\n      <td>-0.030870</td>\n    </tr>\n    <tr>\n      <th>var_79</th>\n      <td>-0.033287</td>\n    </tr>\n    <tr>\n      <th>var_103</th>\n      <td>-0.049659</td>\n    </tr>\n    <tr>\n      <th>var_130</th>\n      <td>-0.053067</td>\n    </tr>\n    <tr>\n      <th>var_43</th>\n      <td>-0.059511</td>\n    </tr>\n    <tr>\n      <th>var_6</th>\n      <td>-0.075372</td>\n    </tr>\n    <tr>\n      <th>var_59</th>\n      <td>-0.088952</td>\n    </tr>\n    <tr>\n      <th>var_34</th>\n      <td>-0.092581</td>\n    </tr>\n    <tr>\n      <th>var_121</th>\n      <td>-0.098181</td>\n    </tr>\n    <tr>\n      <th>var_57</th>\n      <td>-0.105549</td>\n    </tr>\n    <tr>\n      <th>var_53</th>\n      <td>-0.106785</td>\n    </tr>\n    <tr>\n      <th>var_169</th>\n      <td>-0.109875</td>\n    </tr>\n    <tr>\n      <th>var_150</th>\n      <td>-0.114855</td>\n    </tr>\n    <tr>\n      <th>var_153</th>\n      <td>-0.117679</td>\n    </tr>\n    <tr>\n      <th>var_2</th>\n      <td>-0.127167</td>\n    </tr>\n    <tr>\n      <th>var_144</th>\n      <td>-0.140765</td>\n    </tr>\n    <tr>\n      <th>var_177</th>\n      <td>-0.141625</td>\n    </tr>\n    <tr>\n      <th>var_148</th>\n      <td>-0.142676</td>\n    </tr>\n    <tr>\n      <th>var_23</th>\n      <td>-0.143855</td>\n    </tr>\n    <tr>\n      <th>var_50</th>\n      <td>-0.145888</td>\n    </tr>\n    <tr>\n      <th>var_77</th>\n      <td>-0.149513</td>\n    </tr>\n    <tr>\n      <th>var_68</th>\n      <td>-0.152825</td>\n    </tr>\n    <tr>\n      <th>var_12</th>\n      <td>-0.163664</td>\n    </tr>\n    <tr>\n      <th>var_197</th>\n      <td>-0.189235</td>\n    </tr>\n    <tr>\n      <th>var_105</th>\n      <td>-0.193850</td>\n    </tr>\n    <tr>\n      <th>var_7</th>\n      <td>-0.195089</td>\n    </tr>\n    <tr>\n      <th>var_61</th>\n      <td>-0.202231</td>\n    </tr>\n    <tr>\n      <th>var_111</th>\n      <td>-0.208820</td>\n    </tr>\n    <tr>\n      <th>var_175</th>\n      <td>-0.210809</td>\n    </tr>\n    <tr>\n      <th>var_166</th>\n      <td>-0.212993</td>\n    </tr>\n    <tr>\n      <th>var_66</th>\n      <td>-0.216563</td>\n    </tr>\n    <tr>\n      <th>var_42</th>\n      <td>-0.227371</td>\n    </tr>\n    <tr>\n      <th>var_108</th>\n      <td>-0.227886</td>\n    </tr>\n    <tr>\n      <th>var_71</th>\n      <td>-0.230315</td>\n    </tr>\n    <tr>\n      <th>var_104</th>\n      <td>-0.232570</td>\n    </tr>\n    <tr>\n      <th>var_157</th>\n      <td>-0.233556</td>\n    </tr>\n    <tr>\n      <th>var_26</th>\n      <td>-0.236119</td>\n    </tr>\n    <tr>\n      <th>var_194</th>\n      <td>-0.244734</td>\n    </tr>\n    <tr>\n      <th>var_28</th>\n      <td>-0.244851</td>\n    </tr>\n    <tr>\n      <th>var_85</th>\n      <td>-0.245298</td>\n    </tr>\n    <tr>\n      <th>var_94</th>\n      <td>-0.256473</td>\n    </tr>\n    <tr>\n      <th>var_4</th>\n      <td>-0.257103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target back to float\n# all_data['target'] = all_data['target'].astype('float64')\n\n# Now to return to separate train/test sets for Machine Learning\n# train = all_data[:ntrain]\n# test = all_data[ntrain:]","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation\ndef disarrange(a, axis=-1):\n    \"\"\"\n    Shuffle `a` in-place along the given axis.\n\n    Apply numpy.random.shuffle to the given axis of `a`.\n    Each one-dimensional slice is shuffled independently.\n    \"\"\"\n    b = a.swapaxes(axis, -1)\n    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n    # so `a` is shuffled in place, too.\n    shp = b.shape[:-1]\n    for ndx in np.ndindex(shp):\n        np.random.shuffle(b[ndx])\n    return\n\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        disarrange(x1,axis=0)\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        disarrange(x1,axis=0)\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model parameters\nlgb_params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"boosting\": 'gbdt',\n    \"max_depth\" : -1,\n    \"num_leaves\" : 13,\n    \"learning_rate\" : 0.01,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\" : 0.4,\n    \"feature_fraction\" : 0.05,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10,\n    \"tree_learner\": \"serial\",\n    \"boost_from_average\": \"false\",\n    \"bagging_seed\" : random_state,\n    \"verbosity\" : 1,\n    \"seed\": random_state,\n    'device': 'gpu',\n    'gpu_platform_id': 0,\n    'gpu_device_id': 0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = train[['ID_code', 'target']]\noof['predict'] = 0\npredictions = test[['ID_code']]\nval_aucs = []\nfeature_importance = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [col for col in train.columns if col not in ['target', 'ID_code']]\nX_test = test[features].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold, (trn_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n    X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx]['target']\n    X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx]['target']\n    \n    N = 5\n    p_valid,yp = 0,0\n    for i in range(N):\n        X_t, y_t = augment(X_train.values, y_train.values)\n        X_t = pd.DataFrame(X_t)\n        X_t = X_t.add_prefix('var_')\n    \n        trn_data = lgb.Dataset(X_t, label=y_t)\n        val_data = lgb.Dataset(X_valid, label=y_valid)\n        evals_result = {}\n        lgb_clf = lgb.train(lgb_params,\n                        trn_data,\n                        100000,\n                        valid_sets = [trn_data, val_data],\n                        early_stopping_rounds=3000,\n                        verbose_eval = 1000,\n                        evals_result=evals_result\n                       )\n        p_valid += lgb_clf.predict(X_valid)\n        yp += lgb_clf.predict(X_test)\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = features\n    fold_importance[\"importance\"] = lgb_clf.feature_importance()\n    fold_importance[\"fold\"] = fold + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n    oof['predict'][val_idx] = p_valid/N\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    \n    predictions['fold{}'.format(fold+1)] = yp/N","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('lgb_all_predictions.csv', index=None)\nsub = pd.DataFrame({\"ID_code\":test[\"ID_code\"].values})\nsub[\"target\"] = predictions['target']\nsub.to_csv(\"lgb_submission.csv\", index=False)\noof.to_csv('lgb_oof.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}