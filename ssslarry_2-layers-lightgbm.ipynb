{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\nimport math\nimport lightgbm as lgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom copy import copy\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, RepeatedKFold,StratifiedKFold\nfrom pandas.api.types import is_numeric_dtype\nfrom pandas.api.types import is_string_dtype\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\ndef get_bps_from_tree(tree_obj):\n    # Find valid node index\n    idx = np.arange(0, tree_obj.tree_.feature.shape[0])\n    idx = list(filter(lambda x: tree_obj.tree_.feature[x] == 0, idx))\n    # Find corresponding threshold for the split\n    bps = sorted(tree_obj.tree_.threshold[idx])\n    return bps\n\ndef discretize_feature2(df, var_col, label_col,nn,\n                       max_depth=10,\n                       max_leaf_nodes=5,\n                       min_samples_leaf=0.05):\n    tree = DecisionTreeClassifier(max_depth=max_depth,\n                                  max_leaf_nodes=nn,\n                                  min_samples_leaf=min_samples_leaf)\n    tree = tree.fit(df[[var_col]].as_matrix(), df[label_col].values)\n    bps = get_bps_from_tree(tree)\n    return bps\n\ndef baddist(df,y,var,nn=2,bins=None):\n    if bins is None:\n        df['Bin']=df[var]\n    else:\n        df['Bin']=pd.cut(df[var],bins).astype('str')\n    if is_string_dtype(df[var]):\n        df.loc[df['Bin'].isnull(),'Bin']=\"null\"\n    if len(df[var].unique())>nn and is_numeric_dtype(df[var]) :\n        if bins is None:\n            bb=discretize_feature2(df=df, var_col=var, label_col=y,nn=nn)\n            bb=[math.floor(f*10000)/10000 for f in bb]\n            bins=[float('-inf')]+bb+[float('Inf')]\n        df['Bin']=pd.cut(df[var],bins,duplicates='drop').astype('str')\n    tab=pd.crosstab(df['Bin'],df[y])\n    tab=tab.reset_index()\n    try:\n        tab=tab.sort_values(by=['Bin'])\n        tab['min']=tab['Bin'].apply(lambda x: x.split(',')[0]).apply(lambda x: x[1:]).astype('float')\n        tab['max']=tab['Bin'].apply(lambda x: x.split(',')[1]).apply(lambda x: x[:-1]).astype('float')\n        tab=tab.sort_values('max')\n        del tab['min'],tab['max']\n    except: \n        tab=tab\n    del df['Bin']\n    tab['0%']=round(tab[0]/tab[0].sum(),4)*100\n    tab['1%']=round(tab[1]/tab[1].sum(),4)*100\n    tab['All']=tab[0]+tab[1]\n    tab['All%']=round(tab['All']/tab['All'].sum(),4)*100\n    tab['Bad Rate%']=round(tab[1]/tab['All'],4)*100\n    tab['IV']=np.log(tab['1%']/tab['0%'])*(tab['1%']-tab['0%'])\n    \n    print(var+' IV after binningï¼š',round(tab['IV'].sum(),4),\"%\")\n    ivdict={\"Var\":[var],\"IV\":[round(tab['IV'].sum(),6)]}\n    ivdf=pd.DataFrame.from_dict(ivdict)\n    return tab,df,ivdf\n\ndef lgbmodelling(features,train_df,test_df,param=None):\n    print(len(features))\n    if param is None:\n        param ={'bagging_fraction': 0.5,\n                 'bagging_freq': 1,\n                 'bagging_seed': 1993,\n                 'feature_fraction': 0.05,\n                 'learning_rate': 0.025,\n                 'metric': 'auc',\n                 'min_data_in_leaf': 50,\n                 'num_leaves': 3,\n                 'objective': 'binary'}\n    \n    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1993)\n    target = train_df['target']\n    print(len(target))\n    oof = np.zeros(len(train_df))\n    predictions = np.zeros(len(test_df))\n    \n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n        print(\"Fold {}\".format(fold_+1))\n        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n        val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n\n        clf = lgb.train(param, trn_data, num_boost_round=500000, valid_sets = [trn_data, val_data], verbose_eval=5000, \n                        early_stopping_rounds = 3000)\n        oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)    \n        predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n    print(\"CV score: {:<8.6f}\".format(roc_auc_score(target, oof)))\n    return oof,predictions\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60134195496538cf23750bd4ca91bbba1ed8c9fb"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c02152e02e5556406a7b5205b15deab72f1cef9"},"cell_type":"code","source":"features = ['var_'+str(c) for c in range(0,200)]\nivdf=pd.DataFrame()\nfor f in features:\n    _,_,iv=baddist(df=train_df, y='target',var=f,nn=10)\n    ivdf=pd.concat([ivdf,iv])\nivdf=ivdf.sort_values('IV',ascending=False)\nivdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57030615ad94ddad51c014d6914f2b817696fe13"},"cell_type":"code","source":"plt.figure(figsize=(14,28))\nsns.barplot(x=\"IV\", y=\"Var\", data=ivdf)\nplt.title('IV Ranking (of 10 bins)')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7753afecff19fb00384cda674423b8291bde4c9c"},"cell_type":"code","source":"features = list(ivdf.loc[ivdf['IV']>3,:]['Var'])\nprint(features)\ntrain_df['pred_lgb_ivgt3'],test_df['pred_lgb_ivgt3']=lgbmodelling(features,train_df,test_df)\n\n\nfeatures = list(ivdf.loc[ivdf['IV']<=3,:]['Var'])\nprint(features)\ntrain_df['pred_lgb_ivle3'],test_df['pred_lgb_ivle3']=lgbmodelling(features,train_df,test_df)\n\n\ntarget = train_df['target']\nfeatures=['pred_lgb_ivgt3','pred_lgb_ivle3']\nprint(features)\n\ntrain_df['pred_lgb_iv3'],test_df['pred_lgb_iv3']=lgbmodelling(features,train_df,test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6015b82f45adefd9873a224a2930edee0174a539"},"cell_type":"code","source":"sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df[\"target\"] = test_df['pred_lgb_iv3']\nsub_df.to_csv(\"lgbm pred_lgb_iv3.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}