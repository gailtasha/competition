{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"../input/santander-customer-transaction-prediction/sample_submission.csv\")\ntest = pd.read_csv(\"../input/santander-customer-transaction-prediction/test.csv\")\ntrain = pd.read_csv(\"../input/santander-customer-transaction-prediction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    df_train = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv',index_col='ID_code')\n    df_test = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv', index_col='ID_code')\n\n    \n    return df_train,df_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train,df_test = load_data()\nprint(f'Train dataset has {df_train.shape[0]} rows and {df_train.shape[1]} columns.')\nprint(f'Test dataset has {df_test.shape[0]} rows and {df_test.shape[1]} columns.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df_train['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encoding selected categorical columns, while leaving other columns as it is\nfrom sklearn import preprocessing\n\ndef label_encoding(sel_cat,inpX):\n    for col in sel_cat:\n        if col in inpX.columns:\n            le = preprocessing.LabelEncoder()\n            le.fit(list(inpX[col].astype(str).values))\n            inpX[col] = le.transform(list(inpX[col].astype(str).values))\n    return inpX\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Returns list of categorical columns, and part of dataset with only categorical columns\ndef categorical_cols(input_df):\n    # Selecting numeric columns in df_train\n    print(input_df.select_dtypes('object').columns)\n    sel_train = input_df.select_dtypes('object').columns.values\n    #print(type(sel_train))\n\n    train = input_df[sel_train]\n    #print(train.describe())\n    return sel_train, train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#features = sel_features+num_id+sel_cards\n#train = df_train[features]\ndef balanced_sampling(input_df): \n    \n    train = numeric_cols(input_df)\n    y= train['target']\n    # Selecting target 1 and target 0  \n    X_target = train[train.target==1]\n    X_notarget= train[train.target==0]\n    total_target = X_target.shape\n    print(\"Target Size : \",total_target[1],total_target[0])\n    scale_factor = 2\n    X_notarget1=X_notarget.sample(scale_factor*total_target[0])\n    X=pd.concat([X_target,X_notarget1], ignore_index=True)\n    y= X['target']\n    print(X.shape)\n    print(X.sample(10))\n\n    #dropping target column from X\n    X.drop([\"target\"],axis=1,inplace=True)\n    \n    ### Train-test split with Stratification\n    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,  test_size=0.25)\n    return X_train, X_test, y_train, y_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def numeric_cols(input_df):\n    # Selecting numeric columns in df_train\n    print(input_df.select_dtypes('number').columns)\n    sel_train = input_df.select_dtypes('number').columns.values\n    print(type(sel_train))\n\n    train = input_df[sel_train]\n    print(train.describe())\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(inp):\n# Filling 0.0 in place of NaN\n    inp.fillna(0.0, inplace=True)\n    inp.sample(10)\n    return inp ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndef scaling(unscaled_data):\n    #unscaled_data.reset_index()\n    ss = StandardScaler()\n    #preprocessing to remove NaN's\n    processed_data=preprocess(unscaled_data)\n    #scaling\n    scaled_data = ss.fit_transform(processed_data)\n    #print('Unscaled Data:\\n',X)\n    #print(\"Scaled Data :\\n\",scaled_data)\n    return scaled_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\ndef randomforest(inpX,inpy):\n    #Create a Gaussian Classifier\n    clf=RandomForestClassifier(n_estimators=500)\n\n    #Train the model using the training sets y_pred=clf.predict(X_test)\n    clf.fit(inpX,inpy)\n    return clf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\ndef randomforest2(inpX,inpy):\n    sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n    sel.fit(inpX, inpy)\n    sel.get_support()\n    selected_feat= inpX.columns[(sel.get_support())]\n    len(selected_feat)\n    return sel, selected_feat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experiment 1 | Random Forest with Balanced Sampling and All Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1 : Load Data\ndf_train,df_test = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select Categorical Columns\nsel_cat,X = categorical_cols(df_train)\ndf_train[sel_cat].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pre-process train and test datasets to remove NaNs\nprocessed_trainX =  preprocess(df_train)\nprocessed_testX = preprocess(df_test)\nprocessed_trainX.sample(100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_testX.sample(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Balanced sampling with train-test split\nX_train, X_test, y_train, y_test = balanced_sampling(processed_trainX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 6 : Traing part of classification\nclf = randomforest(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction\ny_pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ndef eval2(y_test,y_pred):\n    # Model Accuracy, how often is the classifier correct?\n    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval2(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \ndef performance_analysis(y_test,y_pred):\n    results = confusion_matrix(y_test, y_pred) \n    print('Confusion Matrix :')\n    print(results) \n    print('Accuracy Score :',accuracy_score(y_test, y_pred))\n    print ('Report : ')\n    print (classification_report(y_test, y_pred))\n    return\n\nperformance_analysis(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub3(inpt,clf):\n    # Use df_test with selected columns for final submission\n    y_preds = clf.predict_proba(inpt)[:,1] \n    sample_submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv', index_col='ID_code')\n    sample_submission['target'] = y_preds\n    sample_submission.to_csv('santander2.csv')\n    return 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_testX.sample(100)\nsub3(processed_testX,clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Experment 2 | Random Forest with Feature Selection and Balanced Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1 : Load Data\ndf_train,df_test = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select Categorical Columns\nsel_cat,X = categorical_cols(df_train)\ndf_train[sel_cat].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pre-process train and test datasets to remove NaNs\nprocessed_trainX =  preprocess(df_train)\nprocessed_testX = preprocess(df_test)\nprocessed_trainX.sample(100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_testX.sample(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Balanced sampling with train-test split\nX_train, X_test, y_train, y_test = balanced_sampling(processed_trainX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"sfm, sel_feat = randomforest2(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Selected Features : \\n\",sel_feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of features : \", len(sel_feat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a random forest classifier\nclf2 = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n\n# Train the classifier\nclf2.fit(X_train, y_train)\n\n# Print the name and gini importance of each feature\nfor feature in zip(sel_feat, clf2.feature_importances_):\n    print(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the data to create a new dataset containing only the most important features\n# Note: We have to apply the transform to both the training X and test X data.\nX_important_train = sfm.transform(X_train)\nX_important_test = sfm.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_important_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_important_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf3 = randomforest(X_important_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction\ny_pred=clf3.predict(X_important_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ndef eval2(y_test,y_pred):\n    # Model Accuracy, how often is the classifier correct?\n    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n    return ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval2(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \ndef performance_analysis(y_test,y_pred):\n    results = confusion_matrix(y_test, y_pred) \n    print('Confusion Matrix :')\n    print(results) \n    print('Accuracy Score :',accuracy_score(y_test, y_pred))\n    print ('Report : ')\n    print (classification_report(y_test, y_pred))\n    return\n\nperformance_analysis(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sub3(inpt,clf):\n    # Use df_test with selected columns for final submission\n    y_preds = clf.predict_proba(inpt)[:,1] \n    sample_submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv', index_col='ID_code')\n    sample_submission['target'] = y_preds\n    sample_submission.to_csv('santander2_1.csv')\n    return 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_testX.sample(100)\nX_important_df_test = sfm.transform(df_test)\nsub3(X_important_df_test,clf3)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}