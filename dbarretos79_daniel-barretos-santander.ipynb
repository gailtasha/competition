{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Competição Kaggle: Santander\n( Notebook in Portuguese-BR) \n\nLink no Kaggle: https://www.kaggle.com/c/santander-customer-transaction-prediction\n\n\nProblema de classificação binária:\n- Identificar quais clientes farão uma transação específica no futuro, independentemente da quantidade de dinheiro transacionada. Os dados fornecidos pelo Santander para esta competição têm a mesma estrutura que os dados reais que são disponíveis para resolver este problema na empresa.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Importando as bibliotecas"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # algebra linear\nimport pandas as pd # data frames, leitura CSV... \nimport seaborn as sns # visualização, bibilioteca baseada na matplotlib\nimport statsmodels.api as sm  # estatística\nimport statsmodels.formula.api as smf # estatística\nimport pandas_profiling # análise de dataset \nfrom scipy import stats # estatística \nfrom tqdm import tqdm # barra de progresso\nimport matplotlib.pyplot as plt # plotar gráficos\nfrom sklearn import metrics # importando a biblioteca de métricas\nfrom sklearn.linear_model import Lasso,LassoCV,Ridge,RidgeCV # importando as bibliotecas de \"ruídos\"\nfrom sklearn.decomposition import PCA # compressão de dados\nfrom sklearn.model_selection import train_test_split # dividir dataset em treino e teste\nfrom sklearn.preprocessing import StandardScaler # para deixar as variáveis na mesma escala\n\n# importando as bibliotecas com os modelos classificadores\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression   \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n\n###  KAGGLE ###\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# Código para execução do Notebook no Kaggle\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imprimindo uma barra de tempo para descrever o progresso do processamento\ntqdm.pandas(desc=\"Operation Progress\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Lendo e verificando as primeiras linhas dos arquivos\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()\n# EStá sem a variável target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Explorando Dataset\n\ninformações sobre o dataset de treino e para envio\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DataSet para envio tem 1 coluna a menos... A variável target "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorando Dataset: estatísticas básicas do dataset de treino\n\ndf_train.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorando Dataset: verificando a distribuição da variável target \n\ndf_train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando distribuição pelo histograma da variável target\n\ndf_train.target.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorando Dataset: verificando a distribuição da variável target ( percentual)\n\nval_0 = df_train.target.value_counts()[0]\nval_1 = df_train.target.value_counts()[1]\ntotal = val_0 + val_1\nperc_1 = round(val_1/total,4)*100\n# percentual de positivos ( target =1 )\nperc_1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fazendo correlação das variáveis para verificar a possibilidade de seleção das features mais significativas\n\nPorém, pelas correlações não foi possível fazer a seleção, uma vez que as correlaões estão com valores muito próximos"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo a correlação das variáveis\ncorrelacoes = df_train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ordenando as correlações de acordo com a variável target\ncorrelacoes.nlargest(200,'target')['target'].head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ordenando as correlações de acordo com a variável target\ncorrelacoes.nlargest(200,'target')['target'].tail(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ordenando as correlações de acordo com a variável target\ncorrelacoes.nlargest(200,'target')['target'].head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n Lista de Features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Teste: informações das variáveis, sem a target e ID\nfeatures = list(df_train)\ndf_train[features[2:22]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(df_train)\nfeatures\n#inicio = 2\n#fim = inicio +10\n#sns.pairplot(df_train[features[inicio:fim]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Fazendo pairplot para identificar distribuições das features e possíveis outliers\n\nOBSERVAÇÃO: No notebook está salvo apenas 1 dos plots e 1 análise através do pandas_profiling, porém foram feitos para TODAS as variáveis em grupos de 10\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(df_train)\ninicio = 2\nfim = inicio +10\nsns.pairplot(df_train[features[inicio:fim]])\n#%time sns.pairplot(df_train[features[inicio:fim]], hue='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando dataset com pandas_profiling\npandas_profiling.ProfileReport(df_train[features[inicio:fim]])\n\ninicio = fim\nfim = inicio +10\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Avaliando Retirada de outliers\n\nPelo \"pandas_profiling\" não foi identificada nenhuma feature muito fora do padrão de \"distribuição normal\"\n\n1. Todas as features que foram identificados outliers no pairplot, foram plotadas individualmente para avaliar a retirada dos outliers\n\nOBSERVAÇÕES: \n- Só tem o plot de 1 das features salvo neste notebook, mas o processo foi realizado com TODAS as features onde identificou-se outliers \n- Não havia nenhum outlier com grande variação em relação a média, apenas outliers com pequenas variações\n"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Identificando Outliers\n\nn = np.arange(0,df_train.shape[0])\nplt.plot(n,df_train['var_185'],'o')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definindo a Máscara de retirada\n\nmascara = (df_train['var_185']< 10) & (df_train['var_185']> -19)\n\nn = np.arange(0,df_train[ mascara].shape[0]) \nplt.plot(n,df_train[mascara]['var_185'],'o')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## Aplicando as máscaras para a retirada de outliers do dataframe de treino\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"mascara1 = (df_train['var_2']< 18) & (df_train['var_2']> 3.5)\nmascara2 = (df_train['var_4']< 15.5) & (df_train['var_4']> 5.75)\nmascara3 = (df_train['var_10']< 15.5) & (df_train['var_10']> -16)\nmascara4 = (df_train['var_11']< 13) & (df_train['var_11']> -21)\nmascara5 = (df_train['var_12']< 14.5) & (df_train['var_12']> 13.6)\nmascara6 = (df_train['var_15']< 15.6) & (df_train['var_15']> 13.45)\nmascara7 = (df_train['var_16']< 16.5) & (df_train['var_16']> 2.45)\nmascara8 = (df_train['var_17']< 12) & (df_train['var_17']> -26)\nmascara9 = (df_train['var_18']< 37) & (df_train['var_18']> -6)\nmascara10 = (df_train['var_20']< 29) & (df_train['var_20']> -1.5)\nmascara11 = (df_train['var_23']< 4.6) & (df_train['var_23']> 1.6)\nmascara12= (df_train['var_24']< 21) & (df_train['var_24']> 1)\nmascara13= (df_train['var_28']< 8.1) & (df_train['var_28']> 3.3)\nmascara14= (df_train['var_31']< 17.7) & (df_train['var_31']> 3.6)\nmascara15 = (df_train['var_32']< 6.2) & (df_train['var_32']> -7.5)\nmascara16 = (df_train['var_33']< 26) & (df_train['var_33']> 2.7)\nmascara17 = (df_train['var_38']< 24) & (df_train['var_38']> -2)\nmascara18 = (df_train['var_40']< 15) & (df_train['var_40']> -31)\nmascara19 = (df_train['var_44']< 25) & (df_train['var_44']> -9)\nmascara20 = (df_train['var_45']< 50) & (df_train['var_45']> -75)\nmascara21 = (df_train['var_47']< 13) & (df_train['var_47']> -41)\nmascara22 = (df_train['var_52']< 11) & (df_train['var_52']> -18)\nmascara23= (df_train['var_60']< 25) & (df_train['var_60']> 1)\nmascara24= (df_train['var_65']< 12) & (df_train['var_65']> -11)\nmascara25= (df_train['var_66']< 9) & (df_train['var_66']> 2.5)\nmascara26= (df_train['var_70']< 58) & (df_train['var_70']> -10)\nmascara27= (df_train['var_78']< 11) & (df_train['var_78']> -0.5)\nmascara28= (df_train['var_80']< 26) & (df_train['var_80']> -16)\nmascara29= (df_train['var_81']< 22) & (df_train['var_81']> 8.5)\nmascara30= (df_train['var_87']< 28) & (df_train['var_87']> -5)\nmascara31= (df_train['var_89']< 13) & (df_train['var_89']> -6)\nmascara32= (df_train['var_107']< 41) & (df_train['var_107']> -3)\nmascara33= (df_train['var_108']< 14.65) & (df_train['var_108']> 13.75)\nmascara34= (df_train['var_110']< 17) & (df_train['var_110']> -6)\nmascara35= (df_train['var_111']< 9.5) & (df_train['var_111']> 3.5)\nmascara36= (df_train['var_115']< 10.5) & (df_train['var_115']> -6)\nmascara37= (df_train['var_116']< 7) & (df_train['var_116']> -2.2)\nmascara38= (df_train['var_120']< 61) & (df_train['var_120']> -12)\nmascara39= (df_train['var_121']< 16.5) & (df_train['var_121']> 6.5)\nmascara40= (df_train['var_124']< 12.5) & (df_train['var_124']> -5)\nmascara41= (df_train['var_129']< 28) & (df_train['var_129']> 3)\nmascara42= (df_train['var_131']< 1.8) & (df_train['var_131']> -0.8)\nmascara43= (df_train['var_135']< 18) & (df_train['var_135']> -27)\nmascara44 = (df_train['var_138']< 16) & (df_train['var_138']> -14)\nmascara45 = (df_train['var_140']< 17) & (df_train['var_140']> -12)\nmascara46 = (df_train['var_146']< 18) & (df_train['var_146']> 2)\nmascara47 = (df_train['var_153']< 23) & (df_train['var_153']> 11.6)\nmascara48 = (df_train['var_163']< 29) & (df_train['var_163']> -5)\nmascara49 = (df_train['var_166']< 4.05) & (df_train['var_166']> 1.95)\nmascara50 = (df_train['var_168']< 14) & (df_train['var_168']> -5)\nmascara51 = (df_train['var_169']< 6.7) & (df_train['var_169']> 4.5)\nmascara52 = (df_train['var_175']< 20) & (df_train['var_175']> 3)\nmascara53 = (df_train['var_176']< 16) & (df_train['var_176']> -25)\nmascara54 = (df_train['var_180']< 11) & (df_train['var_180']> -18)\nmascara55 = (df_train['var_181']< 14) & (df_train['var_181']> 6)\nmascara56 = (df_train['var_185']< 10) & (df_train['var_185']> -19)\n\n\ndf = df_train[mascara1 & mascara2 & mascara4 & mascara3 & mascara5 & mascara6 & mascara7 & mascara8 & mascara9 & mascara10 & \n              mascara11 & mascara12 & mascara13 & mascara14 & mascara15 & mascara16 & mascara17 & mascara18 & mascara19 & mascara20 &\n              mascara21 & mascara22 & mascara23 & mascara24 & mascara25 & mascara26 & mascara27 & mascara28 & mascara29 & mascara30 &\n              mascara31 & mascara32 & mascara33 & mascara34 & mascara35 & mascara36 & mascara37 & mascara38 & mascara39 & mascara40 &\n              mascara41 & mascara42 & mascara43 & mascara44 & mascara45 & mascara46 & mascara47 & mascara48 & mascara49 & mascara50 &\n              mascara51 & mascara52 & mascara53 & mascara54 & mascara55 & mascara56]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## Fazendo o balanceamento dos dados\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# definindo variáveis para cada uma das classes\ndf1 = df[df.target==0]\ndf2 = df[df.target==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verificando o desbalanceamento\nlen(df1),len(df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fazendo um undersampling da classe com output zero (em maior número)\ndf1=df1.sample(n=18613)\nlen(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatenando os dois DataSets com o mesmo tamanho\ndf = pd.concat([df1,df2])\ndf.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Dividindo o DataSet em dois componentes\n\nX: todas as variáveis exceto target\\\nY: variável target \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, 2:202].values \ny = df.iloc[:, 1].values \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Dividindo X e Y em Trainning set e Testing set \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividindo os dados  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Aplicando o Standard Scaler\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# é preciso certificar que todas as features estão na mesma escala para evitar enviesamento.\nscaler = StandardScaler()\n\n# ajustando com os dados de treino função fit + transform juntas\nX_train = scaler.fit_transform(X_train) \n# transformando os dados de teste\nX_test = scaler.transform(X_test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Descobrir melhor número de componentes em PCA\n\nPorém, como o resultado foi uma reta, optou-se por não aplicar PCA no resultado final\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npca = PCA().fit(X_train)\n#Plotando a soma cumulativa para identificar o melhor número de componentes\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Numero de Componentes')\nplt.ylabel('Variacao (%)') #para cada componente\nplt.title('Explicacao por n.o de variaveis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n##  Fazendo vários modelos por loop \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# definindo uma lista com todos os classificadores para identificar qual teria uma melhor performance\nclassifiers = [\n    KNeighborsClassifier(3),\n    GaussianNB(),\n    LogisticRegression(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GradientBoostingClassifier()]\n\n# definindo o tamanho da figura para o gráfico\nplt.figure(figsize=(12,8))\n\n# rotina para instanciar, predizer e medir os rasultados de todos os modelos\nfor clf in classifiers:\n    # instanciando o modelo\n    clf.fit(X_train, y_train)\n    # armazenando o nome do modelo na variável name\n    name = clf.__class__.__name__\n    # imprimindo o nome do modelo\n    print(\"=\"*30)\n    print(name)\n    # imprimindo os resultados do modelo\n    print('****Resultados****')\n    y_pred = clf.predict(X_test)\n    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n    print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n    \n    \n    # plotando a curva ROC\n    y_pred_proba = clf.predict_proba(X_test)[::,1]\n    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=name+\", auc=\"+str(auc))\n    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n    plt.legend(loc=4)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## Pelo resultado acima, escolheu-se o modelo Naive bayes\n\nTreinando o modelo escolhido, provavelmente pelo fato das variáveis serem independentes ( não conseguiu-se usar nem PCA, por exemplo ) \n\n## Naive Bayes\n\nUm classificador Naive Bayes é um modelo probabilístico de aprendizado de máquina usado para tarefas de classificação. O cerne do classificador é baseado no teorema de Bayes.\n\nP(A|B) = ( P(B|A)*P(A) ) / P( B )\n\nUsando o teorema de Bayes, podemos encontrar a probabilidade de A acontecer, dado que B ocorreu. Aqui, B é a evidência e A é a hipótese. A suposição feita aqui é que os preditores / características são independentes. Essa é a presença de um recurso em particular não afeta o outro. Por isso, é chamado ingênuo.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# GaussianNB 0.8 -  sem fazer PCA\n# LogisticRegression 0.77 - c/ PCA de 10 componentes\n\n#clf = LogisticRegression()\nclf = GaussianNB()\n\nclf.fit(X_train, y_train)\n# armazenando o nome do modelo na variável name\nname = clf.__class__.__name__\n# imprimindo o nome do modelo\nprint(\"=\"*30)\nprint(name)\n# imprimindo os resultados do modelo\nprint('****Resultados****')\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\", metrics.recall_score(y_test, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparando o dataframe de entrega com os mesmos métodos aplicados no dataset de treino e posteriormente, calculando valores ( preditos )  "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = df_test.iloc[:, 1:201].values # variáveis , começa 1 antes, pois nao tem o target antes das variáveis\nX = scaler.transform(X)           # só faz o transform, mas não o fit novamente, o mesmo com test\n                                  # fit calcula os parametros, transform - transforma... não pode calcular novamente\ny_pred = clf.predict_proba(X)     # predição retornando probabilidade é mais eficaz no kaggle do que 0 ou 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred\n# primeiro valor no array é a probabilidade de ser 0\n# segundo valor no array é a probabilidade de ser 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['target'] = y_pred[:,1] # apenas probabilidade de ser 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparando arquivo de entrega"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[['ID_code','target']].head() # Apenas ID + target/predição","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Escrevendo arquivo para submissão ( máquina do usuário)\n# df_test[['ID_code','target']].to_csv (r'C:\\Users\\Usuario\\Desktop\\submission5.csv', index = None, header=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score no Kaggle: 0.88707 ( c/ predict_proba, ou 0.804 c/ predict )"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}