{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Santander Customer Transaction Prediction Analysis:\n\n## Comparing Using only Features Where Mean or SD of Positive-Target Subset Is Significantly Different from Original Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nfrom pandas.plotting import scatter_matrix\nimport numpy as np\n\nfrom scipy.stats import ttest_ind, levene\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for dataset issues:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#data types by column\ndf.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#mising values\ndf.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Number of 1s in target, total rows, and percent of 1s in target column:\npositives = df.target.sum()\ntotal = len(df.target)\nprint('positives:',positives,'total:',total,'percent:','{}%'.format(positives/total*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hypothesis testing features in relation to their target subset (by mean and standard deviation):"},{"metadata":{"trusted":false},"cell_type":"code","source":"pvalue_index_list = []\n\nfor i in range(200):\n    data1 = df['var_'+str(i)].values\n        \n    data2 = df[df['target']==1]['var_'+str(i)].values\n        \n    test_stat1, p_value_mean = ttest_ind(data1,data2)\n    \n    test_stat2, p_value_sd = levene(data1,data2)\n    \n    pvalue_index_list.append([i, p_value_mean, p_value_sd])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_pvalues = pd.DataFrame(pvalue_index_list, columns=['column_name',\n                                                      'p_value_mean',\n                                                      'p_value_sd'])\ndf_pvalues.set_index('column_name',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_pvalues.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Gives indication of number of significant values (by p-value)\n#Then we will remove everything not below 1.25e-4 p-value threshold\nhistogram = df_pvalues.hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_pvalues.p_value_mean.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_pvalues.p_value_sd.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separating out statistically different features:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#The 1.25e-4 threshold was generated by taking the critical value .05 and\n#and dividing it by 400 (200 features tested for two characteristics)\nsignificant_columns1 = df_pvalues[df_pvalues['p_value_mean']<=1.25e-4].index\n\nsignificant_columns2 = df_pvalues[df_pvalues['p_value_sd']<=1.25e-4].index\n\nsig_col = significant_columns1.union(significant_columns2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"columns_list = ['var_'+str(i) for i in sig_col]\n\ndf_sig = df[['target']+columns_list]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_sig.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Separating training and test sets:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Pruned values\nX_all1 = df_sig.drop(['target'],axis=1)\ny_all1 = df_sig['target']\n\n#All values\nX_all2 = df.drop(['target','ID_code'],axis=1)\ny_all2 = df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine learning:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#classifiers\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nimport xgboost as xgb\n\n#for function below\nfrom sklearn.model_selection import StratifiedKFold\nfrom time import time\nfrom sklearn.metrics import make_scorer,confusion_matrix,accuracy_score,\\\n    precision_score,recall_score,f1_score,roc_auc_score,matthews_corrcoef","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Balancing dataset target:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#for xgboost scale_pos_weight\nxgb_weight = (total-positives)/positives\n\nxgb_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf_A = LogisticRegression(random_state=0,class_weight='balanced')\n\nclf_B = RandomForestClassifier(random_state=0,max_depth=3,class_weight='balanced')\n\nclf_C = xgb.XGBClassifier(random_state=0,max_depth=3,scale_pos_weight=xgb_weight,\n                          subsample=.5,sample_type='weighted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Fold cross-validation function:"},{"metadata":{"trusted":false},"cell_type":"code","source":"average_orig_auc=[]\naverage_prune_auc=[]\n\ndef metrics_function(target,pred):\n    return accuracy_score(target, pred),precision_score(target, pred),\\\n        recall_score(target, pred),f1_score(target, pred),\\\n        roc_auc_score(target, pred),matthews_corrcoef(target, pred)\n\ndef FOLD_TEST(clf,X_all,y_all,folds_num,row_factor,orig_or_prune):\n    start=time()\n    \n    KFLD=StratifiedKFold(n_splits=folds_num,random_state=662,shuffle=True)\n    print ('{}:'.format(clf.__class__.__name__),'\\n')\n    \n    acc_list_train=[]\n    acc_list_test=[]\n    prc_list_train=[]\n    prc_list_test=[]\n    rcal_list_train=[]\n    rcal_list_test=[]\n    f1_list_train=[]\n    f1_list_test=[]\n    matt_list_train=[]\n    matt_list_test=[]\n    AUC_list_train=[]\n    AUC_list_test=[]\n    \n    samp_size=X_all.shape[0]//row_factor\n    \n    for fold,(train_index,target_index) in enumerate(KFLD.split(X_all[:samp_size],\n                                                                y_all[:samp_size])):\n        X_train=X_all.iloc[train_index].values\n        y_train=y_all.iloc[train_index].values\n\n        X_test=X_all.iloc[target_index].values\n        y_test=y_all.iloc[target_index].values\n\n        clf.fit(X_train,y_train)\n        y_pred1=clf.predict(X_train)\n        y_pred2=clf.predict(X_test)\n\n        train_acc,train_prc,train_rcal,train_f1,train_auc,train_matt=metrics_function(y_train,y_pred1)\n        \n        test_acc,test_prc,test_rcal,test_f1,test_auc,test_matt=metrics_function(y_test,y_pred2)\n        \n        acc_list_train.append(train_acc)\n        acc_list_test.append(test_acc)\n        prc_list_train.append(train_prc)\n        prc_list_test.append(test_prc)\n        rcal_list_train.append(train_rcal)\n        rcal_list_test.append(test_rcal)\n        \n        f1_list_train.append(train_f1)\n        f1_list_test.append(test_f1)\n        matt_list_train.append(train_matt)\n        matt_list_test.append(test_matt)\n        AUC_list_train.append(train_auc)\n        AUC_list_test.append(test_auc)\n    \n    print(\"Averages:\"'\\n')\n    \n    print(\"Train acc: {}, Test acc: {}\".format(np.mean(acc_list_train),\n                                               np.mean(acc_list_test)))\n    print(\"Train prc: {}, Test prc: {}\".format(np.mean(prc_list_train),\n                                               np.mean(prc_list_test)))\n    print(\"Train recall: {}, Test recall: {}\".format(np.mean(rcal_list_train),\n                                                     np.mean(rcal_list_test)),'\\n')\n    \n    print(\"Train f1: {}, Test f1: {}\".format(np.mean(f1_list_train),\n                                             np.mean(f1_list_test)))\n    print(\"Train MattCC: {}, Test MattCC: {}\".format(np.mean(matt_list_train),\n                                                     np.mean(matt_list_test)))\n    print(\"Train AUC: {}, Test AUC: {}\".format(np.mean(AUC_list_train),\n                                               np.mean(AUC_list_test)),'\\n'*2)\n        \n    print(\"Sample Size: {}, Folds Num: {}, Time: {}\".format(samp_size,folds_num,\n                                                            time()-start))\n    \n    if orig_or_prune == 'orig':\n        average_orig_auc.append(np.mean(AUC_list_test))\n    elif orig_or_prune == 'prune':\n        average_prune_auc.append(np.mean(AUC_list_test))\n    else:\n        print(\"orig_or_prune argument should be either 'orig' or 'prune'\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Pruned data:\nFOLD_TEST(clf_A, X_all1, y_all1,5,7,'prune')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Original data:\nFOLD_TEST(clf_A, X_all2, y_all2,5,7,'orig')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest: "},{"metadata":{"trusted":false},"cell_type":"code","source":"#Pruned data:\nFOLD_TEST(clf_B, X_all1, y_all1,5,7,'prune')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Original data:\nFOLD_TEST(clf_B, X_all2, y_all2,5,7,'orig')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost:"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Pruned data:\nFOLD_TEST(clf_C, X_all1, y_all1,5,7,'prune')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Original data:\nFOLD_TEST(clf_C, X_all2, y_all2,5,7,'orig')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results:"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Avg Original AUC: {}, Avg Pruned AUC: {}\".format(np.mean(average_orig_auc),\n                                                        np.mean(average_prune_auc)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There does not appear to be a significant difference between the original and pruned datasets, but optimizing the k-folds, sample size, and classification parameters might change that.\n\n### However, the pruned data did take less time and produced equivalent results."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}