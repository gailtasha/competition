{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport sklearn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score, auc, confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectKBest, SelectPercentile, GenericUnivariateSelect, f_regression\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBClassifier\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nimport pickle\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\ntrain = pd.read_csv(r\"/kaggle/input/santander-customer-transaction-prediction/train.csv\")\ntest = pd.read_csv(r\"/kaggle/input/santander-customer-transaction-prediction/test.csv\")\ntrain.columns = train.columns.str.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# lets check the shape of both test and train dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Dataset \",train.shape)\nprint(\"Test Dataset \",test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# lets check for the missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing Percentage of all the features\ndef missing_percentage(df):     \n    missing_total = df.isnull().sum().sort_values(ascending = False)[df.isnull().sum().sort_values(ascending = False) != 0]\n    percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100,2)[round(df.isnull().sum().sort_values(ascending = False)/len(df)*100,2) != 0]\n    return pd.concat([missing_total, percent], axis=1, keys=['Missing_Total','Percent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So We can clearly conclude that there is no missing value are present in training and test set!\n\nSo lets checks whether target columns is balanced or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['target']\n#train = train.drop([\"ID_code\", \"target\"], axis=1)\nsns.set_style('whitegrid')\nsns.countplot(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for imbalanced\ndef check_balance(df,target):\n    check=[]\n    print('size of data is:',df.shape[0] )\n    for i in [0,1]:\n        print('for target  {} ='.format(i))\n        print(df[target].value_counts()[i]/df.shape[0]*100,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_balance(train, 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a Imbalanced target competition.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_prep = [col for col in train.columns if col not in ['ID_code', 'target']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# skewness and kurtosis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Skewness: %f\" % train['target'].skew())\nprint(\"Kurtosis: %f\" % train['target'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of test and train set for mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train[data_prep].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[data_prep].mean(axis=1),color=\"red\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution for Standard Deviation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per rows in the train and test set\")\nsns.distplot(train[data_prep].std(axis=1),color=\"black\",kde=True,bins=120, label='train')\nsns.distplot(test[data_prep].std(axis=1),color=\"green\", kde=True,bins=120, label='test')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of skewness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per row in the train set\")\nsns.distplot(t0[data_prep].skew(axis=1),color=\"pink\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[data_prep].skew(axis=1),color=\"green\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of kurtosis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of kurtosis values per row in the train set\")\nsns.distplot(t0[data_prep].kurtosis(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[data_prep].kurtosis(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there are nearly 200 columns so it will take lot of time to create model. For that we have to check which feature is important.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['ID_code', 'target'], axis = 1)\ny = train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate mean absolute error\ndef cross_val(X_train, y_train, model):\n    # Applying k-Fold Cross Validation    \n    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5)\n    return accuracies.mean()\n\n# Takes in a model, trains the model, and evaluates the model on the test set\ndef fit_and_evaluate(model):\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions and evalute\n    model_pred = model.predict(X_test)\n    model_cross = cross_val(X_train, y_train, model)\n    \n    # Return the performance metric\n    return model_cross\n\n#This method is used for selecting the Most important feature which affect the target value using PCA.\ndef fit_and_evaluate_select_k(model):\n    \n    # Train the model\n    model.fit(X_train_pca, y_train_pca)\n    \n    # Make predictions and evalute\n    model_pred = model.predict(X_test_pca)\n    model_cross = cross_val(X_train_pca, y_train_pca, model)\n    \n    # Return the performance metric\n    return model_cross\n\n\n\n\n#As our dataset is imbalanced so we used SMOTE\n# Takes in a model, trains the model, and evaluates the model on the test set\ndef fit_and_evaluate_smote(model):\n    \n    # Train the model\n    model.fit(X_train_smote, Y_train_smote)\n    \n    # Make predictions and evalute\n    model_pred = model.predict(X_test)\n    model_cross = cross_val(X_train_smote, Y_train_smote, model)\n    \n    # Return the performance metric\n    return model_cross\n\n\n\ndef performance(Y_test, logist_pred):\n    logist_pred_var = [0 if i < 0.5 else 1 for i in logist_pred]\n    print('Confusion Matrix:')\n    print(confusion_matrix(Y_test, logist_pred_var)) \n   \n    fpr, tpr, thresholds = roc_curve(Y_test, logist_pred, pos_label=1)\n    print('AUC:')\n    print(auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# scaling dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X)\nX_scaled = sc.transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Due to  logistic regression and it depends on euclidean distance so we scaled the value \nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.5, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlogistic_Regression = fit_and_evaluate(lr)\n\nprint('LogisticRegression Performance on the test set: Cross Validation Score = %0.4f' % logistic_Regression)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets predict\nY_predict = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us seaborn in confusion matrix\ncm = confusion_matrix(y_test, Y_predict)\nannot_kws = {\"ha\": 'left',\"va\": 'top'}\nsns.heatmap(cm/np.sum(cm), annot=True, annot_kws=annot_kws,\n           fmt='.2%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nperformance(y_test, Y_predict)\n\n#This model gave out an AUC of 0.626 on validation set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate AUC\nauc = roc_auc_score(y_test, Y_predict)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(lr, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist(), top=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. As you move down the top of the graph, the importance of the feature decreases.\n2. The features that are shown in green indicate that they have a positive impact on our prediction\n3. The features that are shown in white indicate that they have no effect on our prediction\n4. The features shown in red indicate that they have a negative impact on our prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression accuracy is 91 percent. Lets Check the Precision & Recall.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report about the model \nprint(classification_report(y_test, Y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Precision is quite good 69 percent. But the as we know that your dataset is skewed, we have to concentrate on improving your F1 score. If your data is not skewed, only accuracy can be used to say whether a model is good or not.\n\nSo I decide to use SMOTE (Synthetic Minority Oversampling Technique) in this dataset. And Try to increase F1 score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_smote, Y_train_smote = smote.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nprint(\"Before SMOTE \", Counter(y_train))\nprint(\"After SMOTE\", Counter(Y_train_smote))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before SMOTE  Counter({0: 90055, 1: 9945})\n\nAfter SMOTE Counter({1: 90055, 0: 90055})\n\nSo Lets check Precision and F1 Score using Logitics Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_smote = LogisticRegression()\nlogistic_Regression_smote = fit_and_evaluate_smote(lr_smote)\n\nprint('LogisticRegression Performance on the SMOTE test set: Cross Validation Score = %0.4f' % logistic_Regression_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets predict\nY_predict_smote = lr_smote.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#After using SMOTE lets check the peformance\n#Let us seaborn in confusion matrix\ncm = confusion_matrix(y_test, Y_predict_smote)\nannot_kws = {\"ha\": 'left',\"va\": 'top'}\nsns.heatmap(cm/np.sum(cm), annot=True, annot_kws=annot_kws,\n           fmt='.2%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate AUC\nauc = roc_auc_score(y_test, Y_predict_smote)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict_smote)\n# plot no skill\nplt.plot([0, 1], [0, 1])\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report about the model \nprint(classification_report(y_test, Y_predict_smote))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Precision is too low !!\n\nAlso the dataset is too big and taking a very long time to train the data. For that I have used PCA technique to reduce the dimension. And again try to use logistic regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components= 100)\n\nX_pca = pca.fit_transform(X_train_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, Y_train_smote, test_size=0.3, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlr_pca = LogisticRegression()\nlogistic_Regression_pca = fit_and_evaluate_select_k(lr_pca)\n\nprint('LogisticRegression Performance on the test set: Cross Validation Score = %0.4f' % logistic_Regression_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets predict\nY_predict_pca = lr_pca.predict(X_test_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us seaborn in confusion matrix\ncm = confusion_matrix(y_test_pca, Y_predict_pca)\nannot_kws = {\"ha\": 'left',\"va\": 'top'}\nsns.heatmap(cm/np.sum(cm), annot=True, annot_kws=annot_kws,\n           fmt='.2%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate AUC\nauc = roc_auc_score(y_test_pca, Y_predict_pca)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test_pca, Y_predict_pca)\n# plot no skill\nplt.plot([0, 1], [0, 1])\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#classification report about the model \nprint(classification_report(y_test_pca, Y_predict_pca))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And after using the PCA technique our algorithm giving a better result with good Precision, Recall and F1-Score.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Lets Check in Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrandom = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nrandom_cross = fit_and_evaluate_select_k(random)\n\nprint('Random Forest Performance on the test set: Cross Validation Score = %0.4f' % random_cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets predict\nY_predict_rf = random.predict(X_test_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us seaborn in confusion matrix\ncm = confusion_matrix(y_test_pca, Y_predict_rf)\nannot_kws = {\"ha\": 'left',\"va\": 'top'}\nsns.heatmap(cm/np.sum(cm), annot=True, annot_kws=annot_kws,\n           fmt='.2%', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate AUC\nauc = roc_auc_score(y_test_pca, Y_predict_rf)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test_pca, Y_predict_rf)\n# plot no skill\nplt.plot([0, 1], [0, 1])\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report about the model \nprint(classification_report(y_test_pca, Y_predict_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest is a great fit as the precision, recall, f1score are highly balance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model=XGBClassifier(random_state=1,learning_rate=0.01)\n\nxgBoost_Cross = fit_and_evaluate_select_k(model)\nprint('XGBClassifier Performance on the test set: Cross Validation Score = %0.4f' % xgBoost_Cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nclf = LinearSVC(random_state=0, tol=1e-5)\nclf.fit(X_train_pca, y_train_pca) \n\nsvc_fit = fit_and_evaluate_select_k(clf)\n\nprint('SVC Performance on the test set: Cross Validation Score = %0.4f' % svc_fit)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC Performance on the test set: Cross Validation Score = 0.7960\nSo, I have evaluted 4 algorithms\n\n1.Logistic Regression\n\n2.Random Forest Classifier\n\n3.XGBClassifier\n\n4.SVC\n\nBut from the above algorithms Random Forest Classifier is good for evaluting because of Cross Validation Score of 85%. As we know Logistic regression are used more often when we have cleanly and linearly separable classes. If we add more variables into the mix, which means that logistic regression performs worse under high dimensionality conditions. That means that typically we have to shift over to random forest if we have a lot of variables.\n\nFortunately we had a algorithm which is a good fit for our business module and that mean Random Forest Classifier is the best choice with good Precision, Recall and F1Score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now it is time to test our algorithm using TEST set.\ndata_x_test = test.drop(columns = ['ID_code'])\n\n#scaling dataset\nsc = StandardScaler()\nsc.fit(data_x_test)\nX_scaled = sc.transform(data_x_test)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n\n#Reducing the dimension\npca = PCA(n_components= 100)\nX_pca = pca.fit_transform(X_scaled) \n\n\ny_pred = random.predict(X_pca)\ndata_y = pd.DataFrame(y_pred)\ndf_submission = pd.merge(pd.DataFrame(test['ID_code']),data_y, left_index=True, right_index=True)\n\nprint(df_submission)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}