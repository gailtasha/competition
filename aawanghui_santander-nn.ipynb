{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"7646c73810d475601436c096d36498cfaa489ec4"},"cell_type":"code","source":"# Basic packages\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport time\nimport random\nimport glob\nimport sys\nimport os\nimport gc\n\nimport pandas as pd\nimport numpy as np\nimport scipy\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Input, Flatten, Dropout,Conv1D, BatchNormalization ,Activation, Add,Reshape, Average,Lambda, concatenate\nfrom keras import callbacks\nfrom keras import optimizers\nimport keras.backend as K\n\n# visualization packages\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# execution progress bar\nfrom tqdm import tqdm_notebook, tnrange\nfrom tqdm.auto import tqdm\ntqdm.pandas()\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"16768a965c3ced6a76d33642e11ecae18f5977e8"},"cell_type":"code","source":"# System Setup\n%matplotlib inline\n%precision 4\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\nnp.set_printoptions(suppress=True)\npd.set_option(\"display.precision\", 15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c90af9d21a49adcbd478c56871149f1282c58b7f"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_uuid":"a2ad6d700b17b5efff5e374c62985b66d0019ae1"},"cell_type":"markdown","source":"### Neural Net"},{"metadata":{"trusted":true,"_uuid":"2748550bafaecec788d32a621888b64df3b8444e"},"cell_type":"code","source":"#LOAD DATA\ndf_train = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv', index_col=0)\ny_train = df_train.pop('target')\n\n\nlen_train = len(df_train)\ndf_test = pd.read_csv('./../input/santander-customer-transaction-prediction/test.csv', index_col=0)\ndf_all = pd.concat((df_train, df_test), sort=False)\nprev_cols = df_all.columns\n\n# PREPROCESS\nscaler = StandardScaler()\ndf_all[prev_cols] = scaler.fit_transform(df_all[prev_cols])\ndf_train = df_all[0:len_train]\ndf_test = df_all[len_train:]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b749cf55da65e6c04ad9b10761169aff3f0cd70"},"cell_type":"code","source":" def augment_train(df_train, y_train):   \n    t0 = df_train[y_train == 0].copy()\n    t1 = df_train[y_train == 1].copy()\n    i = 0\n    N = 3\n    for I in range(0):  # augment data into 2x\n        for col in df_train.columns:\n            i = i + 1000\n            np.random.seed(i)\n            np.random.shuffle(t0[col].values)\n            np.random.shuffle(t1[col].values)\n        df_train = pd.concat([df_train, t0.copy()])\n        df_train = pd.concat([df_train, t1.copy()])\n        y_train = pd.concat([y_train, pd.Series([0] * t0.shape[0]), pd.Series([1] * t1.shape[0])])\n    return df_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in df_train.columns if c not in [\"ID_code\",\"target\"]]\ndef detect_test(test_df):\n    df_test=test_df.values\n    unique_count = np.zeros_like(df_test)\n    for feature in tqdm(range(df_test.shape[1])):\n        _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n        unique_count[index_[count_ == 1], feature] += 1\n\n    # Samples which have unique values are real the others are fake\n    real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n    synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n    return real_samples_indexes,synthetic_samples_indexes\ndef generate_fe(trn, tst):\n    #tst,target=augment_train(tst,y_train=target)\n    real,syn = detect_test(df_test[features])\n    al = pd.concat([trn,tst,df_test.iloc[real]],axis=0)\n    trn_fe = pd.DataFrame()\n    tst_fe = pd.DataFrame()\n    for c in features:\n        trn[c+\"_test\"]=trn[c].map(al[c].value_counts())\n        trn[c+\"_multi\"] = trn[c+\"_test\"]*trn[c]\n        #trn[c+\"_div\"] = trn[c]/trn[c+\"_test\"]\n        trn_fe[c] = trn[c]\n        trn_fe[c+\"_test\"] = trn[c+\"_test\"]\n        trn_fe[c+\"_muti\"] = trn[c+\"_multi\"]\n        #trn_fe[c+\"_div\"] = trn[c+\"_div\"]\n        tst[c+\"_test\"]=tst[c].map(al[c].value_counts())\n        #tst[c+\"_test\"] = tst[c+\"_test\"]*tst[c]\n        tst_fe[c] = tst[c]\n        tst[c+\"_multi\"] = tst[c+\"_test\"]*tst[c]\n        #tst[c+\"_div\"] = tst[c]/tst[c+\"_test\"]\n        tst_fe[c+\"_test\"] = tst[c+\"_test\"]\n        tst_fe[c+\"_muti\"] = tst[c+\"_multi\"]\n        #tst_fe[c+\"_div\"] = tst[c+\"_div\"]\n    return trn_fe, tst_fe\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_fe_test(tst):\n    re,sy =  detect_test(tst[features])\n    al = pd.concat([df_train,df_test.iloc[re]],axis=0)\n    tst_fe = pd.DataFrame()\n    for c in features:\n        tst[c+\"_test\"]=tst[c].map(al[c].value_counts())\n        #tst[c+\"_test\"] = tst[c+\"_test\"]*tst[c]\n        tst_fe[c] = tst[c]\n        tst[c+\"_multi\"] = tst[c+\"_test\"]*tst[c]\n        #tst[c+\"_div\"] = tst[c]/tst[c+\"_test\"]\n        tst_fe[c+\"_test\"] = tst[c+\"_test\"]\n        tst_fe[c+\"_muti\"] = tst[c+\"_multi\"]\n        #tst_fe[c+\"_div\"] = tst[c+\"_div\"]\n    return tst_fe\ntest_fe = generate_fe_test(df_test[features])","execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=200), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d9ad24a835b4e1ba567445839bdcec9"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"8f0e1a0ab529f4561d4511f650ac9b80e5202fd1"},"cell_type":"code","source":"# MODEL DEF\ndef auc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\ndef _Model():\n    inp = Input(shape=(200,3))\n    d1 = Dense(32,activation='relu')(inp)\n    d1 = BatchNormalization()(d1)\n    '''d1 = Dense(128,activation='relu')(d1)\n    d1 = Dense(64,activation='relu')(d1)\n    d1 = Dense(32,activation='relu')(d1)\n    d1 = Dense(16,activation='relu')(d1)'''\n    #d2 = Lambda(lambda x: x, output_shape=(400,1))(inp)\n    #d2 = Dense(256,activation='relu')(inp)\n    #d3 = concatenate([d1, d2], axis = 2)\n    ''' d3 = Dense(256,activation=\"relu\")(d3)\n    d3 = Dense(128,activation=\"relu\")(d3)\n    d3 = Dense(64,activation=\"relu\")(d3)\n    d3 = Dense(32,activation=\"relu\")(d3)'''\n    d1 = Dense(8,activation=\"relu\")(d1)\n    d1 = BatchNormalization()(d1)\n    d4 = Flatten()(d1)\n    preds = Dense(1, activation=\"sigmoid\")(d4)\n    model = Model(inputs=inp, outputs=preds)\n    adam = optimizers.Adam(lr=0.009)\n    model.compile(optimizer=adam, loss=K.binary_crossentropy,metrics=[\"acc\"])\n    model.summary()\n    return model","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"174a3090029ebc352cd914d4bd36256f43145140"},"cell_type":"code","source":"# LOGGER\nclass Logger(callbacks.Callback):\n    def __init__(self, out_path='./', patience=30, lr_patience=3, out_fn='', log_fn=''):\n        self.auc = 0\n        self.path = out_path\n        self.fn = out_fn\n        self.patience = patience\n        self.lr_patience = lr_patience\n        self.no_improve = 0\n        self.no_improve_lr = 0\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        cv_pred = self.model.predict(self.validation_data[0], batch_size=1024)\n        cv_true = self.validation_data[1]\n        auc_val = roc_auc_score(cv_true, cv_pred)\n        if self.auc < auc_val:\n            self.no_improve = 0\n            self.no_improve_lr = 0\n            print(\"Epoch %s - best AUC: %s\" % (epoch, round(auc_val, 4)))\n            self.auc = auc_val\n            self.model.save(self.path + self.fn, overwrite=True)\n        else:\n            self.no_improve += 1\n            self.no_improve_lr += 1\n            print(\"Epoch %s - current AUC: %s\" % (epoch, round(auc_val, 4)))\n            if self.no_improve >= self.patience:\n                self.model.stop_training = True\n            if self.no_improve_lr >= self.lr_patience:\n                lr = float(K.get_value(self.model.optimizer.lr))\n                K.set_value(self.model.optimizer.lr, 0.75*lr)\n                print(\"Setting lr to {}\".format(0.75*lr))\n                self.no_improve_lr = 0\n\n        return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09d54e544403e9d61d74d6a97f189ee70acc3d20","scrolled":true},"cell_type":"code","source":"#RUN\npreds = []\nc = 0\noof_preds = np.zeros((len(df_train), 1))\ncv = StratifiedKFold(n_splits=5,shuffle=True, random_state=3263)\nfor train, valid in cv.split(df_train, y_train):\n    print(\"VAL %s\" % c)\n    trn = df_train.iloc[train]\n    tst = df_train.iloc[valid]\n    trn, tst = generate_fe(trn, tst)\n    X_train = np.reshape(trn.values, (-1,200,3))\n    y_train_ = y_train.iloc[train].values\n    X_valid = np.reshape(tst.values, (-1,200,3))\n    y_valid = y_train.iloc[valid].values\n    model = _Model()\n    logger = Logger(patience=30, out_path='./', out_fn='cv_{}.h5'.format(c))\n    model.fit(X_train, y_train_, validation_data=(X_valid, y_valid), epochs=150, verbose=2, batch_size=1024,\n              callbacks=[logger])\n    model.load_weights('cv_{}.h5'.format(c))\n    fe = [c for c in test_fe.columns if c not in [\"ID_code\",\"target\"]]\n    X_test = np.reshape(test_fe[fe].values, (200000, 200, 3))\n    curr_preds = model.predict(X_test, batch_size=2048)\n    oof_preds[valid] = model.predict(X_valid)\n    preds.append(curr_preds)\n    c += 1\npd.DataFrame(oof_preds).to_csv(\"NN_oof_preds.csv\", index = False)\nauc = roc_auc_score(y_train, oof_preds)\nprint(\"CV_AUC: {}\".format(auc))\n\n# SAVE DATA\npreds = np.asarray(preds)\npreds = preds.reshape((5, 200000))\npreds_final = np.mean(preds.T, axis=1)\nsubmission = pd.read_csv('./../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = preds_final\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"VAL 0\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=200), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d24bab1ce8436eadac518ca97c78b2"}},"metadata":{}},{"output_type":"stream","text":"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_14 (InputLayer)        (None, 200, 3)            0         \n_________________________________________________________________\ndense_40 (Dense)             (None, 200, 32)           128       \n_________________________________________________________________\nbatch_normalization_27 (Batc (None, 200, 32)           128       \n_________________________________________________________________\ndense_41 (Dense)             (None, 200, 8)            264       \n_________________________________________________________________\nbatch_normalization_28 (Batc (None, 200, 8)            32        \n_________________________________________________________________\nflatten_14 (Flatten)         (None, 1600)              0         \n_________________________________________________________________\ndense_42 (Dense)             (None, 1)                 1601      \n=================================================================\nTotal params: 2,153\nTrainable params: 2,073\nNon-trainable params: 80\n_________________________________________________________________\nTrain on 159999 samples, validate on 40001 samples\nEpoch 1/150\n - 10s - loss: 0.2332 - acc: 0.9144 - val_loss: 0.2715 - val_acc: 0.8908\nEpoch 0 - best AUC: 0.8977\nEpoch 2/150\n - 7s - loss: 0.2005 - acc: 0.9257 - val_loss: 0.2351 - val_acc: 0.9161\nEpoch 1 - best AUC: 0.9078\nEpoch 3/150\n - 7s - loss: 0.1893 - acc: 0.9303 - val_loss: 0.6103 - val_acc: 0.7106\nEpoch 2 - best AUC: 0.9137\nEpoch 4/150\n - 7s - loss: 0.1865 - acc: 0.9312 - val_loss: 0.2186 - val_acc: 0.9244\nEpoch 3 - best AUC: 0.9167\nEpoch 5/150\n - 7s - loss: 0.1832 - acc: 0.9325 - val_loss: 0.4936 - val_acc: 0.7750\nEpoch 4 - best AUC: 0.9191\nEpoch 6/150\n - 7s - loss: 0.1826 - acc: 0.9325 - val_loss: 0.3380 - val_acc: 0.8575\nEpoch 5 - best AUC: 0.9207\nEpoch 7/150\n - 7s - loss: 0.1819 - acc: 0.9328 - val_loss: 0.2287 - val_acc: 0.9211\nEpoch 6 - current AUC: 0.9199\nEpoch 8/150\n - 7s - loss: 0.1799 - acc: 0.9339 - val_loss: 0.1998 - val_acc: 0.9254\nEpoch 7 - best AUC: 0.9216\nEpoch 9/150\n - 7s - loss: 0.1799 - acc: 0.9335 - val_loss: 0.1859 - val_acc: 0.9300\nEpoch 8 - best AUC: 0.9224\nEpoch 10/150\n - 7s - loss: 0.1788 - acc: 0.9341 - val_loss: 0.2252 - val_acc: 0.9215\nEpoch 9 - current AUC: 0.9209\nEpoch 11/150\n - 7s - loss: 0.1775 - acc: 0.9348 - val_loss: 0.2182 - val_acc: 0.9163\nEpoch 10 - current AUC: 0.9221\nEpoch 12/150\n - 7s - loss: 0.1784 - acc: 0.9346 - val_loss: 0.2500 - val_acc: 0.9165\nEpoch 11 - current AUC: 0.9218\nSetting lr to 0.006749999709427357\nEpoch 13/150\n - 7s - loss: 0.1759 - acc: 0.9353 - val_loss: 0.2009 - val_acc: 0.9271\nEpoch 12 - best AUC: 0.9236\nEpoch 14/150\n - 7s - loss: 0.1756 - acc: 0.9355 - val_loss: 0.2003 - val_acc: 0.9237\nEpoch 13 - current AUC: 0.921\nEpoch 15/150\n - 7s - loss: 0.1765 - acc: 0.9350 - val_loss: 0.1976 - val_acc: 0.9278\nEpoch 14 - current AUC: 0.9224\nEpoch 16/150\n - 7s - loss: 0.1752 - acc: 0.9357 - val_loss: 0.1842 - val_acc: 0.9305\nEpoch 15 - current AUC: 0.9236\nSetting lr to 0.0050624997820705175\nEpoch 17/150\n - 7s - loss: 0.1737 - acc: 0.9362 - val_loss: 0.2188 - val_acc: 0.9228\nEpoch 16 - best AUC: 0.9237\nEpoch 18/150\n - 7s - loss: 0.1738 - acc: 0.9360 - val_loss: 0.1804 - val_acc: 0.9325\nEpoch 17 - current AUC: 0.9229\nEpoch 19/150\n - 7s - loss: 0.1733 - acc: 0.9363 - val_loss: 0.2540 - val_acc: 0.9163\nEpoch 18 - current AUC: 0.9237\nEpoch 20/150\n - 7s - loss: 0.1734 - acc: 0.9361 - val_loss: 0.1981 - val_acc: 0.9279\nEpoch 19 - current AUC: 0.9232\nSetting lr to 0.003796875011175871\nEpoch 21/150\n - 7s - loss: 0.1722 - acc: 0.9366 - val_loss: 0.2653 - val_acc: 0.8945\nEpoch 20 - current AUC: 0.9232\nEpoch 22/150\n - 7s - loss: 0.1722 - acc: 0.9365 - val_loss: 0.1924 - val_acc: 0.9259\nEpoch 21 - best AUC: 0.9241\nEpoch 23/150\n - 7s - loss: 0.1720 - acc: 0.9368 - val_loss: 0.1790 - val_acc: 0.9323\nEpoch 22 - best AUC: 0.9246\nEpoch 24/150\n - 7s - loss: 0.1722 - acc: 0.9366 - val_loss: 0.2047 - val_acc: 0.9216\nEpoch 23 - current AUC: 0.9245\nEpoch 25/150\n - 7s - loss: 0.1715 - acc: 0.9374 - val_loss: 0.1812 - val_acc: 0.9319\nEpoch 24 - current AUC: 0.9233\nEpoch 26/150\n - 7s - loss: 0.1723 - acc: 0.9367 - val_loss: 0.2130 - val_acc: 0.9175\nEpoch 25 - current AUC: 0.9238\nSetting lr to 0.002847656258381903\nEpoch 27/150\n - 7s - loss: 0.1712 - acc: 0.9368 - val_loss: 0.1848 - val_acc: 0.9296\nEpoch 26 - current AUC: 0.9236\nEpoch 28/150\n - 7s - loss: 0.1708 - acc: 0.9374 - val_loss: 0.1800 - val_acc: 0.9323\nEpoch 27 - current AUC: 0.9238\nEpoch 29/150\n - 7s - loss: 0.1710 - acc: 0.9370 - val_loss: 0.1788 - val_acc: 0.9323\nEpoch 28 - current AUC: 0.9239\nSetting lr to 0.002135742106474936\nEpoch 30/150\n - 7s - loss: 0.1702 - acc: 0.9374 - val_loss: 0.2319 - val_acc: 0.9097\nEpoch 29 - current AUC: 0.9238\nEpoch 31/150\n - 7s - loss: 0.1703 - acc: 0.9374 - val_loss: 0.1882 - val_acc: 0.9275\nEpoch 30 - current AUC: 0.9242\nEpoch 32/150\n - 7s - loss: 0.1703 - acc: 0.9371 - val_loss: 0.1829 - val_acc: 0.9314\nEpoch 31 - current AUC: 0.9239\nSetting lr to 0.0016018064925447106\nEpoch 33/150\n - 7s - loss: 0.1698 - acc: 0.9375 - val_loss: 0.1962 - val_acc: 0.9287\nEpoch 32 - current AUC: 0.9242\nEpoch 34/150\n - 7s - loss: 0.1696 - acc: 0.9378 - val_loss: 0.1849 - val_acc: 0.9292\nEpoch 33 - current AUC: 0.924\nEpoch 35/150\n - 7s - loss: 0.1699 - acc: 0.9375 - val_loss: 0.1831 - val_acc: 0.9307\nEpoch 34 - current AUC: 0.9241\nSetting lr to 0.001201354869408533\nEpoch 36/150\n - 7s - loss: 0.1693 - acc: 0.9380 - val_loss: 0.1802 - val_acc: 0.9319\nEpoch 35 - current AUC: 0.9243\nEpoch 37/150\n - 7s - loss: 0.1691 - acc: 0.9380 - val_loss: 0.1819 - val_acc: 0.9313\nEpoch 36 - current AUC: 0.9242\nEpoch 38/150\n - 7s - loss: 0.1695 - acc: 0.9379 - val_loss: 0.2012 - val_acc: 0.9276\nEpoch 37 - current AUC: 0.9241\nSetting lr to 0.0009010161738842726\nEpoch 39/150\n - 7s - loss: 0.1690 - acc: 0.9376 - val_loss: 0.1785 - val_acc: 0.9328\nEpoch 38 - current AUC: 0.9242\nEpoch 40/150\n - 7s - loss: 0.1689 - acc: 0.9379 - val_loss: 0.1788 - val_acc: 0.9331\nEpoch 39 - current AUC: 0.9244\nEpoch 41/150\n - 7s - loss: 0.1688 - acc: 0.9383 - val_loss: 0.1780 - val_acc: 0.9331\nEpoch 40 - current AUC: 0.9244\nSetting lr to 0.0006757621304132044\nEpoch 42/150\n - 7s - loss: 0.1687 - acc: 0.9381 - val_loss: 0.1784 - val_acc: 0.9328\nEpoch 41 - current AUC: 0.9243\nEpoch 43/150\n - 7s - loss: 0.1685 - acc: 0.9381 - val_loss: 0.1786 - val_acc: 0.9327\nEpoch 42 - current AUC: 0.9242\nEpoch 44/150\n - 7s - loss: 0.1685 - acc: 0.9381 - val_loss: 0.1813 - val_acc: 0.9317\nEpoch 43 - current AUC: 0.9242\nSetting lr to 0.0005068215978099033\nEpoch 45/150\n - 7s - loss: 0.1685 - acc: 0.9380 - val_loss: 0.1782 - val_acc: 0.9328\nEpoch 44 - current AUC: 0.9243\nEpoch 46/150\n - 7s - loss: 0.1684 - acc: 0.9381 - val_loss: 0.1799 - val_acc: 0.9321\nEpoch 45 - current AUC: 0.9242\nEpoch 47/150\n - 7s - loss: 0.1683 - acc: 0.9379 - val_loss: 0.1783 - val_acc: 0.9327\nEpoch 46 - current AUC: 0.9242\nSetting lr to 0.0003801162092713639\nEpoch 48/150\n - 7s - loss: 0.1683 - acc: 0.9382 - val_loss: 0.1782 - val_acc: 0.9328\nEpoch 47 - current AUC: 0.9243\nEpoch 49/150\n - 7s - loss: 0.1682 - acc: 0.9384 - val_loss: 0.1785 - val_acc: 0.9326\nEpoch 48 - current AUC: 0.9242\nEpoch 50/150\n - 7s - loss: 0.1681 - acc: 0.9382 - val_loss: 0.1802 - val_acc: 0.9324\nEpoch 49 - current AUC: 0.9243\nSetting lr to 0.00028508716786745936\nEpoch 51/150\n - 7s - loss: 0.1681 - acc: 0.9378 - val_loss: 0.1786 - val_acc: 0.9325\nEpoch 50 - current AUC: 0.9243\nEpoch 52/150\n - 7s - loss: 0.1681 - acc: 0.9382 - val_loss: 0.1783 - val_acc: 0.9326\nEpoch 51 - current AUC: 0.9243\nEpoch 53/150\n - 7s - loss: 0.1681 - acc: 0.9382 - val_loss: 0.1787 - val_acc: 0.9326\nEpoch 52 - current AUC: 0.9243\nSetting lr to 0.0002138153649866581\nVAL 1\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=200), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d8ac3365257459f8494b3ea8f5e0473"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"d176dabfa1bfdcf74a08526fb5a01a774ff1a0bf"},"cell_type":"markdown","source":"kkjjjsubmission = pd.read_csv('./../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = sub1.target \nsubmission.to_csv('submission.csv', index=False)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}