{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport sklearn.decomposition as skde\nimport sklearn.model_selection as ms\nfrom sklearn import linear_model\nimport sklearn.metrics as sklm\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"test_dataset = pd.read_csv(\"../input/test.csv\")\ntrain_dataset = pd.read_csv(\"../input/train.csv\")\n# train_dataset.corr()\n#test_dataset.corr()\n# test_dataset.info()\ntrain_dataset.isnull().values.any() #Check if there are null values in dataset\ntrain_dataset[\"target\"].value_counts() #Test to check for class imbalance\nsns.countplot(train_dataset[\"target\"]) #visualize class distribution\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"824504de20a742f7c14251579729aba2cac89b08"},"cell_type":"code","source":"#split into input and label\nlabels = train_dataset[\"target\"]\nnew_train_dataset = train_dataset.drop([\"target\",\"ID_code\"],axis =1)\nnew_train_dataset.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e9dd93f447d925c4c6bb5094543c0db4339f785"},"cell_type":"code","source":"#select important features\nfrom sklearn.feature_selection import SelectFromModel\nclf = RandomForestClassifier(n_estimators=100)\nselected_features = SelectFromModel(clf)\nselected_features.fit(new_train_dataset,labels.values.ravel())\nlist_sel= new_train_dataset.columns[(selected_features.get_support())]\nnew_train = pd.DataFrame(data = new_train_dataset,columns = list_sel)\nnew_train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f7ed9b99ccfba4a8774743a6a8a5f5f8711879a"},"cell_type":"code","source":"# check class distribution in percentage\ncount_0 = len(train_dataset[train_dataset[\"target\"] == 0])\ncount_1 = len(train_dataset[train_dataset[\"target\"] == 1])\npercentage_count_0 = ((count_0)/(count_0+count_1)) * 100\npercentage_count_1 = 100-percentage_count_0\nprint(\"{}{}{}{}{}\".format(\"Percentage of 0 class is \",percentage_count_0,\"\\n\",\"Percentage of 1 class is \",percentage_count_1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"888922efa738dac142951e44c63cb9fb4daeea39"},"cell_type":"code","source":"#use SMOTE technique to take care of the class imbalance\nos = SMOTE(random_state=0) #   We are using SMOTE as the function for oversampling\nos_data_X,os_data_y=os.fit_sample(new_train,labels)\nos_data_X = pd.DataFrame(data=os_data_X,columns=new_train.columns)\nos_data_y= pd.DataFrame(data=os_data_y,columns=[\"target\"])\n\n\nprint(\"length of oversampled data is \",len(os_data_X))\nprint(\"Number of 0 class in oversampled data\",len(os_data_y[os_data_y[\"target\"]==0]))\nprint(\"Number of 1 class in oversampled data\",len(os_data_y[os_data_y[\"target\"]==1]))\nprint(\"Proportion of 0 class in oversampled data is \",len(os_data_y[os_data_y[\"target\"]==0])/len(os_data_X))\nprint(\"Proportion of 1 class in oversampled data is \",len(os_data_y[os_data_y[\"target\"]==1])/len(os_data_X))\n\nos_data_X.shape,os_data_y.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af2bc35d77e069b7baf07c5d3946072888369d55"},"cell_type":"code","source":"#check if therea are highly correlated features\nos_data_X.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c77cb0c114750e0dd3ffe9b8f033bb402ec00ee"},"cell_type":"code","source":"#scale dataset\n# scaler = preprocessing.StandardScaler()\n# scaled_data = scaler.fit_transform(os_data_X)\n# scaled_data = pd.DataFrame(data = scaled_data,columns = os_data_X.columns)\n# scaled_data.head()\nos_data_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b4629daec64b28b0f18c98957cf1fb505a99820"},"cell_type":"code","source":"#split data into test and train set\nx_train, x_test, y_train, y_test = train_test_split(os_data_X, os_data_y, test_size = 0.25, random_state = 0)\nx_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e38a9be6f0c0ecd13209604c858737d275d6ac45"},"cell_type":"code","source":"#convert dataset to lightgbm format for lightgbm training\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\ntrain_set = lgb.Dataset(x_train, label=y_train)\ntrain_eval = lgb.Dataset(x_test, y_test, reference=train_set)\nparams = {}\nparams['learning_rate'] = 0.001\nparams['boosting_type'] = 'rf'\nparams['objective'] = 'binary'\nparams['metric'] = 'binary_error'\nparams['sub_feature'] = 0.5\nparams['min_data'] = 50\nparams['max_depth'] = 8\nparams['bagging_freq'] =  5\nparams['bagging_fraction'] = 0.4\nparams['feature_fraction'] = 0.05\nparams['num_leaves'] = 256\nparams['task'] = 'train'\nparams['min_data_in_leaf'] = 100\nparams['max_bin'] = 120\nparams['num_iteration']=150\nparams['verbose'] = 1\n# clf = lgb.train(params,train_set, early_stopping_rounds=15,valid_sets=[train_set,train_eval],\n#             valid_names=['train', 'eval'],)\n\n# #Prediction\n# y_pred=clf.predict(x_test)\n# #convert into binary values\n# for i in range(0,89951):\n#     if y_pred[i]>=.5:       # setting threshold to .5\n#        y_pred[i]=1\n#     else:  \n#        y_pred[i]=0\n\nfolds = StratifiedKFold(n_splits=10)\noof_preds = np.zeros(x_train.shape[0])\nsub_preds = np.zeros(x_test.shape[0])\n\nmodel = lgb.LGBMRegressor(**params, n_estimators=100000)\nmodel.fit(x_train, y_train, eval_set=[(x_test,y_test)], early_stopping_rounds=3000, verbose=1000)\n\n# oof_preds[val_] = model.predict(x_test,num_iteration=model.best_iteration_)\nsub_preds += model.predict(x_test, num_iteration=model.best_iteration_)\nnp.max(sub_preds)\nfor i in range(0,89951):\n    if sub_preds[i]>=.5:       # setting threshold to .5\n       sub_preds[i]=1\n    else:  \n        sub_preds[i]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"900bffa49251fb84a46d0d7647ff8f1a1e1c00f3"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, sub_preds)\ncm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3344a0e779eedbdc6f74cfa16ff5c9828f41792a"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,precision_score,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\naccuracy=accuracy_score(sub_preds,y_test)\nprecision = precision_score(sub_preds,y_test)\nrecall = recall_score(sub_preds,y_test)\naccuracy,precision,recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c51e235f97cb108b54b020393a3fa6b4a349311"},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nID_code = test_dataset[\"ID_code\"]\nTEST = pd.DataFrame(data = test_dataset,columns = list_sel)\n\nscaled_TEST = scaler.fit_transform(TEST)\nscaled_TEST = pd.DataFrame(data = scaled_TEST,columns = list_sel)\nprediction = np.zeros(scaled_TEST.shape[0])\nprint(scaled_TEST.head())\nprediction += model.predict(scaled_TEST,num_iteration=model.best_iteration_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1022489d4c8182208abde9c5af19f41fd3bad8aa"},"cell_type":"code","source":"#submission\nsubmission = pd.DataFrame({'ID_code' : ID_code,\n                            'target' : prediction})\nsubmission['target'] = submission['target'].apply(lambda x : 1 if x > 0.5 else 0)\nsubmission.to_csv('./version2.csv', index=False)\nsub = pd.read_csv('./version2.csv')\nsub['target'].unique()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}