{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVR\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, scale\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\nsubmit_data = pd.read_csv('../input/sample_submission.csv')\nprint(\"Data Loaded\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data = train_data.head(100)\n#test_data = test_data.head(100)\nK = 600","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train_data['target']\ntar = train_data['target']\n\nfeatures = [c for c in train_data.columns if c not in ['ID_code', 'target']]\n\nprint (\"Data is ready!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop([\"ID_code\"], axis=1)\ntest_data = test_data.drop([\"ID_code\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target0 = train_data[target==0]\ntarget1 = train_data[target==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,199):\n    ch = 'var_' + str(i)\n    target0[ch] = np.random.permutation(target0[ch])\nfor i in range(0,199):\n    ch = 'var_' + str(i)\n    target1[ch] = np.random.permutation(target1[ch])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target0 = target0.append(target1)\ntrain_data = train_data.append(target0)\ntrain_data = train_data.sample(frac=1)\ntarget = train_data['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop([\"target\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = train_data.shape[0]\ntest_size = test_data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge Train Test Data\ntrain_test = train_data\ntrain_test = train_test.append(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_test = pd.DataFrame(scale(train_test.values), columns=train_test.columns, index=train_test.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clustering\nkmeans = KMeans(n_clusters=K)\nkmeans.fit(train_test)\n\ntrain_test['k_labels'] = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Some Weights to the Labels \ntemp_df = train_test['k_labels']\ntrain_test['weight1'] = temp_df.apply(lambda x: x*3)\ntrain_test['weight2'] = temp_df.apply(lambda x: x*7)\ntrain_test['weight3'] = temp_df.apply(lambda x: x*11)\ntrain_test['weight4'] = temp_df.apply(lambda x: x*5)\ntrain_test['weight5'] = temp_df.apply(lambda x: x*13)\n\ntrain_test['weight6'] = temp_df.apply(lambda x: x*17)\ntrain_test['weight7'] = temp_df.apply(lambda x: x*19)\ntrain_test['weight8'] = temp_df.apply(lambda x: x*23)\ntrain_test['weight9'] = temp_df.apply(lambda x: x*29)\ntrain_test['weight10'] = temp_df.apply(lambda x: x*31)\n\ntrain_test['weight11'] = temp_df.apply(lambda x: x*37)\ntrain_test['weight12'] = temp_df.apply(lambda x: x*41)\ntrain_test['weight13'] = temp_df.apply(lambda x: x*43)\ntrain_test['weight14'] = temp_df.apply(lambda x: x*47)\ntrain_test['weight15'] = temp_df.apply(lambda x: x*53)\n\ntrain_test['weight16'] = temp_df.apply(lambda x: x*59)\ntrain_test['weight17'] = temp_df.apply(lambda x: x*61)\ntrain_test['weight18'] = temp_df.apply(lambda x: x*67)\ntrain_test['weight19'] = temp_df.apply(lambda x: x*71)\ntrain_test['weight20'] = temp_df.apply(lambda x: x*73)\n\ntrain_test.head(2)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_count = pd.Series()\nfor i in range(0,K):\n    #print(i , \" \" , train_test.loc[train_test['k_labels']==i].shape[0])\n    temp = (train_test.loc[train_test['k_labels']==i].shape[0])\n    cluster_count = cluster_count.append(pd.Series(temp))\n\nclusterCountVal = pd.DataFrame()\nclusterCountVal = cluster_count.to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusterCountVal.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_test[:train_size]\ntest_data = train_test[train_size:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {}\nparams['bagging_freq'] = 5 #reducing it as smaller freq & frac reduce overfitting \nparams['bagging_fraction'] = 0.0331\nparams['random_state'] = 42\nparams['learning_rate'] = 0.0123\nparams['boost_from_average'] = False\nparams['boosting_type'] = 'gbdt'\nparams['feature_fraction'] = 0.045\nparams['objective'] = 'binary'\nparams['metric'] = 'auc'\nparams['min_data_in_leaf'] = 80\nparams['num_leaves'] = 13\nparams['num_threads'] = 8\nparams['tree_learner'] = 'serial'\nparams['max_depth'] = -1\nparams['min_sum_hessian_in_leaf'] = 10.0\nparams['verbosity'] =  1\nparams['bagging_seed'] = 42\nparams['seed'] = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_folds = 10\nfeatures = [c for c in test_data.columns if c not in ['ID_code', 'target']]\n#print(features)\nfolds = StratifiedKFold(n_splits=num_folds,shuffle=True, random_state=42)\noof = np.zeros(len(train_data))\ngetVal = np.zeros(len(train_data))\npredictions = np.zeros(len(tar))\nprint(predictions.shape)\nfeature_importance_df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data.values, target.values)):\n    \n    X_train, y_train = train_data.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_valid, y_valid = train_data.iloc[val_idx][features], target.iloc[val_idx]\n    \n    X_tr, y_tr = X_train.values, y_train.values\n    X_tr = pd.DataFrame(X_tr)\n    \n    print(\"Fold idx:{}\".format(fold_ + 1))\n    trn_data = lgb.Dataset(X_tr, label=y_tr)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    \n    clf = lgb.train(params, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n  \n    predictions += clf.predict(test_data[features], num_iteration=clf.best_iteration) / folds.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_data['target'] = pd.DataFrame(predictions)\nsubmit_data.to_csv(\"LGBMwithClustering.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}