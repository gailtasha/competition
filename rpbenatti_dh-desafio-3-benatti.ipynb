{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SANTANDER CUSTOMER TRANSACTION PREDICTION\n\n## Entendendo o Problema\n\nAt Santander our mission is to help people and businesses prosper. We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals.\n\nOur data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?\n\n**In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem.**\n\nRef.: https://www.kaggle.com/c/santander-customer-transaction-prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando as bibliotecas\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport statsmodels.api as sm\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pegando os Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configurando opção para mostrar todas as colunas do dataset\npd.set_option(\"display.max_columns\", None)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Lendo e verificando os dados de treino e de teste\ndf_train = pd.read_csv(r'/kaggle/input/santander-customer-transaction-prediction/train.csv')\ndf_test = pd.read_csv(r'/kaggle/input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processamento dos Dados"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tratando os nulos"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusão:** não existem valores nulos nos datasets."},{"metadata":{},"cell_type":"markdown","source":"### Procurando por observações duplicadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.duplicated().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.duplicated().value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusão:** não existem valores duplicados nos datasets."},{"metadata":{},"cell_type":"markdown","source":"### Verificando as distribuições das variáveis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.iloc[:,2:102].hist(figsize = (20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.iloc[:,102:202].hist(figsize = (20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.iloc[:,1:101].hist(figsize = (20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.iloc[:,101:201].hist(figsize = (20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\nskewed_feats = df_train.iloc[:,2:].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nAssimetria: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\nskewed_feats = df_test.iloc[:,1:].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nAssimetria: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusão:** as variáveis explicativas apresentam distribuições normais."},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)"},{"metadata":{},"cell_type":"markdown","source":"### Verificando as correlações e plotando um HeatMap"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as correlações no Dataset de Treino\ndf_train_corr = df_train.corr()\ndf_train_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as correlações no Dataset de Teste\ndf_test_corr = df_test.corr()\ndf_test_corr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusão:** As variáveis possuem fraca correlação entre si."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identificando as 10 variáveis que mais estão positivamente correlacionadas com o target\ndf_train_most_pos_corr = df_train_corr.nlargest(11, 'target')['target']\n# Identificando as 10 variáveis que mais estão negativamente correlacionadas com o target\ndf_train_most_neg_corr = df_train_corr.nsmallest(10, 'target')['target']\n# Concatenando as 20 variáveis\ndf_train_most_corr = pd.concat([df_train_most_pos_corr,df_train_most_neg_corr])\ndf_train_most_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando um mapa de calor com as 20 variáveis mais correlacionadas (10+ positivamente e 10+ negativamente)\ncols = df_train_most_corr.index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.15)\nf, ax = plt.subplots(figsize=(20, 20))\nhm = sns.heatmap(cm, \n                 cbar=True, \n                 annot=True, \n                 square=True, \n                 fmt='.2f', \n                 annot_kws={'size': 10}, \n                 yticklabels=cols.values, \n                 xticklabels=cols.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotando um Pair-Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando o PAIPLOT para as variáveis mais correlacionadas com um sample (100 amostras)\nsample = df_train[cols].sample(100)\nsns.pairplot(sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pelo resultado do pair-plot, não é possivel identificar nenhum agrupamento ou linearidade entre as variáveis.\n\nAlém disso, os histogramas da diagonal mostram novamente que as variáveis se aproximam de distribuições normais."},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance - Variancethreshold"},{"metadata":{},"cell_type":"markdown","source":"***\"This method removes features with variation below a certain cutoff.\nThe idea is when a feature doesn’t vary much within itself, it generally has very little predictive power.***\n\n***Variance Threshold doesn’t consider the relationship of features with the target variable.***\n\nRef.: https://towardsdatascience.com/why-how-and-when-to-apply-feature-selection-e9c69adfabf2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nselector = VarianceThreshold(20.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realizando Feature Selection das variáveis de Treino\nselected_trainX = selector.fit_transform(df_train.drop(['ID_code','target'], axis=1))\nselected_trainX = pd.DataFrame(selected_trainX)\nselected_trainX.rename(columns=('var_' + pd.Series(selector.get_support(indices=True)).astype(str)), inplace=True)\nselected_trainX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realizando Feature Selection das variáveis de Teste\nselected_testX = selector.fit_transform(df_test.drop(['ID_code'], axis=1))\nselected_testX = pd.DataFrame(selected_testX)\nselected_testX.rename(columns=('var_' + pd.Series(selector.get_support(indices=True)).astype(str)), inplace=True)\nselected_testX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(selected_trainX.shape, selected_testX.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Padronizando os Dados"},{"metadata":{},"cell_type":"markdown","source":"Transformando os dados através de uma operação de \"scaling\".\n\nDesta forma será possível realizar a comparação entre os resultados, pois os cálculos de alguns modelos são baseados em distâncias e portanto os dados precisam estar padronizados."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Padronizando os dados de Treino com Standard Scaler\nscaled_trainX = scaler.fit_transform(selected_trainX)\nscaled_trainX = pd.DataFrame(scaled_trainX)\nscaled_trainX.columns = selected_trainX.columns\nscaled_trainX.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nota:\n\nApós a padronização, o desvio padrão (std) das variáveis deve ser igual a 1.0 e a média (mean) deve ser igual a 0.0, o que pode ser confirmado no comando describe acima."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Padronizando os dados de Teste com Standard Scaler\nscaled_testX = scaler.fit_transform(selected_testX)\nscaled_testX = pd.DataFrame(scaled_testX)\nscaled_testX.columns = selected_testX.columns\nscaled_testX.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nota:\n\nApós a padronização, o desvio padrão (std) das variáveis deve ser igual a 1.0 e a média (mean) deve ser igual a 0.0, o que pode ser confirmado no comando describe acima."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scaled_trainX.shape, scaled_testX.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train = pd.concat([df_train.target, scaled_trainX], axis=1)\nscaled_trainY = scaled_train.target\nscaled_trainY.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nota:\n    \nO dataset de Test não inclui a variável target, pois é ela que queremos prever.\n\nSendo assim, vamos considerar que scaled_test = scaled_testX"},{"metadata":{},"cell_type":"markdown","source":"### Balaceamento do Dataset de Treino"},{"metadata":{},"cell_type":"markdown","source":"De acordo com os resultados, a quantidade de dados obtidos para a variável target mostra um dataset não balanceado.\n\nPara corrigir este desbalanceamento, utilizada a técnica de oversampling.\n\nRef.: https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Resample the minority class.\nsmt = SMOTE(sampling_strategy='minority', random_state=42)\n\n# Fit the model to generate the data.\n%time oversampled_trainX, oversampled_trainY = smt.fit_sample(scaled_trainX, scaled_trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversampled_trainX = pd.DataFrame(oversampled_trainX, columns=scaled_trainX.columns.values)\noversampled_trainY = pd.DataFrame(oversampled_trainY, columns=pd.DataFrame(scaled_trainY).columns.values)\noversampled_train = pd.concat([oversampled_trainY, oversampled_trainX], axis=1)\noversampled_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversampled_train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O resultado acima mostra que o DataFrame agora está balanceado e podemos prosseguir na análise."},{"metadata":{},"cell_type":"markdown","source":"### Plotando um HeatMap após o Balaceamento"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as correlações no Dataset de Treino após o Balanceamento\noversampled_train_corr = oversampled_train.corr()\noversampled_train_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identificando as 10 variáveis que mais estão positivamente correlacionadas com o target\noversampled_train_most_pos_corr = oversampled_train_corr.nlargest(11, 'target')['target']\n# Identificando as 10 variáveis que mais estão negativamente correlacionadas com o target\noversampled_train_most_neg_corr = oversampled_train_corr.nsmallest(10, 'target')['target']\n# Concatenando as 20 variáveis\noversampled_train_most_corr = pd.concat([oversampled_train_most_pos_corr,oversampled_train_most_neg_corr])\noversampled_train_most_corr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nota: o resultado acima mostra que houve uma pequena melhora nas correlações após realizar o balanceamento."},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering (F.E)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for x in oversampled_train.var_0.unique():\n#     temp = oversampled_train[oversampled_train.var_0==x]\n# #    print(x,temp['price'].mean())\n\n# # Criação de um DataFrame para o tamanho médio das casas para cada ZIP CODE\n# # Aproveitando o tamanho médio das casas com mesmo ZIP CODE\n# df_zip = df.groupby(['zip']).agg({'size_house':'mean'})\n# df_zip.shape\n\n# # Fazendo uma merge dos dois DataFrames para capturar o tamanho médio das casas por ZIP CODE em pandas\n# df = pd.merge(df, df_zip, how='inner', left_on='zip', right_index=True)\n\n# data['Destination'].unique()\n# data['Destination'] = np.where(data['Destination']=='Delhi','New Delhi', data['Destination'])\n\n# df_train['var_0'].unique()\n# df_train['var_0_c'] = np.where(df_train['var_0']=='Delhi','New Delhi', data['Destination'])\n\n# df_train['var_0_c'] = [df_train['var_0'].value_counts().head(20)\n\n# pd.Series(df_train['var_0'].unique()).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rodando os modelos de Machine Learning"},{"metadata":{},"cell_type":"markdown","source":"Rodando uma primeira regressão do tipo Logística como Benchmark"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definindo as variáveis explicativas e a variável target para o dataframe original\nX = df_train.drop(['ID_code','target'], axis=1)\ny = df_train.target\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rodando uma regressão logística com statsmodel para os dados originais para efeito de comparação\nlr = sm.Logit(y, X)        # instanciando o modelo\nresult = lr.fit()          # ajustando o modelo\nprint(result.summary2())   # imprimindo o resumo dos resultados","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definindo as variáveis explicativas e a variável target para o dataframe balanceado e reduzido via feature selection\nX = oversampled_trainX\ny = oversampled_trainY\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rodando a regressão logística via statsmodel\nlr = sm.Logit(y, X)        # instanciando o modelo\nresult = lr.fit()          # ajustando o modelo\nprint(result.summary2())   # imprimindo o resumo dos resultados","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusão:** o resultado para os dados balanceados e reduzidos via feature selection produziu um R quadrado mais baixo, porém pode ajudar a não overfitar o modelo."},{"metadata":{},"cell_type":"markdown","source":" ### Separando os dados do Dataset de Treino via \"train_test_split\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando em dados de treino e teste - 80/20\nX_train, X_test, y_train, y_test = train_test_split(oversampled_trainX, oversampled_trainY, test_size=0.2, random_state=42, stratify=oversampled_trainY)\ny_train = pd.Series.ravel(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rodando uma regressão logística com o pacote sklearn\nlr = LogisticRegression(solver='liblinear')   # instanciando o modelo\n%time lr.fit(X_train, y_train)                # ajustando o modelo\ny_pred = lr.predict(X_test)                   # calculando os preditos\nlr.score(X_test, y_test)                      # obtendo o score do modelo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculando a Matriz de Confusão\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imprimindo as métricas \nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotando a curva ROC\ny_pred_proba = lr.predict_proba(X_test)[::,1]\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\n\nplt.plot(fpr,tpr,label=\"Logistic Regression, auc=%0.2f\" % auc)\nplt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC)')\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como um primeiro resultado, o valor da área AUC da curva ROC foi de 0.77."},{"metadata":{"trusted":false},"cell_type":"markdown","source":"**Fazendo predições com outros modelos**"},{"metadata":{},"cell_type":"markdown","source":"Rodando outros modelos e medindo seus resultados, incluindo a curva ROC, a qual poderá nos ajudar a escolher qual o melhor modelo para a predição."},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\n# Definindo uma lista com todos os modelos\nclassifiers = [\n    GaussianNB(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier()]\n\n# Rotina para instanciar, predizer e medir os resultados de todos os modelos\nfor clf in classifiers:\n    start = time.time()\n    # instanciando o modelo\n    clf.fit(X_train, y_train)\n    # armazenando o nome do modelo na variável name\n    name = clf.__class__.__name__\n    # imprimindo o nome do modelo\n    print(\"=\"*30)\n    print(name)\n    # imprimindo os resultados do modelo\n    print('****Results****')\n    y_pred = clf.predict(X_test)\n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(\"Precision:\", precision_score(y_test, y_pred))\n    print(\"Recall:\", recall_score(y_test, y_pred))\n    \n    # Plotando a curva ROC\n    y_pred_proba = clf.predict_proba(X_test)[::,1]\n    fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n    auc = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=name+\", auc=\"+str(auc))\n    plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n    plt.legend(loc=4)\n    \n    end = time.time()\n    print('****Elapsed time to run:', end - start,'****')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observações:\n\nO algoritmo **Gaussian Naive Bayes** teve um bom resultado, pois suas premissas foram satisfeitas:\n\n- O requisito dos preditores é serem independentes. Vimos que as features possuem fraca correlação entre si no pair plot analisado com as 10 mais e 10 menos correlacionadas à variável target.\n- Quando os preditores assumem um valor contínuo e não são discretos, assumimos que esses valores são amostrados a partir de uma distribuição gaussiana.\n\nNota: **Bernoulli Naive Bayes** não faz sentido nesse caso, pois os preditores não são variáveis booleanas.\n\nOs classificadores **Decision Tree** e **Random Forest** precisariam ter os parâmetros otimizados, pois pode ser que estejam se ajustando demais ao modelo não sendo assim generalistas."},{"metadata":{},"cell_type":"markdown","source":"**Conclusão:**\n\nConsiderando que a avaliação para este desafio do Santander se baseia na AUC, os melhores resultados obtidos foram com os modelos:\n\n- **Gaussian Naive Bayes**\n- **Random Forest Classifier**\n\n\"Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\"\n\nRef.: https://www.kaggle.com/c/santander-customer-transaction-prediction/overview/evaluation"},{"metadata":{"trusted":false},"cell_type":"markdown","source":"## Avaliação do Modelo"},{"metadata":{"trusted":false},"cell_type":"markdown","source":"### Realizando Cross-validation\n\nUtilizando cross_val_score para validação e fine tune do modelo RandomForest.\n\n**cross_val_score** -> uses stratifield kfold by default"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_GNB = cross_val_score(GaussianNB(), X_train, y_train, cv=5)\n# scores_GNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_LR = cross_val_score(LogisticRegression(solver='liblinear'), X_train, y_train, cv=3)\n# scores_LR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_DT = cross_val_score(DecisionTreeClassifier(max_depth=10), X_train, y_train, cv=3)\n# scores_DT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_DT = cross_val_score(DecisionTreeClassifier(max_depth=20), X_train, y_train, cv=3)\n# scores_DT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_DT = cross_val_score(DecisionTreeClassifier(max_depth=40), X_train, y_train, cv=3)\n# scores_DT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_RF = cross_val_score(RandomForestClassifier(n_estimators=10), X_train, y_train, cv=3)\n# scores_RF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_RF = cross_val_score(RandomForestClassifier(n_estimators=20), X_train, y_train, cv=3)\n# scores_RF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %time scores_RF = cross_val_score(RandomForestClassifier(n_estimators=40), X_train, y_train, cv=3)\n# scores_RF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Não houve variação dos valores aumentando o folder (cv), o que é um bom resultado\n- DecisionTreeClassifier -> produz melhor resultado aumentando a profundidade\n- Random Forest classifier -> produz melhor resultado aumentando a quantidade de trees"},{"metadata":{},"cell_type":"markdown","source":"### Rodando os modelos para o dataset de Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando em dados de treino e teste - 80/20\nX_train, X_test, y_train, y_test = train_test_split(oversampled_trainX, oversampled_trainY, test_size=0.2, random_state=42, stratify=oversampled_trainY)\ny_train = pd.Series.ravel(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rodando a Regressão Logística"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instanciando o modelo\nlr = LogisticRegression(solver='liblinear')\n# ajustando o modelo\n%time lr.fit(X_train, y_train)\n# calculando os preditos para os dados de teste\ny_pred_lr = lr.predict(scaled_testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":" Rodando o algoritmo de Gaussian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instanciando o modelo\ngnb = GaussianNB()\n# ajustando o modelo com os dados de treino\n%time gnb.fit(X_train, y_train)\n# calculando os preditos para os dados de teste\ny_pred_gnb = gnb.predict(scaled_testX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rodando o classificador Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instanciando o modelo\nclf_tree = DecisionTreeClassifier()\n# ajustando o modelo com os dados de treino\n%time clf_tree.fit(X_train, y_train)\n# calculando os preditos para os dados de teste\ny_pred_tree = clf_tree.predict(scaled_testX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rodando o classificador Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instanciando o modelo\nclf_rf = RandomForestClassifier(n_estimators=40)\n# ajustando o modelo com os dados de treino\n%time clf_rf.fit(X_train, y_train)\n# calculando os preditos para os dados de teste\ny_pred_rf = clf_rf.predict(scaled_testX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Criando um arquivo de submissão no KAGGLE"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = y_pred_lr[0:200000]\nsubmission.to_csv('submission_lr.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = y_pred_gnb[0:200000]\nsubmission.to_csv('submission_gnb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = y_pred_tree[0:200000]\nsubmission.to_csv('submission_tree.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/santander-customer-transaction-prediction/sample_submission.csv')\nsubmission['target'] = y_pred_rf[0:200000]\nsubmission.to_csv('submission_rf.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados do Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}