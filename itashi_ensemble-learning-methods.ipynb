{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Importation des différentes librairies\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f58c13c1beab90e970fe07226bf40ca13d1711be"},"cell_type":"code","source":"# Chargement des données d'entraînement et de test en utilisant le chemin vers les différents fichiers\ntrain = pd.read_csv('../input/santander-customer-transaction-prediction/train.csv')\ntest = pd.read_csv('../input/santander-customer-transaction-prediction/test.csv')\nsample_submission=pd.read_csv(\"../input/santander-customer-transaction-prediction/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e289fc0ffb9231a1778808e39ffa560e18cca94"},"cell_type":"code","source":"# On extrait la variable cible et on enlève pour des raisons de simplicités la variable \"ID\"\nY_train = train.target              \ntrain.drop(['ID_code'], axis = 1, inplace = True) \ntest.drop(['ID_code'], axis = 1, inplace = True)\ntrain.drop(['target'], axis = 1, inplace = True) \ntrain = train.iloc[:, 1:].values.astype('float64')\ntest = test.iloc[:, 1:].values.astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c3b2023a32359959527c16767a8fe0251b72c57"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, \\\n    GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5185e4c64563978c89b1fef7d713339701c25b3"},"cell_type":"code","source":"# On peut récupérer le modèle directement qu'on a sauvegardé :) \nimport pickle\nwith open('../input/lgbm-model-saved/LGBM.pkl', 'rb') as input_file:\n    model_recupere = pickle.load(input_file)\n    input_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f4d8b26a6d514b95c0de02ece740f66f9757036"},"cell_type":"code","source":"model_recupere","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"371ed6d7e035c239a0f0fb7e1e090ccac9b1f142"},"cell_type":"code","source":"# On peut récupérer le modèle directement qu'on a sauvegardé :) \nimport pickle\nwith open('../input/lighgbm/lgb.pkl', 'rb') as input_file:\n    model_recupere2 = pickle.load(input_file)\n    input_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01b6f11a98e882963a6ab5340f5a840ac133b7d4"},"cell_type":"code","source":"model_recupere2.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bcc42b84f5cf725dfa5361025e4e34cb078300b"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(train,Y_train, random_state =1234 , test_size = 0.33) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fed30c491b3d60384ebe8df58429cd8bb61444a"},"cell_type":"code","source":"model_recupere2.fit(X_train, y_train)\n\nfpr, tpr, _ = roc_curve(y_test, model_recupere2.predict_proba(X_test)[:, 1])    \nfprs.append(fpr)\ntprs.append(tpr)\naucs.append(auc(fpr, tpr))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8715d0f66e0dd42fe2f31d240730ce7f6aa4917"},"cell_type":"code","source":"plt.figure(figsize=(9, 7))\nplt.plot([0, 1], [0, 1], 'k--')\n\nfor fpr, tpr, auc, name in zip(fprs, tprs, aucs, names):\n    plt.plot(fpr, tpr, label=name + ' (AUC=%.2f)' % auc, lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('Receiver operating characteristic', fontsize=18)\nplt.legend(loc=\"lower right\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a0b5545e9ca23464d31b5019f9ef41040587f35"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom catboost import CatBoostClassifier\nclass Ensemble(object):\n    def __init__(self, n_splits, stacker, base_models):\n        self.n_splits = n_splits\n        self.stacker = stacker\n        self.base_models = base_models\n        self.y_pred = np.empty([1,1])\n\n    def fit_predict(self, X, y, T):\n        X = np.array(X)\n        y = np.array(y)\n        T = np.array(T)\n\n        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n\n        S_train = np.zeros((X.shape[0], len(self.base_models)))\n        S_test = np.zeros((T.shape[0], len(self.base_models)))\n        for i, clf in enumerate(self.base_models):\n\n            S_test_i = np.zeros((T.shape[0], self.n_splits))\n\n            for j, (train_idx, test_idx) in enumerate(folds):\n                X_train = X[train_idx]\n                y_train = y[train_idx]\n                X_holdout = X[test_idx]\n#                y_holdout = y[test_idx]\n\n                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n                clf.fit(X_train, y_train)\n                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n                y_pred = clf.predict_proba(X_holdout)[:,1]                \n\n                S_train[test_idx, i] = y_pred\n                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n            S_test[:, i] = S_test_i.mean(axis=1)\n\n        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n        print(\"Stacker score: %.5f\" % (results.mean()))\n\n        self.stacker.fit(S_train, y)\n        self.y_pred = self.stacker.predict_proba(S_test)[:,1]\n        return self.y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e68b3690e0c331c6ebce705e5805b1b51e860a3"},"cell_type":"code","source":"# LightGBM params\n\nlgb_params2 = {}\nlgb_params2['n_estimators'] = 280\nlgb_params2['learning_rate'] = 0.1\nlgb_params2['colsample_bytree'] = 0.3   \nlgb_params2['subsample'] = 0.7\nlgb_params2['subsample_freq'] = 2\nlgb_params2['num_leaves'] = 16\nlgb_params2['random_state'] = 99\n\nparam1 = {\n    'num_leaves': 18,\n     'max_bin': 63,\n     'min_data_in_leaf': 5,\n     'learning_rate': 0.010614430970330217,\n     'min_sum_hessian_in_leaf': 0.0093586657313989123,\n     'feature_fraction': 0.056701788569420042,\n     'lambda_l1': 0.060222413158420585,\n     'lambda_l2': 4.6580550589317573,\n     'min_gain_to_split': 0.29588543202055562,\n     'max_depth': 49,\n     'save_binary': True,\n     'seed': 1337,\n     'feature_fraction_seed': 1337,\n     'bagging_seed': 1337,\n     'drop_seed': 1337,\n     'data_random_seed': 1337,\n     'objective': 'binary',\n     'boosting_type': 'gbdt',\n     'verbose': 1,\n     'metric': 'auc',\n     'is_unbalance': True,\n     'boost_from_average': False\n}\n    \n# paramètres optimaux qu'on avait obtenu du 1er modèle que j'avais pas sauvegardé mdrr !!! \ngb_params = {}\ngb_params['max_depth'] = 6\ngb_params['max_features'] = 4\ngb_params['min_samples_leaf'] = 4\ngb_params['min_samples_split'] = 8\ngb_params['n_estimators'] = 265","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8f4f5b6832d25bbb297876142ccc76e3c5a249e"},"cell_type":"code","source":"# Modelès qu'on va utiliser\n\nlgb_model1 = LGBMClassifier(**param1)\nlgb_model2 = LGBMClassifier(**lgb_params2)\nlgb_model3 = model_recupere.best_estimator_\ngb_model = GradientBoostingClassifier(**gb_params)\ncb_model = CatBoostClassifier(iterations=1000, loss_function='Logloss')\nlog_model = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9e723625f2d15e5633be0c977c209fa829ceec2"},"cell_type":"code","source":"stack = Ensemble(n_splits=3,\n        stacker = log_model,\n        base_models = (lgb_model2,lgb_model3,gb_model,cb_model,log_model\n                      ))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a740ce09bfce0beae1706be9a7942aabd8891cbf"},"cell_type":"code","source":"y_pred = stack.fit_predict(train, Y_train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75ceefd9e229c80286e6d346a4c0237941ab0551","_kg_hide-output":true},"cell_type":"code","source":"# On sauvegarde le modèle de méthodes d'ensemble\nimport pickle\nwith open('ensemble_learning2.pkl', 'wb') as output:\n    pickle.dump(stack, output, pickle.HIGHEST_PROTOCOL)\n    output.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"218a5960327cd7cdf4fd4c09f08cfc21097e86b0"},"cell_type":"code","source":"# On ouvre le modèle récupéré !\nimport pickle\nwith open('ensemble_learning2.pkl', 'rb') as input_file:\n    stack = pickle.load(input_file)\n    input_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46df5969a0599888935997c50529c5fc2558a33d"},"cell_type":"code","source":"clf.fit(X_train, y_train)\n\n    fpr, tpr, _ = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])    \n    fprs.append(fpr)\n    tprs.append(tpr)\n    aucs.append(auc(fpr, tpr))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a6017ceb4370455ed7ff339e30385df5daf255c"},"cell_type":"code","source":"# c'est complètement bidon ce que je fais puisque là je fais une validation\n# avec les y_pred que j'ai prédit avec les données de test et le Y_train du modèle d'apprentissage\n# ce qui en fait n'a aucun sens d'où mon résultat médiocre mdrrr !!! j'ai paniqué pour rien Lol :) \n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(Y_train, stack.y_pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label=\"LR (AUC=%.6f)\" % roc_auc, lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('Receiver operating characteristic', fontsize=18)\nplt.legend(loc=\"lower right\", fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfea4eac398a53832bc0b0579affd10b092b7d8e"},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, average_precision_score\nprecision, recall, _ = precision_recall_curve(Y_train, stack.y_pred)\n\nplt.step(recall, precision, color='b', alpha=0.2,\n         where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2,\n                 color='b')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\naverage_precision = average_precision_score(Y_train, stack.y_pred)\nplt.title('2-class Precision-Recall curve: AP={0:0.6f}'.format(\n          average_precision))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"756924fd006a1dde2ed32257bb11df6d0cd25ad5"},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49221a8fb83847b71e4dc8dabab4ce597e2dcea9"},"cell_type":"code","source":"stack.y_pred","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"d954bcf9bc7e20dc9015b0612cdcc277c7a5aed9"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['ID_code'] = sample_submission.ID_code\nsub['target'] = y_pred\nsub.to_csv('stacked_2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f4d423f36154e66f1e4a9ada5ddb4450f9ceedf"},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34091e17c131fe87504cb0941af4eb238a0f2949"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}