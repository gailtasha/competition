{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom scipy.stats import spearmanr\nimport seaborn as sns\nsns.set_style()\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost  import XGBClassifier\nfrom sklearn.naive_bayes import ComplementNB,BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nimport lightgbm as lgb\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\nt_d = test_data.copy()\ntest_data.drop(columns=['ID_code'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution of targets\ncolors = ['lightgreen','maroon']\nplt.figure(figsize=(6,6))\nplt.pie(data[\"target\"].value_counts(), explode=(0, 0.25), labels= [\"0\", \"1\"], startangle=45, autopct='%1.1f%%', colors=colors)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = data.copy()\nY = all_data['target']\nall_data.drop(columns=['target','ID_code'],inplace=True)\nX = all_data.loc[:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Creating new Features\ndef creating_features(X):\n    square_df = X.apply(lambda a:a**2)\n    cube_df =X.apply(lambda x:x**3)\n    four_df = X.apply(lambda x:x**4)\n    five_df = X.apply(lambda x:x**5)\n    b = pd.concat([X,square_df,cube_df,four_df,five_df],axis=1)\n    # cube_root = X.apply(lambda x:x**1/3)\n    return b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(data):\n    ## fitting it on whole data first\n    X = preprocessing.normalize(data)\n    X = preprocessing.scale(X)\n    # X_data_pca = preprocessing.normalize(X_data_pca)\n    # X_data_pca = preprocessing.scale(X_data_pca)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pca_obj(data,n):\n    pca_obj_1 = PCA(n_components=n)\n    X = pca_obj_1.fit_transform(data)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = creating_features(X)\nX = preprocess(X)\n# X_pca_data = pca_obj(X)\n# X_pca_data = preprocess(X_pca_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data = creating_features(test_data)\ntest_data = preprocess(test_data)\n# test_data_pca=pca_obj(test_data)\n# test_data_pca = preprocess(test_data_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df = pd.DataFrame(X)\n# X_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state=32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_1 = pd.concat([X_df,Y],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=random_state)\noof = data[['ID_code', 'target']]\noof['predict'] = 0\npredictions = t_d[['ID_code']]\nval_aucs = []\nfeature_importance = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [col for col in data.columns if col not in ['target', 'ID_code']]\nX_test = test_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model parameters\nlgb_params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"boosting\": 'gbdt',\n    \"max_depth\" : -1,\n    \"num_leaves\" : 31,\n    \"learning_rate\" : 0.01,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\" : 0.4,\n    \"feature_fraction\" : 0.05,\n    \"min_data_in_leaf\": 150,\n    \"min_sum_heassian_in_leaf\": 10,\n    \"tree_learner\": \"serial\",\n    \"boost_from_average\": \"false\",\n    \"bagging_seed\" : random_state,\n    \"verbosity\" : 1,\n    \"seed\": random_state}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold, (trn_idx, val_idx) in enumerate(skf.split(Y,Y)):\n    X_train, y_train = X[trn_idx, :], Y[trn_idx]\n    X_valid, y_valid = X[val_idx, :], Y[val_idx]\n    \n    N = 3\n    p_valid,yp = 0,0\n    for i in range(N):\n        X_t, y_t = augment(X_train, y_train)\n        X_t = pd.DataFrame(X_t)\n        X_t = X_t.add_prefix('var_')\n    \n        trn_data = lgb.Dataset(X_t, label=y_t)\n        val_data = lgb.Dataset(X_valid, label=y_valid)\n        evals_result = {}\n        lgb_clf = lgb.train(lgb_params,\n                        trn_data,\n                        100000,\n                        valid_sets = [trn_data, val_data],\n                        early_stopping_rounds=3000,\n                        verbose_eval = 1000,\n                        evals_result=evals_result\n                       )\n        p_valid += lgb_clf.predict(X_valid)\n        yp += lgb_clf.predict(X_test)\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = features\n    fold_importance[\"importance\"] = lgb_clf.feature_importance()\n    fold_importance[\"fold\"] = fold + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n    oof['predict'][val_idx] = p_valid/N\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    \n    predictions['fold{}'.format(fold+1)] = yp/N","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('lgb_all_predictions.csv', index=None)\nsub = pd.DataFrame({\"ID_code\":test[\"ID_code\"].values})\nsub[\"target\"] = predictions['target']\nsub.to_csv(\"lgb_submission.csv\", index=False)\noof.to_csv('lgb_oof.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}