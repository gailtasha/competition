{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Solution:\n\n- Implements a really simple CNN arquitecture \n- Train it with 400 columns (Original 200 vars + 200 columns of counts)\n- Data augmentation (Each epoch is feed with different data) \n- Got 0.922 in private LB \n- Using cyclic learning rate to train the CNN"},{"metadata":{},"cell_type":"markdown","source":"# Download and import packages\nDownload keras-contrib for CyclicLR and santander_helper for auc metric and custom Datagenerator"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"! pip install git+https://www.github.com/keras-team/keras-contrib.git\n! wget https://github.com/jganzabal/santander_kaggle_solutions_tests/raw/master/santander_helper.py","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting git+https://www.github.com/keras-team/keras-contrib.git\n  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-2xwwr2oc\nRequirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /opt/conda/lib/python3.6/site-packages\nRequirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from keras-contrib==2.0.8) (2.2.4)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (3.12)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.1.0)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.12.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.16.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (2.9.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.9)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.7)\nBuilding wheels for collected packages: keras-contrib\n  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-rte_h1vd/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\nSuccessfully built keras-contrib\n\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n--2019-05-03 19:49:19--  https://github.com/jganzabal/santander_kaggle_solutions_tests/raw/master/santander_helper.py\nResolving github.com (github.com)... 192.30.255.113\nConnecting to github.com (github.com)|192.30.255.113|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/jganzabal/santander_kaggle_solutions_tests/master/santander_helper.py [following]\n--2019-05-03 19:49:19--  https://raw.githubusercontent.com/jganzabal/santander_kaggle_solutions_tests/master/santander_helper.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3336 (3.3K) [text/plain]\nSaving to: ‘santander_helper.py.2’\n\nsantander_helper.py 100%[===================>]   3.26K  --.-KB/s    in 0s      \n\n2019-05-03 19:49:19 (46.9 MB/s) - ‘santander_helper.py.2’ saved [3336/3336]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from santander_helper import auc, DataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, Flatten\nfrom keras.optimizers import Adam\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom keras_contrib.callbacks import CyclicLR\nimport warnings\nimport gc\nwarnings.filterwarnings(\"ignore\")","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"> # Divide fake from real:\n\nThis is taken from https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# GET INDICIES OF REAL TEST DATA FOR FE\n#######################\n# TAKE FROM YAG320'S KERNEL\n# https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split\n\ntest_path = '../input/test.csv'\ntrain_path = '../input/train.csv'\n\ndf_test = pd.read_csv(test_path)\ndf_test.drop(['ID_code'], axis=1, inplace=True)\ndf_test = df_test.values\n\nunique_samples = []\nunique_count = np.zeros_like(df_test)\nfor feature in range(df_test.shape[1]):\n    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n    unique_count[index_[count_ == 1], feature] += 1\n\n# Samples which have unique values are real the others are fake\nreal_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\nsynthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n\nprint('Found',len(real_samples_indexes),'real test')\nprint('Found',len(synthetic_samples_indexes),'fake test')\n\n###################\n\nd = {}\nfor i in range(200): d['var_'+str(i)] = 'float32'\nd['target'] = 'uint8'\nd['ID_code'] = 'object'\n\ntrain = pd.read_csv('../input/train.csv', dtype=d)\ntest = pd.read_csv('../input/test.csv', dtype=d)\n\nprint('Loaded',len(train),'rows of train')\nprint('Loaded',len(test),'rows of test')\nprint('Found',len(real_samples_indexes),'real test')\nprint('Found',len(synthetic_samples_indexes),'fake test')\n\n###################\n\nd = {}\nfor i in range(200): d['var_'+str(i)] = 'float32'\nd['target'] = 'uint8'\nd['ID_code'] = 'object'\n\ntrain = pd.read_csv(train_path, dtype=d)\ntest = pd.read_csv(test_path, dtype=d)\n\nprint('Loaded',len(train),'rows of train')\nprint('Loaded',len(test),'rows of test')","execution_count":3,"outputs":[{"output_type":"stream","text":"Found 100000 real test\nFound 100000 fake test\nLoaded 200000 rows of train\nLoaded 200000 rows of test\nFound 100000 real test\nFound 100000 fake test\nLoaded 200000 rows of train\nLoaded 200000 rows of test\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Add counts to each of the 200 vars\nThis is taken from https://www.kaggle.com/cdeotte/200-magical-models-santander-0-920/comments, a must read kernel from @cdeotte"},{"metadata":{"trusted":true},"cell_type":"code","source":"# FREQUENCY ENCODE\ndef encode_FE(df,col,test):\n    cv = df[col].value_counts()\n    nm = col+'_FE'\n    df[nm] = df[col].map(cv)\n    test[nm] = test[col].map(cv)\n    test[nm].fillna(0,inplace=True)\n    if cv.max()<=255:\n        df[nm] = df[nm].astype('uint8')\n        test[nm] = test[nm].astype('uint8')\n    else:\n        df[nm] = df[nm].astype('uint16')\n        test[nm] = test[nm].astype('uint16')        \n    return\n\ntest['target'] = -1\ncomb = pd.concat([train,test.loc[real_samples_indexes]],axis=0,sort=True)\nfor i in range(200): \n    encode_FE(comb,'var_'+str(i),test)\ntrain = comb[:len(train)]; del comb\nprint('Added 200 new magic features!')","execution_count":4,"outputs":[{"output_type":"stream","text":"Added 200 new magic features!\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"del df_test, real_samples_indexes, synthetic_samples_indexes, unique_count, unique_samples, d\ngc.collect()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"259"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Load and prepare data for CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data with counts saved in the previous cells\ndf_train_data = train.drop(columns=['ID_code'])\ny = df_train_data['target'].values\ndf_train_X = df_train_data.drop(columns=['target'])","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is taken from https://www.kaggle.com/sibmike/are-vars-mixed-up-time-intervals.\nReally can't justify it from a theoretical point of view but it improoves a bit the private score. Any ideas will be welcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_columns = True\nif reverse_columns:\n    reverse_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 15, 16, 18, 19, 22, 24, 25, 26,\n                    27, 29, 32, 35, 37, 40, 41, 47, 48, 49, 51, 52, 53, 55, 60, 61,\n                    62, 65, 66, 67, 69, 70, 71, 74, 78, 79, 82, 84, 89, 90, 91, 94,\n                    95, 96, 97, 99, 103, 105, 106, 110, 111, 112, 118, 119, 125, 128,\n                    130, 133, 134, 135, 137, 138, 140, 144, 145, 147, 151, 155, 157,\n                    159, 161, 162, 163, 164, 167, 168, 170, 171, 173, 175, 176, 179,\n                    180, 181, 184, 185, 187, 189, 190, 191, 195, 196, 199,\n                    ]\n\n    for j in reverse_list:\n        df_train_X[f'var_{j}'] *= -1","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize data\nmeans = df_train_X.mean(axis=0)\nstds = df_train_X.std(axis=0)\ndf_train_X_normalized = (df_train_X - means)/stds","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for CNN\nX_train_normalized = np.zeros((df_train_X_normalized.shape[0], 400, 1))\nfor i in range(200):\n    X_train_normalized[:, 2*i] = df_train_X_normalized[[f'var_{i}']].values #[indexes]\n    X_train_normalized[:, 2*i+1] = df_train_X_normalized[[f'var_{i}_FE']].values #[indexes]","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model\ndef get_model(N_units = 600, kernel_size=2, strides=2):\n    model = Sequential()\n    model.add(Conv1D(N_units, kernel_size=kernel_size, strides=strides, padding='valid', \n                     activation='relu', input_shape=(X_train_normalized.shape[1], 1)))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    return model","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_model().summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_1 (Conv1D)            (None, 200, 600)          1800      \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 120000)            0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 120001    \n=================================================================\nTotal params: 121,801\nTrainable params: 121,801\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"del df_train_data, df_train_X\ngc.collect()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"55"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Train model"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"best_model_file_name = 'best_full_model_aux.hdf5'\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\npatience = 18\nepochs = 100\nbs = 512\nN_units = 600\ncommon_rows = 2\nclass_0_aug = 4\nclass_1_aug = 6\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df_train_X_normalized, y)):\n    print('###############################################')\n    print(f'##################Fold {fold}#######################')\n    print('###############################################')\n    model = get_model(N_units)\n    model.compile(Adam(), loss='binary_crossentropy', metrics=[auc, 'accuracy'])\n    es = EarlyStopping(monitor='val_auc', patience=patience, mode='max', verbose=1)\n    mc = ModelCheckpoint(best_model_file_name, monitor='val_auc', mode='max', verbose=1, save_best_only=True)\n \n    generator = DataGenerator(X_train_normalized[trn_idx], y[trn_idx], \n                              batch_size=bs, shuffle=True, \n                              class_1_aug=class_1_aug, \n                              class_0_aug=class_0_aug,\n                              common_rows = common_rows\n                             )\n    tr_iter_in_epoch = generator.__len__()\n#     gamma = 1 - 6e-05  * 4*312/tr_iter_in_epoch\n#     clr = CyclicLR(base_lr=0.0001, max_lr=0.005, step_size=4*tr_iter_in_epoch, mode='exp_range', gamma=gamma)\n    clr = CyclicLR(base_lr=0.0001, max_lr=0.005, step_size=4*tr_iter_in_epoch, mode='triangular2')\n    X_val_data, y_val_data = DataGenerator.augment(X_train_normalized[val_idx], \n                                     y[val_idx], class_1_aug=class_1_aug//2, class_0_aug=class_0_aug//2, common_rows = common_rows)\n    indexes_val = np.arange(len(y_val_data))\n    np.random.shuffle(indexes_val)\n    model.fit_generator(generator,\n              epochs=epochs,\n              verbose=2,\n              callbacks = [es, \n                           mc, \n                           clr],\n              validation_data=(X_val_data[indexes_val], y_val_data[indexes_val])\n                )\n    # print(f'Finish training with lr {lr}')\n    model = get_model()\n    # Load weights from ModelCheckpoint\n    model.load_weights(best_model_file_name)\n    # Save them to disk\n    model.save_weights(f'CNN_generator_fold_{fold}_cl1_{class_1_aug}_cl0_{class_0_aug}_{N_units}.hdf5')","execution_count":13,"outputs":[{"output_type":"stream","text":"###############################################\n##################Fold 0#######################\n###############################################\nEpoch 1/2\n - 27s - loss: 0.2746 - auc: 0.8757 - acc: 0.8920 - val_loss: 0.2466 - val_auc: 0.9013 - val_acc: 0.9039\n\nEpoch 00001: val_auc improved from -inf to 0.90131, saving model to best_full_model_aux.hdf5\nEpoch 2/2\n - 47s - loss: 0.2411 - auc: 0.9111 - acc: 0.9056 - val_loss: 0.2374 - val_auc: 0.9090 - val_acc: 0.9084\n\nEpoch 00002: val_auc improved from 0.90131 to 0.90897, saving model to best_full_model_aux.hdf5\n###############################################\n##################Fold 1#######################\n###############################################\nEpoch 1/2\n - 25s - loss: 0.2737 - auc: 0.8755 - acc: 0.8920 - val_loss: 0.2466 - val_auc: 0.9017 - val_acc: 0.9022\n\nEpoch 00001: val_auc improved from -inf to 0.90170, saving model to best_full_model_aux.hdf5\nEpoch 2/2\n - 46s - loss: 0.2399 - auc: 0.9118 - acc: 0.9061 - val_loss: 0.2357 - val_auc: 0.9113 - val_acc: 0.9074\n\nEpoch 00002: val_auc improved from 0.90170 to 0.91128, saving model to best_full_model_aux.hdf5\n###############################################\n##################Fold 2#######################\n###############################################\nEpoch 1/2\n - 26s - loss: 0.2763 - auc: 0.8740 - acc: 0.8909 - val_loss: 0.2437 - val_auc: 0.9058 - val_acc: 0.9051\n\nEpoch 00001: val_auc improved from -inf to 0.90576, saving model to best_full_model_aux.hdf5\nEpoch 2/2\n - 46s - loss: 0.2421 - auc: 0.9103 - acc: 0.9050 - val_loss: 0.2312 - val_auc: 0.9133 - val_acc: 0.9103\n\nEpoch 00002: val_auc improved from 0.90576 to 0.91325, saving model to best_full_model_aux.hdf5\n###############################################\n##################Fold 3#######################\n###############################################\nEpoch 1/2\n - 26s - loss: 0.2742 - auc: 0.8751 - acc: 0.8922 - val_loss: 0.2640 - val_auc: 0.9031 - val_acc: 0.8946\n\nEpoch 00001: val_auc improved from -inf to 0.90309, saving model to best_full_model_aux.hdf5\nEpoch 2/2\n - 46s - loss: 0.2412 - auc: 0.9108 - acc: 0.9053 - val_loss: 0.2341 - val_auc: 0.9118 - val_acc: 0.9079\n\nEpoch 00002: val_auc improved from 0.90309 to 0.91185, saving model to best_full_model_aux.hdf5\n###############################################\n##################Fold 4#######################\n###############################################\nEpoch 1/2\n - 26s - loss: 0.2734 - auc: 0.8759 - acc: 0.8926 - val_loss: 0.2635 - val_auc: 0.9027 - val_acc: 0.8977\n\nEpoch 00001: val_auc improved from -inf to 0.90272, saving model to best_full_model_aux.hdf5\nEpoch 2/2\n - 46s - loss: 0.2403 - auc: 0.9111 - acc: 0.9058 - val_loss: 0.2352 - val_auc: 0.9112 - val_acc: 0.9078\n\nEpoch 00002: val_auc improved from 0.90272 to 0.91123, saving model to best_full_model_aux.hdf5\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = test.drop(columns=['ID_code', 'target'])\nif reverse_columns:\n    for j in reverse_list:\n        df_test[f'var_{j}'] *= -1\ndf_test_X_normalized = (df_test - means)/stds","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_normalized = np.zeros((df_test_X_normalized.shape[0], 400, 1))\nfor i in range(200):\n    X_test_normalized[:, 2*i] = df_test_X_normalized[[f'var_{i}']].values\n    X_test_normalized[:, 2*i+1] = df_test_X_normalized[[f'var_{i}_FE']].values","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfull_val_preds = np.zeros((len(df_train_X_normalized), 1))\nmodel = get_model(N_units)\ntest_predictions = 0\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df_train_X_normalized, y)):\n    print('###############################################')\n    print(f'##################Fold {fold}#######################')\n    print('###############################################')\n    X_train = X_train_normalized[trn_idx]\n    X_val = X_train_normalized[val_idx]\n    filename = f'CNN_generator_fold_{fold}_cl1_{class_1_aug}_cl0_{class_0_aug}_{N_units}.hdf5'\n    model.load_weights(filename)\n    full_val_preds[val_idx] = model.predict(X_val, verbose=1)\n    print(roc_auc_score(y[val_idx], full_val_preds[val_idx]))\n    test_predictions = test_predictions + model.predict(X_test_normalized, verbose=1)/5","execution_count":16,"outputs":[{"output_type":"stream","text":"###############################################\n##################Fold 0#######################\n###############################################\n40001/40001 [==============================] - 3s 75us/step\n0.9113296459256205\n200000/200000 [==============================] - 14s 72us/step\n###############################################\n##################Fold 1#######################\n###############################################\n40001/40001 [==============================] - 3s 75us/step\n0.9096606957154418\n200000/200000 [==============================] - 15s 74us/step\n###############################################\n##################Fold 2#######################\n###############################################\n40000/40000 [==============================] - 3s 72us/step\n0.9156686550571211\n200000/200000 [==============================] - 15s 74us/step\n###############################################\n##################Fold 3#######################\n###############################################\n39999/39999 [==============================] - 3s 78us/step\n0.911913138827368\n200000/200000 [==============================] - 14s 72us/step\n###############################################\n##################Fold 4#######################\n###############################################\n39999/39999 [==============================] - 3s 72us/step\n0.9104977385766692\n200000/200000 [==============================] - 14s 72us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation ROC AUC\nroc_auc_score(y, full_val_preds)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"0.9103571445952121"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Test data - log odds distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n_ = plt.hist(np.log(test_predictions/(1-test_predictions)), 80)\nplt.title('Histogram of Log Odds in test')\nplt.xlabel('Log odds')\nplt.ylabel('Counts')\nplt.show()","execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Create submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_submit_file(predictions, filename, test_filename=test_path, index_column='ID_code', target_column = 'target'):\n    df_test_submit = pd.read_csv(test_filename).set_index(index_column)\n    df_test_submit[target_column] = predictions\n    df_test_submit[[target_column]].to_csv(filename)\n    return ","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_submit_file(test_predictions, \n                 f'submit_CNN_generator_cl1_{class_1_aug}_cl0_{class_0_aug}_{N_units}.csv')","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Discussions"},{"metadata":{},"cell_type":"markdown","source":"## Why CNN?\nThe intuition is to pick var_i and var_i_FE together with each filter, that is why the strides is 2 and the kernel size is 2. Each of the 600 filters will be applied to each pair (var_i, var_i_FE).\n\n## Where is the independence assumption with a CNN?\nThe problem with CNN is that it might try to find correlation between vars. To prevent this we use the **[Datagenerator](https://github.com/jganzabal/santander_kaggle_solutions_tests/blob/master/santander_helper.py)** that in each epoch it will shuffle al rows for each (var_i, var_i_FE) pairs. This idea is taken from this great kernel: https://www.kaggle.com/jesucristo/santander-magic-lgb-0-901\n\n## TODOs\n- Change hyperparameters\n- Add regularization (Dropout, L1, L2)\n- Change arquitecture\n- Add more feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}