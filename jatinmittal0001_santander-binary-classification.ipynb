{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Things I tried and few learnings:\n\n1) Hyper-parameter tuning is very important in this exercise, since there is nothing much that can be done on data processing part\n\n2) I tried PCA, undersampling and outlier treatment, but didn't give any significant improvement.\n\n3) I tried NN, Light GBM, Catboost, XGBoost models of which Light GBM and Catboost were top two. So I tried tuning their parameters using Bayesian optimization. \n* **Catboost:** Very few parameters of Catboost can be trained using Bayesian optimization due to internal creation of process. Without GPU, the run time was very large. SO I tried using GPU and only 3-4 params can be put in Bayesian optimization using that. It didn't give as good AUC as light GBM.\n* **Light GBM:** It can be run without GPU and run time is also less. Tried many hyper-parameters under tuning and got combination which gave 89.4 AUC score on validation data during hyp-param tuning. Number of estimators was one important param.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split,GridSearchCV  \nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom bayes_opt import BayesianOptimization\nfrom lightgbm import LGBMModel,LGBMClassifier\nfrom catboost import CatBoostClassifier\nimport gc \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"traindata = pd.read_csv(\"../input/train.csv\")\ntestdata = pd.read_csv(\"../input/test.csv\")\nprint(traindata.shape)\nprint(testdata.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cde73d239b739524418093141accddc982155372"},"cell_type":"code","source":"traindata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmaster_test_id = testdata['ID_code']\n\ntraindata.drop(['ID_code'],axis=1,inplace=True)\ntestdata.drop(['ID_code'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = traindata[traindata.target == 1].target.sum()\nprint('Percentage of target variables with label =1 is: ',a*100/traindata.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uni = (traindata.nunique()).sort_values()\nprint(uni)\n\n#here we see that there is no variable which is binary.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checked correlation for all but no luck\n\n'''\ncorrmat = traindata.iloc[:,1:199].corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checked for duplicated rows but no duplicates found\n\n'''\n\nsam = traindata.append(testdata,sort=False)\nsam.drop('target',axis=1,inplace=True)\n\ndf = sam[sam.duplicated()]  # checks duplicate rows considering all columns\ndf\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a13a07162e18b9e7afe4553d15d73f47a28ae637"},"cell_type":"code","source":"y_master_train = traindata['target']\n#traindata.drop(['target'],axis=1,inplace=True)\ntestdata['target'] = 'test_data'\ntotaldata = pd.concat([traindata, testdata])  #concatenation will automatically match columns and append\ntotaldata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"totaldata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e242c7f084f2648f6bca3fc1833b8925bff4bac"},"cell_type":"code","source":"y_master_train.value_counts(normalize=True)   #checking proportion of different ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6bb4390380ed472fee8c150b43c8714ee178ef3"},"cell_type":"code","source":"#Plotting boxplots of 5 variables\nm=1\nplt.figure(figsize = (20,20))\nfor i in totaldata.columns[1:6]:\n    plt.subplot(3,4,m)\n    sns.boxplot(totaldata[i])\n    m = m+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56f367fc9984f3d3cd68e7503c7fed9ed9b94e68"},"cell_type":"code","source":"a=list(totaldata.columns)\na.remove(\"target\")\n\ndef outlier_treatment(data,cols):\n    data_X = data.copy()\n    \n    for i in cols:\n        a = data_X[data_X['target']!='test_data'][i].quantile([0.25,0.75]).values  #doing only on train data\n        p_cap = a[1] + 1.5*(a[1]-a[0])\n        p_clip = a[0] - 1.5*(a[1]-a[0])\n        data_X[i][data_X[i] <= p_clip] = p_clip\n        data_X[i][data_X[i] >= p_cap] = p_cap\n    \n  \n    return data_X\n\n#totaldata = outlier_treatment(totaldata,a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"387acdd0e331ed5220f03eec529b322629ec184f"},"cell_type":"markdown","source":"Different variables have different scaling and are very slightly skewed. We wil apply transformation to variables having skewness > 0.75"},{"metadata":{"trusted":true,"_uuid":"5f10d4251d84a4bba43c7479ca969e4c1eeacf03"},"cell_type":"code","source":"from scipy.stats import skew\ndef skew_treatment(data):\n    data_X = data.copy()\n    #finding skewness of all variables\n    col = data_X.columns\n    skewed_feats = data_X[col].apply(lambda x: skew(x.dropna()))\n    #adjusting features having skewness >0.75\n    skewed_feats = skewed_feats[skewed_feats > 0.75]\n    skewed_feats = skewed_feats.index\n    data_X[skewed_feats] = np.log1p(data_X[skewed_feats])\n    \n    return data_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88ff396ac746800f83740b00603ad2e640b0d793"},"cell_type":"code","source":"#totaldata.iloc[:,1:] = skew_treatment(totaldata.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c0639aa23d7bcdbfdc11cf6306e5d278de9b524"},"cell_type":"markdown","source":"I tried both oversampling and skewness treatment but the model was not performing any better so I am not using them in final code. It is written above if you want to try that piece of code."},{"metadata":{"_uuid":"186ce45eb1d93ac9ec2d3d16ebc3537a0b3209e3"},"cell_type":"markdown","source":"Now since the data is unbalanced, we can try oversampleing and undersampling:\n    1. Undersampling\nI  am not trying oversamling since the data is already huge, and oversamling will slow down the entire excecution."},{"metadata":{"trusted":true,"_uuid":"f43146e09f314450af4d591b9b8e98e28c503361"},"cell_type":"markdown","source":"#reducing y=0 labels from training set\ntotaldata = totaldata.reset_index(drop=True)\ny_master_train = y_master_train.reset_index(drop=True)\n\n#get training data and then shuffle and get some random permutation of observations\nntrain = int(y_master_train.shape[0])\nremove_n = int(ntrain*0.6)\ndrop_indices = np.random.choice(y_master_train[y_master_train==0].index, remove_n, replace=False)\nprint('Shape of training data before dropping rows having 0 labels: ', y_master_train.shape)\ntotaldata = totaldata.drop(drop_indices, axis=0)\ny_master_train = y_master_train.drop(drop_indices)\nprint('Shape of training data after dropping rows having 0 labels: ',y_master_train.shape)\n\n#checking proportion of different classes in y\ny_master_train.value_counts(normalize=True)"},{"metadata":{"_uuid":"ab6305dea9c20e88ffb92b9acabe6b309bfc0070"},"cell_type":"markdown","source":"Modelling:"},{"metadata":{"trusted":true,"_uuid":"8b6069aae09b896613c825dd3dbf3dac1127dee8"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data = (totaldata[totaldata['target']!='test_data']).drop(['target'],axis=1)\ntest_data = (totaldata[totaldata['target']=='test_data']).drop(['target'],axis=1)\n#  split X between training and testing set\nx_train, x_test, y_train, y_test = train_test_split(train_data,y_master_train, test_size=0.25, shuffle=True,stratify=y_master_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\n#PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=50)\npca = pca.fit(x_train)\nprincipalComponents_train = pca.transform(x_train)\nprincipalComponents_test = pca.transform(x_test)\nx_train_pca = pd.DataFrame(principalComponents_train)\nx_test_pca = pd.DataFrame(principalComponents_test)\n\n'''\n\n#Not using PCA as it decreased the AUC score from 89.4 to 72 with all other things kept constant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del totaldata\ndel traindata\ndel testdata\ndel uni\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_data\ndel test_data\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb3ba7e9524fbe0effdac66e4dc1b4bf3ce2f58","scrolled":true},"cell_type":"code","source":"y_train.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Light GBM standalone"},{"metadata":{},"cell_type":"markdown","source":"\n#following params are from 1st run of bayesian optimization\nparam = {\n    'feature_fraction': 0.8197428551123196, 'lambda_l1': 7.075054502660179, 'lambda_l2': 7.820448238204753,\n    'learning_rate': 0.05831167983832596, \n    'max_depth': 14.497149517724528, 'min_gain_to_split': 0.31541832302278316, \n    'n_estimators': 2778.5508893048313, 'num_leaves': 5.258308295984117\n}\nclf = LGBMClassifier( n_estimators=int(param['n_estimators']),\n                         num_leaves = int(param['num_leaves']),\n                         learning_rate=param['learning_rate'],\n                         feature_fraction=param['feature_fraction'],\n                         lambda_l1=param['lambda_l1'],\n                        lambda_l2=param['lambda_l2'],\n                        min_gain_to_split=param['min_gain_to_split'],\n                        max_depth=int(param['max_depth']),\n                     eval_metric='auc'\n                    )        \n\nclf.fit(x_train, y_train, \n            eval_set=[(x_test,y_test)],early_stopping_rounds=200,eval_metric='auc',verbose=False\n           )\n\na = clf.best_score_['valid_0']['auc']\nprint(a)"},{"metadata":{},"cell_type":"markdown","source":"# Light GBM bayesian optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model2_lgbm(num_leaves,  # int\n    learning_rate,  \n    feature_fraction,\n    lambda_l1,\n    lambda_l2,\n    min_gain_to_split,\n    max_depth,n_estimators):\n    \n    clf = LGBMClassifier( n_estimators=int(n_estimators),\n                         num_leaves = int(num_leaves),\n                         learning_rate=learning_rate,\n                         feature_fraction=feature_fraction,\n                         lambda_l1=lambda_l1,\n                        lambda_l2=lambda_l2,\n                        min_gain_to_split=min_gain_to_split,\n                        max_depth=int(max_depth),\n                     eval_metric='auc'\n                     \n            )        \n\n    clf.fit(x_train, y_train, \n                eval_set=[(x_test,y_test)],early_stopping_rounds=200,eval_metric='auc',verbose=False\n               )\n    \n    a = clf.best_score_['valid_0']['auc']\n    \n    return a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bounds_lgbm = {\n    'max_depth': (10, 15),\n    'num_leaves':(5,40),\n    'learning_rate':(0.01,0.1),\n    'feature_fraction':(0.7,1),\n    'lambda_l1': (0, 8.0), \n    'lambda_l2': (0, 8.0), \n    'min_gain_to_split': (0, 1.0),\n    'n_estimators':(2000,5000)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\nLGB_BO = BayesianOptimization(model2_lgbm, bounds_lgbm)\n\ninit_points = 5\nn_iter = 15\n\n\nprint('-' * 130)\n\nLGB_BO.maximize(init_points=init_points, n_iter=n_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(LGB_BO.max['target'])\nprint(LGB_BO.max['params'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sdsd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Catboost bayesian optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_1_catb( iterations,learning_rate,depth,l2_leaf_reg):\n        catb = CatBoostClassifier(\n            iterations=int(iterations),\n           #cat_features=cat_col,\n            learning_rate=learning_rate,\n            depth = int(depth),\n            l2_leaf_reg = l2_leaf_reg,\n            #subsample=subsample,  #can't be trained for catboost using bayesian opt\n            early_stopping_rounds=50,\n          #  colsample_bylevel = colsample_bylevel,  #can't be trained on GPU(but only on CPU) for catboost using bayesian opt\n          # max_leaves = int(max_leaves),  can't be trained on CPU\n            eval_metric='AUC',\n           task_type='GPU',\n           #verbose=30\n        )\n        catb.fit(\n            x_train, y_train,\n            eval_set=(x_test, y_test),verbose=10\n        )\n       # print('Model is fitted: ' + str(catb.is_fitted()))\n        #print('Model params:')\n        #print(catb.get_params())\n        a = catb.get_best_score()\n        return a['validation_0']['AUC']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bounds_catb = {\n    'iterations': (30, 150), \n    'learning_rate': (0.05, 0.9),  \n    'depth': (6, 15),\n    'l2_leaf_reg': (0,5),    \n  # 'subsample': (0.75,1),\n   # 'colsample_bylevel': (0.75, 1), \n   # 'max_leaves': (5,40)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\nCATB_BO = BayesianOptimization(model_1_catb, bounds_catb)\n\ninit_points = 3\nn_iter = 10\n\n\nprint('-' * 130)\n\n#CATB_BO.maximize(init_points=init_points, n_iter=n_iter)\n\nprint(CATB_BO.max['target'])\nprint(CATB_BO.max['params'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOTE: Here I have shown how to make prediction on test set made from train data split\n# To make prediction on unknown test set just replace X_train with full train data and \n# X_test with unknown test data\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom vecstack import stacking     #this is a library made for stacking by a Kaggler\nfrom catboost import CatBoostClassifier\n\nmodels = [\n    #KNeighborsClassifier(n_neighbors=5,\n                       # n_jobs=-1),\n    CatBoostClassifier(\n    learning_rate=0.05,\n    depth = 10,\n    rsm = 0.7, loss_function = 'Logloss', logging_level='Verbose', eval_metric='AUC',iterations = 300,),\n        \n    #RandomForestClassifier(random_state=0, n_jobs=-1, \n                           #n_estimators=100, max_depth=3),\n        \n    XGBClassifier(n_estimators=2000, reg_alpha = 0.01, objective= 'rank:pairwise',silent=False)\n]\n\n\nS_train, S_test = stacking(models,                   \n                           x_train, y_train, x_test,   \n                           regression=False, \n     \n                           mode='oof_pred_bag', \n       \n                           needs_proba=False,\n         \n                           save_dir=None, \n            \n                           metric=roc_auc_score, \n    \n                           n_folds=4, \n                 \n                           stratified=True,\n            \n                           shuffle=True)\n\n#meta model\nmodel = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n                      n_estimators=100, max_depth=3)\n    \nmodel = model.fit(S_train, y_train)\ny_pred = model.predict(S_test)\nprint('Final prediction score: [%.8f]' % roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.ravel(y_test)\nb = np.ravel(y_pred)\nroc_auc_score(a,b)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adb7aa4a6ae4279aa6ef9c693707ae876c1633bc"},"cell_type":"markdown","source":"Used XGB, got 0.889 auc score. Commenting now to end execution of whole program faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\nmodel = CatBoostClassifier(\n    random_seed=63,\n    iterations=300,\n    learning_rate=0.05,\n    depth=10,\n    loss_function='Logloss',\n    rsm = 0.7,\n    od_type='Iter',\n    od_wait=20,\n    eval_metric = 'AUC',\n)\nmodel.fit(\n    x_train, y_train,\n    logging_level='Silent',\n    eval_set=(x_test, y_test),\n    plot=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nxgb = XGBClassifier(n_estimators=2000, reg_alpha = 0.01)\nrf = RandomForestClassifier()\nextraT = ExtraTreesClassifier()\n\nclass StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)\n    \n    \nstacked_averaged_models = StackingAveragedModels(base_models = (extraT, rf, xgb),\n                                                 meta_model = lasso)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stacked_averaged_models.fit(x_train, y_train)\n#y_pred = stacked_averaged_models.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Stacking(model,train,y,test,n_fold):\n    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n    test_pred=np.empty((test.shape[0],1),float)\n    train_pred=np.empty((0,1),float)\n    for train_indices,val_indices in folds.split(train,y.values):\n        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n\n        model.fit(X=x_train,y=y_train)\n        train_pred=np.append(train_pred,model.predict(x_val))\n        test_pred=np.append(test_pred,model.predict(test))\n    return test_pred.reshape(-1,1),train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nxgb = XGBClassifier(n_estimators=100, reg_alpha = 0.01)\nrf = RandomForestClassifier()\n\n\ntest_pred1 ,train_pred1=Stacking(model=xgb,n_fold=5, train=x_train,test=x_test,y=y_train)\n\ntrain_pred1=pd.DataFrame(train_pred1)\ntest_pred1=pd.DataFrame(test_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred2 ,train_pred2=Stacking(model=rf,n_fold=10,train=x_train,test=x_test,y=y_train)\n\ntrain_pred2=pd.DataFrame(train_pred2)\ntest_pred2=pd.DataFrame(test_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train_pred1, train_pred2], axis=1)\ndf_test = pd.concat([test_pred1, test_pred2], axis=1)\n\nmodel = ExtraTreesClassifier()\nmodel.fit(df,y_train)\nmodel.score(df_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab9942008943f6ea78ce625dbd5fc709ccef382e"},"cell_type":"code","source":"roc_auc_score(y_test, lgb_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2d3fc84fb675a00fa1b8781e79c24690a78e322"},"cell_type":"code","source":"y_pred = clf.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1b0719b2a82aab12cd1c72dbe300762778c3edf"},"cell_type":"code","source":"sub = pd.DataFrame(data = testid,columns =['ID_code'])\nsub['target'] = y_pred\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}