{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DA-4 Midterm\n## Author: Brankov Ravil CSSE-1707DA-3\nThis work is concerned on prediction of completing transaction by customer. We should use several method of classification to reach the maximum ROG AUC score. AUC score is measure of prediction the FP/TP/TN/FN cases, which are made after fitting the model on test part of dataset. Let's go deeper. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The key libraries is SciKit Learn which contain main classification tools."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n%matplotlib inline\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset is already splitted"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/santander-customer-transaction-prediction/train.csv\")\ntest = pd.read_csv(\"../input/santander-customer-transaction-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\nNow, we must provide the analysis of our data, for better understanding the classification process."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, all columns are anonymous, so it will be hard to preprocess it.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With 200000 records we have no one NaN value. Good!"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=target,data=train, palette='hls')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop_duplicates()\ntrain.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have no duplicate data. Correlations we can see below"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nc= train.corr()\nsns.heatmap(c,cmap=\"BrBG\",annot=True)\nc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression\nLogistic regression using the linear function to divide the classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['target']\ndf_train = train.drop(columns = ['target', 'ID_code'])\ndf_test = test.drop(columns = ['ID_code'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here, we define target and dependent columns. Later, we split our data to train and test parts"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train,  y_test = train_test_split(df_train, target,test_size=0.2, random_state=142)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape,y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logs = LogisticRegression(class_weight='balanced')\nlogs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfpr, tpr, _ = metrics.roc_curve(y_test, logs.predict_proba(X_test)[:,1])\nauc = metrics.auc(fpr, tpr)\nauc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logs_pred_test = logs.predict_proba(df_test)[:,1]\nsubmit = test[['ID_code']]\nsubmit['target'] = logs_pred_test\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('log_reg.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree\nDecision tree is based on binary tree and set the class through evaluating parameters and assigning the 0 or 1 for the answer\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(class_weight='balanced',max_depth=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = tree.predict_proba(X_test)[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\nauc = metrics.auc(fpr, tpr)\nauc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest\nRandom forest is complete models separately like decision tree manner with random parameter and combine predictions for giving the average or weighted output"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=100, class_weight='balanced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= model.predict_proba(X_test)[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\nauc = metrics.auc(fpr, tpr)\nauc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds_gnb = gnb.predict(X_test)\nfpr, tpr, _ = metrics.roc_curve(y_test, y_preds_gnb)\nauc = metrics.auc(fpr, tpr)\nauc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/santander-customer-transaction-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_data = test_data.iloc[:,1:202]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds_test_data_gnb = gnb.predict(X_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission_gnb = pd.DataFrame({'ID_code': test_data.ID_code, 'target': y_preds_test_data_gnb})\nmy_submission_gnb.to_csv('submission_gnb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.testing import ignore_warnings\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=8,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = xgb.predict_proba(X_test)[:, 1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\nauc = metrics.auc(fpr, tpr)\nauc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}